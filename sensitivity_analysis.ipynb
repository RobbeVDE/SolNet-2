{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Data.Featurisation import data_handeler\n",
    "from Models.models import source, target\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "from scale import Scale\n",
    "from hyperparameters.hyperparameters import hyperparameters_source, hyperparameters_target\n",
    "import torch\n",
    "import scienceplots\n",
    "plt.style.use(['science'])\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from Models.lstm import LSTM\n",
    "from tensors.Tensorisation import Tensorisation\n",
    "from scale import Scale\n",
    "from pvlib import location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physics-informed measures\n",
    "- is_day\n",
    "- PoA, T_PV\n",
    "- inverter limit\n",
    "- decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calclations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IS DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index = pd.MultiIndex.from_product([range(7), range(13)])\n",
    "rmse = pd.DataFrame(index=my_index, columns=range(4))\n",
    "sites = range(4)\n",
    "model = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([841, 24, 7]) torch.Size([210, 24, 7]) torch.Size([841, 24, 1]) torch.Size([210, 24, 1])\n",
      "Step 0: Average train loss: 0.0538 | Average test loss: 0.0406\n",
      "Step 5: Average train loss: 0.0141 | Average test loss: 0.0101\n",
      "Step 10: Average train loss: 0.0115 | Average test loss: 0.0096\n",
      "Step 15: Average train loss: 0.0111 | Average test loss: 0.0089\n",
      "Step 20: Average train loss: 0.0107 | Average test loss: 0.0090\n",
      "Step 25: Average train loss: 0.0105 | Average test loss: 0.0090\n",
      "Step 30: Average train loss: 0.0104 | Average test loss: 0.0091\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0090\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0090\n",
      "Step 45: Average train loss: 0.0103 | Average test loss: 0.0088\n",
      "Step 50: Average train loss: 0.0098 | Average test loss: 0.0083\n",
      "Step 55: Average train loss: 0.0096 | Average test loss: 0.0082\n",
      "Step 60: Average train loss: 0.0099 | Average test loss: 0.0090\n",
      "Step 65: Average train loss: 0.0099 | Average test loss: 0.0088\n",
      "Step 70: Average train loss: 0.0095 | Average test loss: 0.0085\n",
      "Step 75: Average train loss: 0.0093 | Average test loss: 0.0083\n",
      "Step 80: Average train loss: 0.0093 | Average test loss: 0.0087\n",
      "Step 85: Average train loss: 0.0093 | Average test loss: 0.0082\n",
      "Step 90: Average train loss: 0.0095 | Average test loss: 0.0083\n",
      "Step 95: Average train loss: 0.0092 | Average test loss: 0.0084\n",
      "Best Epoch: 98\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 54346.1328125\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0087\n",
      "Step 10: Average train loss: 0.0087\n",
      "Step 15: Average train loss: 0.0087\n",
      "Step 20: Average train loss: 0.0087\n",
      "Step 25: Average train loss: 0.0087\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0086\n",
      "Step 40: Average train loss: 0.0086\n",
      "Step 45: Average train loss: 0.0086\n",
      "Step 50: Average train loss: 0.0086\n",
      "Step 55: Average train loss: 0.0086\n",
      "Step 60: Average train loss: 0.0086\n",
      "Step 65: Average train loss: 0.0086\n",
      "Step 70: Average train loss: 0.0086\n",
      "Step 75: Average train loss: 0.0086\n",
      "Step 80: Average train loss: 0.0086\n",
      "Step 85: Average train loss: 0.0085\n",
      "Step 90: Average train loss: 0.0085\n",
      "Step 95: Average train loss: 0.0085\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 56943.83203125\n",
      "Step 0: Average train loss: 0.0090\n",
      "Step 5: Average train loss: 0.0090\n",
      "Step 10: Average train loss: 0.0090\n",
      "Step 15: Average train loss: 0.0090\n",
      "Step 20: Average train loss: 0.0090\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0090\n",
      "Step 70: Average train loss: 0.0090\n",
      "Step 75: Average train loss: 0.0090\n",
      "Step 80: Average train loss: 0.0090\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 46696.7109375\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0083\n",
      "Step 20: Average train loss: 0.0083\n",
      "Step 25: Average train loss: 0.0083\n",
      "Step 30: Average train loss: 0.0083\n",
      "Step 35: Average train loss: 0.0083\n",
      "Step 40: Average train loss: 0.0083\n",
      "Step 45: Average train loss: 0.0083\n",
      "Step 50: Average train loss: 0.0082\n",
      "Step 55: Average train loss: 0.0082\n",
      "Step 60: Average train loss: 0.0082\n",
      "Step 65: Average train loss: 0.0082\n",
      "Step 70: Average train loss: 0.0082\n",
      "Step 75: Average train loss: 0.0082\n",
      "Step 80: Average train loss: 0.0082\n",
      "Step 85: Average train loss: 0.0082\n",
      "Step 90: Average train loss: 0.0082\n",
      "Step 95: Average train loss: 0.0082\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50113.99609375\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0081\n",
      "Step 10: Average train loss: 0.0081\n",
      "Step 15: Average train loss: 0.0081\n",
      "Step 20: Average train loss: 0.0081\n",
      "Step 25: Average train loss: 0.0081\n",
      "Step 30: Average train loss: 0.0081\n",
      "Step 35: Average train loss: 0.0081\n",
      "Step 40: Average train loss: 0.0081\n",
      "Step 45: Average train loss: 0.0081\n",
      "Step 50: Average train loss: 0.0080\n",
      "Step 55: Average train loss: 0.0080\n",
      "Step 60: Average train loss: 0.0080\n",
      "Step 65: Average train loss: 0.0080\n",
      "Step 70: Average train loss: 0.0080\n",
      "Step 75: Average train loss: 0.0080\n",
      "Step 80: Average train loss: 0.0080\n",
      "Step 85: Average train loss: 0.0080\n",
      "Step 90: Average train loss: 0.0080\n",
      "Step 95: Average train loss: 0.0080\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 48781.3203125\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0075\n",
      "Step 10: Average train loss: 0.0075\n",
      "Step 15: Average train loss: 0.0075\n",
      "Step 20: Average train loss: 0.0075\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0075\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 38099.0625\n",
      "Step 0: Average train loss: 0.0076\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0076\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 26257.2109375\n",
      "Step 0: Average train loss: 0.0069\n",
      "Step 5: Average train loss: 0.0069\n",
      "Step 10: Average train loss: 0.0069\n",
      "Step 15: Average train loss: 0.0069\n",
      "Step 20: Average train loss: 0.0069\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9462.3818359375\n",
      "Step 0: Average train loss: 0.0057\n",
      "Step 5: Average train loss: 0.0057\n",
      "Step 10: Average train loss: 0.0057\n",
      "Step 15: Average train loss: 0.0057\n",
      "Step 20: Average train loss: 0.0057\n",
      "Step 25: Average train loss: 0.0057\n",
      "Step 30: Average train loss: 0.0057\n",
      "Step 35: Average train loss: 0.0057\n",
      "Step 40: Average train loss: 0.0057\n",
      "Step 45: Average train loss: 0.0057\n",
      "Step 50: Average train loss: 0.0057\n",
      "Step 55: Average train loss: 0.0057\n",
      "Step 60: Average train loss: 0.0057\n",
      "Step 65: Average train loss: 0.0057\n",
      "Step 70: Average train loss: 0.0057\n",
      "Step 75: Average train loss: 0.0057\n",
      "Step 80: Average train loss: 0.0057\n",
      "Step 85: Average train loss: 0.0057\n",
      "Step 90: Average train loss: 0.0057\n",
      "Step 95: Average train loss: 0.0057\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 13565.466796875\n",
      "Step 0: Average train loss: 0.0058\n",
      "Step 5: Average train loss: 0.0058\n",
      "Step 10: Average train loss: 0.0058\n",
      "Step 15: Average train loss: 0.0058\n",
      "Step 20: Average train loss: 0.0058\n",
      "Step 25: Average train loss: 0.0058\n",
      "Step 30: Average train loss: 0.0058\n",
      "Step 35: Average train loss: 0.0058\n",
      "Step 40: Average train loss: 0.0058\n",
      "Step 45: Average train loss: 0.0058\n",
      "Step 50: Average train loss: 0.0058\n",
      "Step 55: Average train loss: 0.0058\n",
      "Step 60: Average train loss: 0.0058\n",
      "Step 65: Average train loss: 0.0058\n",
      "Step 70: Average train loss: 0.0058\n",
      "Step 75: Average train loss: 0.0058\n",
      "Step 80: Average train loss: 0.0058\n",
      "Step 85: Average train loss: 0.0058\n",
      "Step 90: Average train loss: 0.0058\n",
      "Step 95: Average train loss: 0.0058\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 40136.0078125\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 52778.87890625\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 55319.29296875\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 81718.3125\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([839, 24, 7]) torch.Size([210, 24, 7]) torch.Size([839, 24, 1]) torch.Size([210, 24, 1])\n",
      "Step 0: Average train loss: 0.0473 | Average test loss: 0.0324\n",
      "Step 5: Average train loss: 0.0102 | Average test loss: 0.0070\n",
      "Step 10: Average train loss: 0.0092 | Average test loss: 0.0068\n",
      "Step 15: Average train loss: 0.0090 | Average test loss: 0.0063\n",
      "Step 20: Average train loss: 0.0089 | Average test loss: 0.0062\n",
      "Step 25: Average train loss: 0.0089 | Average test loss: 0.0061\n",
      "Step 30: Average train loss: 0.0088 | Average test loss: 0.0061\n",
      "Step 35: Average train loss: 0.0088 | Average test loss: 0.0061\n",
      "Step 40: Average train loss: 0.0088 | Average test loss: 0.0061\n",
      "Step 45: Average train loss: 0.0089 | Average test loss: 0.0063\n",
      "Step 50: Average train loss: 0.0087 | Average test loss: 0.0068\n",
      "Step 55: Average train loss: 0.0087 | Average test loss: 0.0061\n",
      "Step 60: Average train loss: 0.0091 | Average test loss: 0.0060\n",
      "Step 65: Average train loss: 0.0089 | Average test loss: 0.0060\n",
      "Step 70: Average train loss: 0.0084 | Average test loss: 0.0057\n",
      "Step 75: Average train loss: 0.0082 | Average test loss: 0.0058\n",
      "Step 80: Average train loss: 0.0081 | Average test loss: 0.0057\n",
      "Step 85: Average train loss: 0.0081 | Average test loss: 0.0060\n",
      "Step 90: Average train loss: 0.0081 | Average test loss: 0.0056\n",
      "Step 95: Average train loss: 0.0079 | Average test loss: 0.0059\n",
      "Best Epoch: 91\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 36202.87890625\n",
      "Step 0: Average train loss: 0.0076\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0075\n",
      "Step 50: Average train loss: 0.0075\n",
      "Step 55: Average train loss: 0.0075\n",
      "Step 60: Average train loss: 0.0075\n",
      "Step 65: Average train loss: 0.0075\n",
      "Step 70: Average train loss: 0.0075\n",
      "Step 75: Average train loss: 0.0075\n",
      "Step 80: Average train loss: 0.0075\n",
      "Step 85: Average train loss: 0.0075\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 37247.47265625\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0075\n",
      "Step 10: Average train loss: 0.0075\n",
      "Step 15: Average train loss: 0.0075\n",
      "Step 20: Average train loss: 0.0075\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0075\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0075\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 45445.16796875\n",
      "Step 0: Average train loss: 0.0082\n",
      "Step 5: Average train loss: 0.0082\n",
      "Step 10: Average train loss: 0.0082\n",
      "Step 15: Average train loss: 0.0082\n",
      "Step 20: Average train loss: 0.0082\n",
      "Step 25: Average train loss: 0.0082\n",
      "Step 30: Average train loss: 0.0082\n",
      "Step 35: Average train loss: 0.0082\n",
      "Step 40: Average train loss: 0.0082\n",
      "Step 45: Average train loss: 0.0082\n",
      "Step 50: Average train loss: 0.0082\n",
      "Step 55: Average train loss: 0.0082\n",
      "Step 60: Average train loss: 0.0082\n",
      "Step 65: Average train loss: 0.0082\n",
      "Step 70: Average train loss: 0.0082\n",
      "Step 75: Average train loss: 0.0082\n",
      "Step 80: Average train loss: 0.0082\n",
      "Step 85: Average train loss: 0.0081\n",
      "Step 90: Average train loss: 0.0081\n",
      "Step 95: Average train loss: 0.0081\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 32309.599609375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0076\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 34422.90625\n",
      "Step 0: Average train loss: 0.0074\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0074\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23947.3046875\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 12867.8818359375\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 7980.96337890625\n",
      "Step 0: Average train loss: 0.0052\n",
      "Step 5: Average train loss: 0.0052\n",
      "Step 10: Average train loss: 0.0052\n",
      "Step 15: Average train loss: 0.0052\n",
      "Step 20: Average train loss: 0.0052\n",
      "Step 25: Average train loss: 0.0052\n",
      "Step 30: Average train loss: 0.0052\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0052\n",
      "Step 55: Average train loss: 0.0052\n",
      "Step 60: Average train loss: 0.0052\n",
      "Step 65: Average train loss: 0.0052\n",
      "Step 70: Average train loss: 0.0052\n",
      "Step 75: Average train loss: 0.0052\n",
      "Step 80: Average train loss: 0.0052\n",
      "Step 85: Average train loss: 0.0052\n",
      "Step 90: Average train loss: 0.0052\n",
      "Step 95: Average train loss: 0.0052\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 10667.95703125\n",
      "Step 0: Average train loss: 0.0053\n",
      "Step 5: Average train loss: 0.0053\n",
      "Step 10: Average train loss: 0.0053\n",
      "Step 15: Average train loss: 0.0053\n",
      "Step 20: Average train loss: 0.0053\n",
      "Step 25: Average train loss: 0.0053\n",
      "Step 30: Average train loss: 0.0053\n",
      "Step 35: Average train loss: 0.0053\n",
      "Step 40: Average train loss: 0.0053\n",
      "Step 45: Average train loss: 0.0053\n",
      "Step 50: Average train loss: 0.0053\n",
      "Step 55: Average train loss: 0.0053\n",
      "Step 60: Average train loss: 0.0053\n",
      "Step 65: Average train loss: 0.0053\n",
      "Step 70: Average train loss: 0.0053\n",
      "Step 75: Average train loss: 0.0053\n",
      "Step 80: Average train loss: 0.0053\n",
      "Step 85: Average train loss: 0.0053\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 15932.0791015625\n",
      "Step 0: Average train loss: 0.0051\n",
      "Step 5: Average train loss: 0.0051\n",
      "Step 10: Average train loss: 0.0051\n",
      "Step 15: Average train loss: 0.0051\n",
      "Step 20: Average train loss: 0.0051\n",
      "Step 25: Average train loss: 0.0051\n",
      "Step 30: Average train loss: 0.0051\n",
      "Step 35: Average train loss: 0.0051\n",
      "Step 40: Average train loss: 0.0051\n",
      "Step 45: Average train loss: 0.0051\n",
      "Step 50: Average train loss: 0.0051\n",
      "Step 55: Average train loss: 0.0051\n",
      "Step 60: Average train loss: 0.0051\n",
      "Step 65: Average train loss: 0.0051\n",
      "Step 70: Average train loss: 0.0051\n",
      "Step 75: Average train loss: 0.0051\n",
      "Step 80: Average train loss: 0.0051\n",
      "Step 85: Average train loss: 0.0051\n",
      "Step 90: Average train loss: 0.0051\n",
      "Step 95: Average train loss: 0.0051\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 49615.765625\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 38753.48046875\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 37619.66796875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([859, 24, 7]) torch.Size([215, 24, 7]) torch.Size([859, 24, 1]) torch.Size([215, 24, 1])\n",
      "Step 0: Average train loss: 0.0370 | Average test loss: 0.0067\n",
      "Step 5: Average train loss: 0.0053 | Average test loss: 0.0039\n",
      "Step 10: Average train loss: 0.0049 | Average test loss: 0.0038\n",
      "Step 15: Average train loss: 0.0048 | Average test loss: 0.0040\n",
      "Step 20: Average train loss: 0.0047 | Average test loss: 0.0040\n",
      "Step 25: Average train loss: 0.0046 | Average test loss: 0.0040\n",
      "Step 30: Average train loss: 0.0046 | Average test loss: 0.0039\n",
      "Step 35: Average train loss: 0.0045 | Average test loss: 0.0039\n",
      "Step 40: Average train loss: 0.0045 | Average test loss: 0.0039\n",
      "Step 45: Average train loss: 0.0045 | Average test loss: 0.0039\n",
      "Step 50: Average train loss: 0.0044 | Average test loss: 0.0039\n",
      "Step 55: Average train loss: 0.0044 | Average test loss: 0.0038\n",
      "Step 60: Average train loss: 0.0044 | Average test loss: 0.0038\n",
      "Step 65: Average train loss: 0.0044 | Average test loss: 0.0038\n",
      "Step 70: Average train loss: 0.0044 | Average test loss: 0.0038\n",
      "Step 75: Average train loss: 0.0044 | Average test loss: 0.0038\n",
      "Step 80: Average train loss: 0.0044 | Average test loss: 0.0038\n",
      "Step 85: Average train loss: 0.0044 | Average test loss: 0.0038\n",
      "Step 90: Average train loss: 0.0044 | Average test loss: 0.0038\n",
      "Step 95: Average train loss: 0.0043 | Average test loss: 0.0038\n",
      "Best Epoch: 8\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 303591.1875\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0160\n",
      "Step 30: Average train loss: 0.0160\n",
      "Step 35: Average train loss: 0.0160\n",
      "Step 40: Average train loss: 0.0160\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0159\n",
      "Step 85: Average train loss: 0.0159\n",
      "Step 90: Average train loss: 0.0159\n",
      "Step 95: Average train loss: 0.0159\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 290157.65625\n",
      "Step 0: Average train loss: 0.0151\n",
      "Step 5: Average train loss: 0.0151\n",
      "Step 10: Average train loss: 0.0151\n",
      "Step 15: Average train loss: 0.0151\n",
      "Step 20: Average train loss: 0.0151\n",
      "Step 25: Average train loss: 0.0151\n",
      "Step 30: Average train loss: 0.0151\n",
      "Step 35: Average train loss: 0.0151\n",
      "Step 40: Average train loss: 0.0151\n",
      "Step 45: Average train loss: 0.0150\n",
      "Step 50: Average train loss: 0.0150\n",
      "Step 55: Average train loss: 0.0150\n",
      "Step 60: Average train loss: 0.0150\n",
      "Step 65: Average train loss: 0.0150\n",
      "Step 70: Average train loss: 0.0150\n",
      "Step 75: Average train loss: 0.0150\n",
      "Step 80: Average train loss: 0.0150\n",
      "Step 85: Average train loss: 0.0150\n",
      "Step 90: Average train loss: 0.0150\n",
      "Step 95: Average train loss: 0.0150\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 247062.71875\n",
      "Step 0: Average train loss: 0.0146\n",
      "Step 5: Average train loss: 0.0146\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0145\n",
      "Step 45: Average train loss: 0.0145\n",
      "Step 50: Average train loss: 0.0145\n",
      "Step 55: Average train loss: 0.0145\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0144\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 280120.25\n",
      "Step 0: Average train loss: 0.0146\n",
      "Step 5: Average train loss: 0.0146\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0145\n",
      "Step 35: Average train loss: 0.0145\n",
      "Step 40: Average train loss: 0.0145\n",
      "Step 45: Average train loss: 0.0145\n",
      "Step 50: Average train loss: 0.0145\n",
      "Step 55: Average train loss: 0.0145\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0144\n",
      "Step 80: Average train loss: 0.0144\n",
      "Step 85: Average train loss: 0.0144\n",
      "Step 90: Average train loss: 0.0144\n",
      "Step 95: Average train loss: 0.0144\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 292307.0625\n",
      "Step 0: Average train loss: 0.0146\n",
      "Step 5: Average train loss: 0.0146\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0145\n",
      "Step 25: Average train loss: 0.0145\n",
      "Step 30: Average train loss: 0.0145\n",
      "Step 35: Average train loss: 0.0145\n",
      "Step 40: Average train loss: 0.0145\n",
      "Step 45: Average train loss: 0.0145\n",
      "Step 50: Average train loss: 0.0145\n",
      "Step 55: Average train loss: 0.0145\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0144\n",
      "Step 70: Average train loss: 0.0144\n",
      "Step 75: Average train loss: 0.0144\n",
      "Step 80: Average train loss: 0.0144\n",
      "Step 85: Average train loss: 0.0144\n",
      "Step 90: Average train loss: 0.0144\n",
      "Step 95: Average train loss: 0.0144\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 315575.5625\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 201694.515625\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0136\n",
      "Step 35: Average train loss: 0.0136\n",
      "Step 40: Average train loss: 0.0136\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0135\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 286348.65625\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0140\n",
      "Step 55: Average train loss: 0.0140\n",
      "Step 60: Average train loss: 0.0140\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 287833.8125\n",
      "Step 0: Average train loss: 0.0140\n",
      "Step 5: Average train loss: 0.0140\n",
      "Step 10: Average train loss: 0.0140\n",
      "Step 15: Average train loss: 0.0140\n",
      "Step 20: Average train loss: 0.0140\n",
      "Step 25: Average train loss: 0.0140\n",
      "Step 30: Average train loss: 0.0140\n",
      "Step 35: Average train loss: 0.0140\n",
      "Step 40: Average train loss: 0.0140\n",
      "Step 45: Average train loss: 0.0139\n",
      "Step 50: Average train loss: 0.0139\n",
      "Step 55: Average train loss: 0.0139\n",
      "Step 60: Average train loss: 0.0139\n",
      "Step 65: Average train loss: 0.0139\n",
      "Step 70: Average train loss: 0.0139\n",
      "Step 75: Average train loss: 0.0139\n",
      "Step 80: Average train loss: 0.0139\n",
      "Step 85: Average train loss: 0.0139\n",
      "Step 90: Average train loss: 0.0139\n",
      "Step 95: Average train loss: 0.0139\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 393217.90625\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0150\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0150\n",
      "Step 25: Average train loss: 0.0150\n",
      "Step 30: Average train loss: 0.0150\n",
      "Step 35: Average train loss: 0.0150\n",
      "Step 40: Average train loss: 0.0150\n",
      "Step 45: Average train loss: 0.0150\n",
      "Step 50: Average train loss: 0.0150\n",
      "Step 55: Average train loss: 0.0150\n",
      "Step 60: Average train loss: 0.0150\n",
      "Step 65: Average train loss: 0.0149\n",
      "Step 70: Average train loss: 0.0149\n",
      "Step 75: Average train loss: 0.0149\n",
      "Step 80: Average train loss: 0.0149\n",
      "Step 85: Average train loss: 0.0149\n",
      "Step 90: Average train loss: 0.0149\n",
      "Step 95: Average train loss: 0.0149\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 413522.875\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0160\n",
      "Step 30: Average train loss: 0.0160\n",
      "Step 35: Average train loss: 0.0160\n",
      "Step 40: Average train loss: 0.0160\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0159\n",
      "Step 90: Average train loss: 0.0159\n",
      "Step 95: Average train loss: 0.0159\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 381633.1875\n",
      "Step 0: Average train loss: 0.0156\n",
      "Step 5: Average train loss: 0.0156\n",
      "Step 10: Average train loss: 0.0156\n",
      "Step 15: Average train loss: 0.0155\n",
      "Step 20: Average train loss: 0.0155\n",
      "Step 25: Average train loss: 0.0155\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0155\n",
      "Step 45: Average train loss: 0.0155\n",
      "Step 50: Average train loss: 0.0155\n",
      "Step 55: Average train loss: 0.0155\n",
      "Step 60: Average train loss: 0.0155\n",
      "Step 65: Average train loss: 0.0155\n",
      "Step 70: Average train loss: 0.0155\n",
      "Step 75: Average train loss: 0.0155\n",
      "Step 80: Average train loss: 0.0155\n",
      "Step 85: Average train loss: 0.0155\n",
      "Step 90: Average train loss: 0.0155\n",
      "Step 95: Average train loss: 0.0155\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 553291.4375\n",
      "Not in Colab environment: Using .pkl files\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', HP_tuning=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('is_day')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "\n",
    "    rmse.loc[(0, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 6]) torch.Size([140, 24, 6]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0581 | Average test loss: 0.0352\n",
      "Step 5: Average train loss: 0.0281 | Average test loss: 0.0189\n",
      "Step 10: Average train loss: 0.0129 | Average test loss: 0.0128\n",
      "Step 15: Average train loss: 0.0119 | Average test loss: 0.0108\n",
      "Step 20: Average train loss: 0.0111 | Average test loss: 0.0101\n",
      "Step 25: Average train loss: 0.0107 | Average test loss: 0.0104\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0103\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0101\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0100\n",
      "Step 45: Average train loss: 0.0101 | Average test loss: 0.0096\n",
      "Step 50: Average train loss: 0.0100 | Average test loss: 0.0093\n",
      "Step 55: Average train loss: 0.0099 | Average test loss: 0.0094\n",
      "Step 60: Average train loss: 0.0096 | Average test loss: 0.0089\n",
      "Step 65: Average train loss: 0.0096 | Average test loss: 0.0088\n",
      "Step 70: Average train loss: 0.0098 | Average test loss: 0.0095\n",
      "Step 75: Average train loss: 0.0095 | Average test loss: 0.0088\n",
      "Step 80: Average train loss: 0.0096 | Average test loss: 0.0087\n",
      "Step 85: Average train loss: 0.0096 | Average test loss: 0.0089\n",
      "Step 90: Average train loss: 0.0095 | Average test loss: 0.0089\n",
      "Step 95: Average train loss: 0.0095 | Average test loss: 0.0089\n",
      "Best Epoch: 74\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 67267.3671875\n",
      "Step 0: Average train loss: 0.0108\n",
      "Step 5: Average train loss: 0.0108\n",
      "Step 10: Average train loss: 0.0108\n",
      "Step 15: Average train loss: 0.0107\n",
      "Step 20: Average train loss: 0.0107\n",
      "Step 25: Average train loss: 0.0107\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0107\n",
      "Step 40: Average train loss: 0.0107\n",
      "Step 45: Average train loss: 0.0106\n",
      "Step 50: Average train loss: 0.0106\n",
      "Step 55: Average train loss: 0.0106\n",
      "Step 60: Average train loss: 0.0106\n",
      "Step 65: Average train loss: 0.0106\n",
      "Step 70: Average train loss: 0.0105\n",
      "Step 75: Average train loss: 0.0105\n",
      "Step 80: Average train loss: 0.0105\n",
      "Step 85: Average train loss: 0.0105\n",
      "Step 90: Average train loss: 0.0105\n",
      "Step 95: Average train loss: 0.0105\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 61848.84375\n",
      "Step 0: Average train loss: 0.0104\n",
      "Step 5: Average train loss: 0.0104\n",
      "Step 10: Average train loss: 0.0103\n",
      "Step 15: Average train loss: 0.0103\n",
      "Step 20: Average train loss: 0.0103\n",
      "Step 25: Average train loss: 0.0103\n",
      "Step 30: Average train loss: 0.0103\n",
      "Step 35: Average train loss: 0.0102\n",
      "Step 40: Average train loss: 0.0102\n",
      "Step 45: Average train loss: 0.0102\n",
      "Step 50: Average train loss: 0.0102\n",
      "Step 55: Average train loss: 0.0102\n",
      "Step 60: Average train loss: 0.0101\n",
      "Step 65: Average train loss: 0.0101\n",
      "Step 70: Average train loss: 0.0101\n",
      "Step 75: Average train loss: 0.0101\n",
      "Step 80: Average train loss: 0.0101\n",
      "Step 85: Average train loss: 0.0101\n",
      "Step 90: Average train loss: 0.0100\n",
      "Step 95: Average train loss: 0.0100\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 48361.44921875\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0090\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0089\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0089\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0088\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0088\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50584.52734375\n",
      "Step 0: Average train loss: 0.0085\n",
      "Step 5: Average train loss: 0.0085\n",
      "Step 10: Average train loss: 0.0085\n",
      "Step 15: Average train loss: 0.0085\n",
      "Step 20: Average train loss: 0.0085\n",
      "Step 25: Average train loss: 0.0084\n",
      "Step 30: Average train loss: 0.0084\n",
      "Step 35: Average train loss: 0.0084\n",
      "Step 40: Average train loss: 0.0084\n",
      "Step 45: Average train loss: 0.0084\n",
      "Step 50: Average train loss: 0.0084\n",
      "Step 55: Average train loss: 0.0084\n",
      "Step 60: Average train loss: 0.0084\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0083\n",
      "Step 80: Average train loss: 0.0083\n",
      "Step 85: Average train loss: 0.0083\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 46891.515625\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0076\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 42090.41015625\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 28787.296875\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 12834.37109375\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 16912.67578125\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 39538.83984375\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 57669.7109375\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 58464.8671875\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 74974.3671875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 6]) torch.Size([140, 24, 6]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0524 | Average test loss: 0.0257\n",
      "Step 5: Average train loss: 0.0172 | Average test loss: 0.0167\n",
      "Step 10: Average train loss: 0.0093 | Average test loss: 0.0074\n",
      "Step 15: Average train loss: 0.0102 | Average test loss: 0.0085\n",
      "Step 20: Average train loss: 0.0091 | Average test loss: 0.0074\n",
      "Step 25: Average train loss: 0.0092 | Average test loss: 0.0073\n",
      "Step 30: Average train loss: 0.0090 | Average test loss: 0.0071\n",
      "Step 35: Average train loss: 0.0089 | Average test loss: 0.0071\n",
      "Step 40: Average train loss: 0.0089 | Average test loss: 0.0071\n",
      "Step 45: Average train loss: 0.0087 | Average test loss: 0.0070\n",
      "Step 50: Average train loss: 0.0087 | Average test loss: 0.0068\n",
      "Step 55: Average train loss: 0.0088 | Average test loss: 0.0066\n",
      "Step 60: Average train loss: 0.0089 | Average test loss: 0.0069\n",
      "Step 65: Average train loss: 0.0089 | Average test loss: 0.0070\n",
      "Step 70: Average train loss: 0.0086 | Average test loss: 0.0068\n",
      "Step 75: Average train loss: 0.0084 | Average test loss: 0.0065\n",
      "Step 80: Average train loss: 0.0082 | Average test loss: 0.0063\n",
      "Step 85: Average train loss: 0.0081 | Average test loss: 0.0062\n",
      "Step 90: Average train loss: 0.0080 | Average test loss: 0.0062\n",
      "Step 95: Average train loss: 0.0079 | Average test loss: 0.0060\n",
      "Best Epoch: 93\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 53166.72265625\n",
      "Step 0: Average train loss: 0.0111\n",
      "Step 5: Average train loss: 0.0111\n",
      "Step 10: Average train loss: 0.0111\n",
      "Step 15: Average train loss: 0.0111\n",
      "Step 20: Average train loss: 0.0111\n",
      "Step 25: Average train loss: 0.0111\n",
      "Step 30: Average train loss: 0.0110\n",
      "Step 35: Average train loss: 0.0110\n",
      "Step 40: Average train loss: 0.0110\n",
      "Step 45: Average train loss: 0.0110\n",
      "Step 50: Average train loss: 0.0110\n",
      "Step 55: Average train loss: 0.0109\n",
      "Step 60: Average train loss: 0.0109\n",
      "Step 65: Average train loss: 0.0109\n",
      "Step 70: Average train loss: 0.0109\n",
      "Step 75: Average train loss: 0.0109\n",
      "Step 80: Average train loss: 0.0108\n",
      "Step 85: Average train loss: 0.0108\n",
      "Step 90: Average train loss: 0.0108\n",
      "Step 95: Average train loss: 0.0108\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 46638.984375\n",
      "Step 0: Average train loss: 0.0102\n",
      "Step 5: Average train loss: 0.0101\n",
      "Step 10: Average train loss: 0.0101\n",
      "Step 15: Average train loss: 0.0101\n",
      "Step 20: Average train loss: 0.0101\n",
      "Step 25: Average train loss: 0.0100\n",
      "Step 30: Average train loss: 0.0100\n",
      "Step 35: Average train loss: 0.0100\n",
      "Step 40: Average train loss: 0.0100\n",
      "Step 45: Average train loss: 0.0099\n",
      "Step 50: Average train loss: 0.0099\n",
      "Step 55: Average train loss: 0.0099\n",
      "Step 60: Average train loss: 0.0099\n",
      "Step 65: Average train loss: 0.0098\n",
      "Step 70: Average train loss: 0.0098\n",
      "Step 75: Average train loss: 0.0098\n",
      "Step 80: Average train loss: 0.0098\n",
      "Step 85: Average train loss: 0.0098\n",
      "Step 90: Average train loss: 0.0097\n",
      "Step 95: Average train loss: 0.0097\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 52891.1796875\n",
      "Step 0: Average train loss: 0.0102\n",
      "Step 5: Average train loss: 0.0102\n",
      "Step 10: Average train loss: 0.0102\n",
      "Step 15: Average train loss: 0.0101\n",
      "Step 20: Average train loss: 0.0101\n",
      "Step 25: Average train loss: 0.0101\n",
      "Step 30: Average train loss: 0.0101\n",
      "Step 35: Average train loss: 0.0101\n",
      "Step 40: Average train loss: 0.0100\n",
      "Step 45: Average train loss: 0.0100\n",
      "Step 50: Average train loss: 0.0100\n",
      "Step 55: Average train loss: 0.0100\n",
      "Step 60: Average train loss: 0.0100\n",
      "Step 65: Average train loss: 0.0099\n",
      "Step 70: Average train loss: 0.0099\n",
      "Step 75: Average train loss: 0.0099\n",
      "Step 80: Average train loss: 0.0099\n",
      "Step 85: Average train loss: 0.0099\n",
      "Step 90: Average train loss: 0.0098\n",
      "Step 95: Average train loss: 0.0098\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 33174.09375\n",
      "Step 0: Average train loss: 0.0088\n",
      "Step 5: Average train loss: 0.0088\n",
      "Step 10: Average train loss: 0.0087\n",
      "Step 15: Average train loss: 0.0087\n",
      "Step 20: Average train loss: 0.0087\n",
      "Step 25: Average train loss: 0.0087\n",
      "Step 30: Average train loss: 0.0087\n",
      "Step 35: Average train loss: 0.0087\n",
      "Step 40: Average train loss: 0.0086\n",
      "Step 45: Average train loss: 0.0086\n",
      "Step 50: Average train loss: 0.0086\n",
      "Step 55: Average train loss: 0.0086\n",
      "Step 60: Average train loss: 0.0086\n",
      "Step 65: Average train loss: 0.0085\n",
      "Step 70: Average train loss: 0.0085\n",
      "Step 75: Average train loss: 0.0085\n",
      "Step 80: Average train loss: 0.0085\n",
      "Step 85: Average train loss: 0.0085\n",
      "Step 90: Average train loss: 0.0085\n",
      "Step 95: Average train loss: 0.0084\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 34521.9765625\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0081\n",
      "Step 10: Average train loss: 0.0080\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0080\n",
      "Step 25: Average train loss: 0.0080\n",
      "Step 30: Average train loss: 0.0080\n",
      "Step 35: Average train loss: 0.0080\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23388.98046875\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0075\n",
      "Step 10: Average train loss: 0.0075\n",
      "Step 15: Average train loss: 0.0075\n",
      "Step 20: Average train loss: 0.0075\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0074\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 12837.6474609375\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0063\n",
      "Step 55: Average train loss: 0.0063\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0063\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 8805.205078125\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 11746.576171875\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 15589.7529296875\n",
      "Step 0: Average train loss: 0.0052\n",
      "Step 5: Average train loss: 0.0052\n",
      "Step 10: Average train loss: 0.0052\n",
      "Step 15: Average train loss: 0.0052\n",
      "Step 20: Average train loss: 0.0052\n",
      "Step 25: Average train loss: 0.0052\n",
      "Step 30: Average train loss: 0.0052\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0052\n",
      "Step 55: Average train loss: 0.0052\n",
      "Step 60: Average train loss: 0.0052\n",
      "Step 65: Average train loss: 0.0052\n",
      "Step 70: Average train loss: 0.0052\n",
      "Step 75: Average train loss: 0.0052\n",
      "Step 80: Average train loss: 0.0052\n",
      "Step 85: Average train loss: 0.0052\n",
      "Step 90: Average train loss: 0.0052\n",
      "Step 95: Average train loss: 0.0052\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 45858.41015625\n",
      "Step 0: Average train loss: 0.0065\n",
      "Step 5: Average train loss: 0.0065\n",
      "Step 10: Average train loss: 0.0065\n",
      "Step 15: Average train loss: 0.0065\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 37543.17578125\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 31712.857421875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 6]) torch.Size([144, 24, 6]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0488 | Average test loss: 0.0421\n",
      "Step 5: Average train loss: 0.0085 | Average test loss: 0.0037\n",
      "Step 10: Average train loss: 0.0068 | Average test loss: 0.0023\n",
      "Step 15: Average train loss: 0.0057 | Average test loss: 0.0017\n",
      "Step 20: Average train loss: 0.0053 | Average test loss: 0.0018\n",
      "Step 25: Average train loss: 0.0052 | Average test loss: 0.0018\n",
      "Step 30: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 40: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 55: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 60: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 65: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 70: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 75: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 80: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 85: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 90: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 95: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Best Epoch: 15\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 303629.0\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0160\n",
      "Step 30: Average train loss: 0.0160\n",
      "Step 35: Average train loss: 0.0160\n",
      "Step 40: Average train loss: 0.0160\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0159\n",
      "Step 90: Average train loss: 0.0159\n",
      "Step 95: Average train loss: 0.0159\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 297376.1875\n",
      "Step 0: Average train loss: 0.0155\n",
      "Step 5: Average train loss: 0.0155\n",
      "Step 10: Average train loss: 0.0155\n",
      "Step 15: Average train loss: 0.0155\n",
      "Step 20: Average train loss: 0.0155\n",
      "Step 25: Average train loss: 0.0155\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0154\n",
      "Step 40: Average train loss: 0.0154\n",
      "Step 45: Average train loss: 0.0154\n",
      "Step 50: Average train loss: 0.0154\n",
      "Step 55: Average train loss: 0.0154\n",
      "Step 60: Average train loss: 0.0154\n",
      "Step 65: Average train loss: 0.0154\n",
      "Step 70: Average train loss: 0.0154\n",
      "Step 75: Average train loss: 0.0154\n",
      "Step 80: Average train loss: 0.0153\n",
      "Step 85: Average train loss: 0.0153\n",
      "Step 90: Average train loss: 0.0153\n",
      "Step 95: Average train loss: 0.0153\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 244038.109375\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 287812.15625\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 288650.34375\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 306827.09375\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 201934.328125\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0136\n",
      "Step 30: Average train loss: 0.0136\n",
      "Step 35: Average train loss: 0.0136\n",
      "Step 40: Average train loss: 0.0136\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 290399.71875\n",
      "Step 0: Average train loss: 0.0141\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0140\n",
      "Step 25: Average train loss: 0.0140\n",
      "Step 30: Average train loss: 0.0140\n",
      "Step 35: Average train loss: 0.0140\n",
      "Step 40: Average train loss: 0.0140\n",
      "Step 45: Average train loss: 0.0140\n",
      "Step 50: Average train loss: 0.0140\n",
      "Step 55: Average train loss: 0.0140\n",
      "Step 60: Average train loss: 0.0140\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0139\n",
      "Step 80: Average train loss: 0.0139\n",
      "Step 85: Average train loss: 0.0139\n",
      "Step 90: Average train loss: 0.0139\n",
      "Step 95: Average train loss: 0.0139\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 297489.59375\n",
      "Step 0: Average train loss: 0.0141\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 396815.375\n",
      "Step 0: Average train loss: 0.0152\n",
      "Step 5: Average train loss: 0.0152\n",
      "Step 10: Average train loss: 0.0152\n",
      "Step 15: Average train loss: 0.0152\n",
      "Step 20: Average train loss: 0.0151\n",
      "Step 25: Average train loss: 0.0151\n",
      "Step 30: Average train loss: 0.0151\n",
      "Step 35: Average train loss: 0.0151\n",
      "Step 40: Average train loss: 0.0151\n",
      "Step 45: Average train loss: 0.0151\n",
      "Step 50: Average train loss: 0.0151\n",
      "Step 55: Average train loss: 0.0151\n",
      "Step 60: Average train loss: 0.0151\n",
      "Step 65: Average train loss: 0.0151\n",
      "Step 70: Average train loss: 0.0151\n",
      "Step 75: Average train loss: 0.0151\n",
      "Step 80: Average train loss: 0.0151\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 414641.96875\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0161\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0161\n",
      "Step 30: Average train loss: 0.0161\n",
      "Step 35: Average train loss: 0.0161\n",
      "Step 40: Average train loss: 0.0161\n",
      "Step 45: Average train loss: 0.0161\n",
      "Step 50: Average train loss: 0.0161\n",
      "Step 55: Average train loss: 0.0161\n",
      "Step 60: Average train loss: 0.0161\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0160\n",
      "Step 90: Average train loss: 0.0160\n",
      "Step 95: Average train loss: 0.0160\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 389849.25\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0157\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0157\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0157\n",
      "Step 80: Average train loss: 0.0157\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 628029.9375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 6]) torch.Size([140, 24, 6]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0376 | Average test loss: 0.0253\n",
      "Step 5: Average train loss: 0.0303 | Average test loss: 0.0245\n",
      "Step 10: Average train loss: 0.0111 | Average test loss: 0.0100\n",
      "Step 15: Average train loss: 0.0095 | Average test loss: 0.0086\n",
      "Step 20: Average train loss: 0.0097 | Average test loss: 0.0084\n",
      "Step 25: Average train loss: 0.0094 | Average test loss: 0.0083\n",
      "Step 30: Average train loss: 0.0093 | Average test loss: 0.0081\n",
      "Step 35: Average train loss: 0.0092 | Average test loss: 0.0081\n",
      "Step 40: Average train loss: 0.0092 | Average test loss: 0.0080\n",
      "Step 45: Average train loss: 0.0091 | Average test loss: 0.0080\n",
      "Step 50: Average train loss: 0.0089 | Average test loss: 0.0080\n",
      "Step 55: Average train loss: 0.0088 | Average test loss: 0.0081\n",
      "Step 60: Average train loss: 0.0093 | Average test loss: 0.0091\n",
      "Step 65: Average train loss: 0.0114 | Average test loss: 0.0168\n",
      "Step 70: Average train loss: 0.0092 | Average test loss: 0.0082\n",
      "Step 75: Average train loss: 0.0095 | Average test loss: 0.0091\n",
      "Step 80: Average train loss: 0.0091 | Average test loss: 0.0082\n",
      "Step 85: Average train loss: 0.0097 | Average test loss: 0.0091\n",
      "Step 90: Average train loss: 0.0092 | Average test loss: 0.0085\n",
      "Step 95: Average train loss: 0.0095 | Average test loss: 0.0087\n",
      "Best Epoch: 46\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 74778.6328125\n",
      "Step 0: Average train loss: 0.0198\n",
      "Step 5: Average train loss: 0.0197\n",
      "Step 10: Average train loss: 0.0197\n",
      "Step 15: Average train loss: 0.0197\n",
      "Step 20: Average train loss: 0.0196\n",
      "Step 25: Average train loss: 0.0196\n",
      "Step 30: Average train loss: 0.0196\n",
      "Step 35: Average train loss: 0.0196\n",
      "Step 40: Average train loss: 0.0195\n",
      "Step 45: Average train loss: 0.0195\n",
      "Step 50: Average train loss: 0.0195\n",
      "Step 55: Average train loss: 0.0194\n",
      "Step 60: Average train loss: 0.0194\n",
      "Step 65: Average train loss: 0.0194\n",
      "Step 70: Average train loss: 0.0194\n",
      "Step 75: Average train loss: 0.0193\n",
      "Step 80: Average train loss: 0.0193\n",
      "Step 85: Average train loss: 0.0193\n",
      "Step 90: Average train loss: 0.0193\n",
      "Step 95: Average train loss: 0.0192\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 84285.65625\n",
      "Step 0: Average train loss: 0.0204\n",
      "Step 5: Average train loss: 0.0204\n",
      "Step 10: Average train loss: 0.0203\n",
      "Step 15: Average train loss: 0.0203\n",
      "Step 20: Average train loss: 0.0202\n",
      "Step 25: Average train loss: 0.0202\n",
      "Step 30: Average train loss: 0.0201\n",
      "Step 35: Average train loss: 0.0201\n",
      "Step 40: Average train loss: 0.0200\n",
      "Step 45: Average train loss: 0.0200\n",
      "Step 50: Average train loss: 0.0199\n",
      "Step 55: Average train loss: 0.0199\n",
      "Step 60: Average train loss: 0.0198\n",
      "Step 65: Average train loss: 0.0198\n",
      "Step 70: Average train loss: 0.0197\n",
      "Step 75: Average train loss: 0.0197\n",
      "Step 80: Average train loss: 0.0196\n",
      "Step 85: Average train loss: 0.0196\n",
      "Step 90: Average train loss: 0.0195\n",
      "Step 95: Average train loss: 0.0195\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 59954.01171875\n",
      "Step 0: Average train loss: 0.0184\n",
      "Step 5: Average train loss: 0.0184\n",
      "Step 10: Average train loss: 0.0183\n",
      "Step 15: Average train loss: 0.0183\n",
      "Step 20: Average train loss: 0.0182\n",
      "Step 25: Average train loss: 0.0182\n",
      "Step 30: Average train loss: 0.0181\n",
      "Step 35: Average train loss: 0.0181\n",
      "Step 40: Average train loss: 0.0180\n",
      "Step 45: Average train loss: 0.0180\n",
      "Step 50: Average train loss: 0.0180\n",
      "Step 55: Average train loss: 0.0179\n",
      "Step 60: Average train loss: 0.0179\n",
      "Step 65: Average train loss: 0.0178\n",
      "Step 70: Average train loss: 0.0178\n",
      "Step 75: Average train loss: 0.0177\n",
      "Step 80: Average train loss: 0.0177\n",
      "Step 85: Average train loss: 0.0177\n",
      "Step 90: Average train loss: 0.0176\n",
      "Step 95: Average train loss: 0.0176\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 51597.7109375\n",
      "Step 0: Average train loss: 0.0162\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0159\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0156\n",
      "Step 55: Average train loss: 0.0156\n",
      "Step 60: Average train loss: 0.0155\n",
      "Step 65: Average train loss: 0.0155\n",
      "Step 70: Average train loss: 0.0154\n",
      "Step 75: Average train loss: 0.0154\n",
      "Step 80: Average train loss: 0.0153\n",
      "Step 85: Average train loss: 0.0153\n",
      "Step 90: Average train loss: 0.0152\n",
      "Step 95: Average train loss: 0.0152\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 32845.98828125\n",
      "Step 0: Average train loss: 0.0129\n",
      "Step 5: Average train loss: 0.0129\n",
      "Step 10: Average train loss: 0.0128\n",
      "Step 15: Average train loss: 0.0128\n",
      "Step 20: Average train loss: 0.0127\n",
      "Step 25: Average train loss: 0.0127\n",
      "Step 30: Average train loss: 0.0126\n",
      "Step 35: Average train loss: 0.0126\n",
      "Step 40: Average train loss: 0.0125\n",
      "Step 45: Average train loss: 0.0125\n",
      "Step 50: Average train loss: 0.0124\n",
      "Step 55: Average train loss: 0.0124\n",
      "Step 60: Average train loss: 0.0123\n",
      "Step 65: Average train loss: 0.0123\n",
      "Step 70: Average train loss: 0.0122\n",
      "Step 75: Average train loss: 0.0122\n",
      "Step 80: Average train loss: 0.0121\n",
      "Step 85: Average train loss: 0.0121\n",
      "Step 90: Average train loss: 0.0120\n",
      "Step 95: Average train loss: 0.0120\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 29022.861328125\n",
      "Step 0: Average train loss: 0.0120\n",
      "Step 5: Average train loss: 0.0120\n",
      "Step 10: Average train loss: 0.0119\n",
      "Step 15: Average train loss: 0.0119\n",
      "Step 20: Average train loss: 0.0119\n",
      "Step 25: Average train loss: 0.0118\n",
      "Step 30: Average train loss: 0.0118\n",
      "Step 35: Average train loss: 0.0117\n",
      "Step 40: Average train loss: 0.0117\n",
      "Step 45: Average train loss: 0.0117\n",
      "Step 50: Average train loss: 0.0116\n",
      "Step 55: Average train loss: 0.0116\n",
      "Step 60: Average train loss: 0.0115\n",
      "Step 65: Average train loss: 0.0115\n",
      "Step 70: Average train loss: 0.0115\n",
      "Step 75: Average train loss: 0.0114\n",
      "Step 80: Average train loss: 0.0114\n",
      "Step 85: Average train loss: 0.0114\n",
      "Step 90: Average train loss: 0.0113\n",
      "Step 95: Average train loss: 0.0113\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 17421.53125\n",
      "Step 0: Average train loss: 0.0099\n",
      "Step 5: Average train loss: 0.0099\n",
      "Step 10: Average train loss: 0.0098\n",
      "Step 15: Average train loss: 0.0098\n",
      "Step 20: Average train loss: 0.0098\n",
      "Step 25: Average train loss: 0.0098\n",
      "Step 30: Average train loss: 0.0097\n",
      "Step 35: Average train loss: 0.0097\n",
      "Step 40: Average train loss: 0.0097\n",
      "Step 45: Average train loss: 0.0097\n",
      "Step 50: Average train loss: 0.0096\n",
      "Step 55: Average train loss: 0.0096\n",
      "Step 60: Average train loss: 0.0096\n",
      "Step 65: Average train loss: 0.0096\n",
      "Step 70: Average train loss: 0.0095\n",
      "Step 75: Average train loss: 0.0095\n",
      "Step 80: Average train loss: 0.0095\n",
      "Step 85: Average train loss: 0.0095\n",
      "Step 90: Average train loss: 0.0094\n",
      "Step 95: Average train loss: 0.0094\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 10573.5927734375\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0081\n",
      "Step 10: Average train loss: 0.0080\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0080\n",
      "Step 25: Average train loss: 0.0080\n",
      "Step 30: Average train loss: 0.0080\n",
      "Step 35: Average train loss: 0.0079\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 12707.326171875\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0077\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0075\n",
      "Step 85: Average train loss: 0.0075\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 21180.630859375\n",
      "Step 0: Average train loss: 0.0073\n",
      "Step 5: Average train loss: 0.0073\n",
      "Step 10: Average train loss: 0.0072\n",
      "Step 15: Average train loss: 0.0072\n",
      "Step 20: Average train loss: 0.0072\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0072\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 35223.64453125\n",
      "Step 0: Average train loss: 0.0073\n",
      "Step 5: Average train loss: 0.0073\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0073\n",
      "Step 20: Average train loss: 0.0073\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0072\n",
      "Step 40: Average train loss: 0.0072\n",
      "Step 45: Average train loss: 0.0072\n",
      "Step 50: Average train loss: 0.0072\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 31464.666015625\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', inv_limit=False, HP_tuning=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('PoA')\n",
    "    features.remove('T_PV')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "\n",
    "    rmse.loc[(1, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoA and T_PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 6]) torch.Size([140, 24, 6]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0502 | Average test loss: 0.0360\n",
      "Step 5: Average train loss: 0.0167 | Average test loss: 0.0148\n",
      "Step 10: Average train loss: 0.0121 | Average test loss: 0.0105\n",
      "Step 15: Average train loss: 0.0112 | Average test loss: 0.0110\n",
      "Step 20: Average train loss: 0.0109 | Average test loss: 0.0111\n",
      "Step 25: Average train loss: 0.0106 | Average test loss: 0.0106\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0104\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0103\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0102\n",
      "Step 45: Average train loss: 0.0103 | Average test loss: 0.0100\n",
      "Step 50: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 55: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 60: Average train loss: 0.0099 | Average test loss: 0.0103\n",
      "Step 65: Average train loss: 0.0099 | Average test loss: 0.0094\n",
      "Step 70: Average train loss: 0.0097 | Average test loss: 0.0091\n",
      "Step 75: Average train loss: 0.0096 | Average test loss: 0.0085\n",
      "Step 80: Average train loss: 0.0097 | Average test loss: 0.0090\n",
      "Step 85: Average train loss: 0.0096 | Average test loss: 0.0091\n",
      "Step 90: Average train loss: 0.0096 | Average test loss: 0.0094\n",
      "Step 95: Average train loss: 0.0095 | Average test loss: 0.0091\n",
      "Best Epoch: 75\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 65121.46484375\n",
      "Step 0: Average train loss: 0.0104\n",
      "Step 5: Average train loss: 0.0104\n",
      "Step 10: Average train loss: 0.0104\n",
      "Step 15: Average train loss: 0.0104\n",
      "Step 20: Average train loss: 0.0104\n",
      "Step 25: Average train loss: 0.0103\n",
      "Step 30: Average train loss: 0.0103\n",
      "Step 35: Average train loss: 0.0103\n",
      "Step 40: Average train loss: 0.0103\n",
      "Step 45: Average train loss: 0.0103\n",
      "Step 50: Average train loss: 0.0103\n",
      "Step 55: Average train loss: 0.0103\n",
      "Step 60: Average train loss: 0.0102\n",
      "Step 65: Average train loss: 0.0102\n",
      "Step 70: Average train loss: 0.0102\n",
      "Step 75: Average train loss: 0.0102\n",
      "Step 80: Average train loss: 0.0102\n",
      "Step 85: Average train loss: 0.0102\n",
      "Step 90: Average train loss: 0.0102\n",
      "Step 95: Average train loss: 0.0101\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 60707.51171875\n",
      "Step 0: Average train loss: 0.0101\n",
      "Step 5: Average train loss: 0.0101\n",
      "Step 10: Average train loss: 0.0101\n",
      "Step 15: Average train loss: 0.0101\n",
      "Step 20: Average train loss: 0.0101\n",
      "Step 25: Average train loss: 0.0101\n",
      "Step 30: Average train loss: 0.0100\n",
      "Step 35: Average train loss: 0.0100\n",
      "Step 40: Average train loss: 0.0100\n",
      "Step 45: Average train loss: 0.0100\n",
      "Step 50: Average train loss: 0.0100\n",
      "Step 55: Average train loss: 0.0100\n",
      "Step 60: Average train loss: 0.0099\n",
      "Step 65: Average train loss: 0.0099\n",
      "Step 70: Average train loss: 0.0099\n",
      "Step 75: Average train loss: 0.0099\n",
      "Step 80: Average train loss: 0.0099\n",
      "Step 85: Average train loss: 0.0099\n",
      "Step 90: Average train loss: 0.0099\n",
      "Step 95: Average train loss: 0.0099\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 47778.41796875\n",
      "Step 0: Average train loss: 0.0089\n",
      "Step 5: Average train loss: 0.0089\n",
      "Step 10: Average train loss: 0.0089\n",
      "Step 15: Average train loss: 0.0089\n",
      "Step 20: Average train loss: 0.0089\n",
      "Step 25: Average train loss: 0.0089\n",
      "Step 30: Average train loss: 0.0089\n",
      "Step 35: Average train loss: 0.0089\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0088\n",
      "Step 50: Average train loss: 0.0088\n",
      "Step 55: Average train loss: 0.0088\n",
      "Step 60: Average train loss: 0.0088\n",
      "Step 65: Average train loss: 0.0088\n",
      "Step 70: Average train loss: 0.0088\n",
      "Step 75: Average train loss: 0.0088\n",
      "Step 80: Average train loss: 0.0087\n",
      "Step 85: Average train loss: 0.0087\n",
      "Step 90: Average train loss: 0.0087\n",
      "Step 95: Average train loss: 0.0087\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50219.8671875\n",
      "Step 0: Average train loss: 0.0084\n",
      "Step 5: Average train loss: 0.0084\n",
      "Step 10: Average train loss: 0.0084\n",
      "Step 15: Average train loss: 0.0084\n",
      "Step 20: Average train loss: 0.0084\n",
      "Step 25: Average train loss: 0.0084\n",
      "Step 30: Average train loss: 0.0084\n",
      "Step 35: Average train loss: 0.0084\n",
      "Step 40: Average train loss: 0.0083\n",
      "Step 45: Average train loss: 0.0083\n",
      "Step 50: Average train loss: 0.0083\n",
      "Step 55: Average train loss: 0.0083\n",
      "Step 60: Average train loss: 0.0083\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0083\n",
      "Step 80: Average train loss: 0.0083\n",
      "Step 85: Average train loss: 0.0083\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 46789.765625\n",
      "Step 0: Average train loss: 0.0076\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0076\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0075\n",
      "Step 80: Average train loss: 0.0075\n",
      "Step 85: Average train loss: 0.0075\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 41911.16015625\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 28038.72265625\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 12810.890625\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 16887.2578125\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 39564.09375\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 57004.9765625\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 57737.48828125\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 74691.0390625\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 6]) torch.Size([140, 24, 6]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0478 | Average test loss: 0.0266\n",
      "Step 5: Average train loss: 0.0201 | Average test loss: 0.0214\n",
      "Step 10: Average train loss: 0.0103 | Average test loss: 0.0082\n",
      "Step 15: Average train loss: 0.0088 | Average test loss: 0.0070\n",
      "Step 20: Average train loss: 0.0086 | Average test loss: 0.0071\n",
      "Step 25: Average train loss: 0.0086 | Average test loss: 0.0075\n",
      "Step 30: Average train loss: 0.0085 | Average test loss: 0.0073\n",
      "Step 35: Average train loss: 0.0084 | Average test loss: 0.0071\n",
      "Step 40: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 45: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 50: Average train loss: 0.0083 | Average test loss: 0.0070\n",
      "Step 55: Average train loss: 0.0083 | Average test loss: 0.0070\n",
      "Step 60: Average train loss: 0.0082 | Average test loss: 0.0069\n",
      "Step 65: Average train loss: 0.0082 | Average test loss: 0.0069\n",
      "Step 70: Average train loss: 0.0082 | Average test loss: 0.0067\n",
      "Step 75: Average train loss: 0.0081 | Average test loss: 0.0068\n",
      "Step 80: Average train loss: 0.0080 | Average test loss: 0.0064\n",
      "Step 85: Average train loss: 0.0082 | Average test loss: 0.0070\n",
      "Step 90: Average train loss: 0.0080 | Average test loss: 0.0065\n",
      "Step 95: Average train loss: 0.0078 | Average test loss: 0.0064\n",
      "Best Epoch: 81\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 49173.5390625\n",
      "Step 0: Average train loss: 0.0103\n",
      "Step 5: Average train loss: 0.0103\n",
      "Step 10: Average train loss: 0.0103\n",
      "Step 15: Average train loss: 0.0102\n",
      "Step 20: Average train loss: 0.0102\n",
      "Step 25: Average train loss: 0.0102\n",
      "Step 30: Average train loss: 0.0102\n",
      "Step 35: Average train loss: 0.0102\n",
      "Step 40: Average train loss: 0.0101\n",
      "Step 45: Average train loss: 0.0101\n",
      "Step 50: Average train loss: 0.0101\n",
      "Step 55: Average train loss: 0.0101\n",
      "Step 60: Average train loss: 0.0100\n",
      "Step 65: Average train loss: 0.0100\n",
      "Step 70: Average train loss: 0.0100\n",
      "Step 75: Average train loss: 0.0100\n",
      "Step 80: Average train loss: 0.0100\n",
      "Step 85: Average train loss: 0.0099\n",
      "Step 90: Average train loss: 0.0099\n",
      "Step 95: Average train loss: 0.0099\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 40701.0625\n",
      "Step 0: Average train loss: 0.0090\n",
      "Step 5: Average train loss: 0.0090\n",
      "Step 10: Average train loss: 0.0089\n",
      "Step 15: Average train loss: 0.0089\n",
      "Step 20: Average train loss: 0.0089\n",
      "Step 25: Average train loss: 0.0089\n",
      "Step 30: Average train loss: 0.0088\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0088\n",
      "Step 50: Average train loss: 0.0087\n",
      "Step 55: Average train loss: 0.0087\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0086\n",
      "Step 75: Average train loss: 0.0086\n",
      "Step 80: Average train loss: 0.0086\n",
      "Step 85: Average train loss: 0.0086\n",
      "Step 90: Average train loss: 0.0085\n",
      "Step 95: Average train loss: 0.0085\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 45484.8125\n",
      "Step 0: Average train loss: 0.0090\n",
      "Step 5: Average train loss: 0.0089\n",
      "Step 10: Average train loss: 0.0089\n",
      "Step 15: Average train loss: 0.0089\n",
      "Step 20: Average train loss: 0.0089\n",
      "Step 25: Average train loss: 0.0088\n",
      "Step 30: Average train loss: 0.0088\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0088\n",
      "Step 50: Average train loss: 0.0087\n",
      "Step 55: Average train loss: 0.0087\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0087\n",
      "Step 80: Average train loss: 0.0086\n",
      "Step 85: Average train loss: 0.0086\n",
      "Step 90: Average train loss: 0.0086\n",
      "Step 95: Average train loss: 0.0086\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 30598.328125\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 34212.140625\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0075\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0074\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 24337.439453125\n",
      "Step 0: Average train loss: 0.0072\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 13900.984375\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9998.7041015625\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0053\n",
      "Step 80: Average train loss: 0.0053\n",
      "Step 85: Average train loss: 0.0053\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 12317.9052734375\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 15190.595703125\n",
      "Step 0: Average train loss: 0.0052\n",
      "Step 5: Average train loss: 0.0052\n",
      "Step 10: Average train loss: 0.0052\n",
      "Step 15: Average train loss: 0.0052\n",
      "Step 20: Average train loss: 0.0052\n",
      "Step 25: Average train loss: 0.0052\n",
      "Step 30: Average train loss: 0.0052\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0052\n",
      "Step 55: Average train loss: 0.0052\n",
      "Step 60: Average train loss: 0.0052\n",
      "Step 65: Average train loss: 0.0052\n",
      "Step 70: Average train loss: 0.0051\n",
      "Step 75: Average train loss: 0.0051\n",
      "Step 80: Average train loss: 0.0051\n",
      "Step 85: Average train loss: 0.0051\n",
      "Step 90: Average train loss: 0.0051\n",
      "Step 95: Average train loss: 0.0051\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 43903.515625\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0063\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 37544.5390625\n",
      "Step 0: Average train loss: 0.0058\n",
      "Step 5: Average train loss: 0.0058\n",
      "Step 10: Average train loss: 0.0058\n",
      "Step 15: Average train loss: 0.0058\n",
      "Step 20: Average train loss: 0.0058\n",
      "Step 25: Average train loss: 0.0058\n",
      "Step 30: Average train loss: 0.0058\n",
      "Step 35: Average train loss: 0.0058\n",
      "Step 40: Average train loss: 0.0058\n",
      "Step 45: Average train loss: 0.0058\n",
      "Step 50: Average train loss: 0.0058\n",
      "Step 55: Average train loss: 0.0058\n",
      "Step 60: Average train loss: 0.0058\n",
      "Step 65: Average train loss: 0.0058\n",
      "Step 70: Average train loss: 0.0058\n",
      "Step 75: Average train loss: 0.0058\n",
      "Step 80: Average train loss: 0.0058\n",
      "Step 85: Average train loss: 0.0058\n",
      "Step 90: Average train loss: 0.0058\n",
      "Step 95: Average train loss: 0.0058\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 30423.712890625\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 6]) torch.Size([144, 24, 6]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0483 | Average test loss: 0.0271\n",
      "Step 5: Average train loss: 0.0063 | Average test loss: 0.0102\n",
      "Step 10: Average train loss: 0.0059 | Average test loss: 0.0031\n",
      "Step 15: Average train loss: 0.0058 | Average test loss: 0.0018\n",
      "Step 20: Average train loss: 0.0054 | Average test loss: 0.0019\n",
      "Step 25: Average train loss: 0.0052 | Average test loss: 0.0019\n",
      "Step 30: Average train loss: 0.0052 | Average test loss: 0.0020\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0020\n",
      "Step 40: Average train loss: 0.0051 | Average test loss: 0.0021\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0022\n",
      "Step 55: Average train loss: 0.0049 | Average test loss: 0.0019\n",
      "Step 60: Average train loss: 0.0049 | Average test loss: 0.0022\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0019\n",
      "Step 70: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 75: Average train loss: 0.0049 | Average test loss: 0.0019\n",
      "Step 80: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 85: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 90: Average train loss: 0.0049 | Average test loss: 0.0024\n",
      "Step 95: Average train loss: 0.0048 | Average test loss: 0.0020\n",
      "Best Epoch: 13\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 306571.125\n",
      "Step 0: Average train loss: 0.0162\n",
      "Step 5: Average train loss: 0.0162\n",
      "Step 10: Average train loss: 0.0162\n",
      "Step 15: Average train loss: 0.0162\n",
      "Step 20: Average train loss: 0.0162\n",
      "Step 25: Average train loss: 0.0162\n",
      "Step 30: Average train loss: 0.0162\n",
      "Step 35: Average train loss: 0.0162\n",
      "Step 40: Average train loss: 0.0162\n",
      "Step 45: Average train loss: 0.0162\n",
      "Step 50: Average train loss: 0.0162\n",
      "Step 55: Average train loss: 0.0161\n",
      "Step 60: Average train loss: 0.0161\n",
      "Step 65: Average train loss: 0.0161\n",
      "Step 70: Average train loss: 0.0161\n",
      "Step 75: Average train loss: 0.0161\n",
      "Step 80: Average train loss: 0.0161\n",
      "Step 85: Average train loss: 0.0161\n",
      "Step 90: Average train loss: 0.0161\n",
      "Step 95: Average train loss: 0.0161\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 300408.25\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0158\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0156\n",
      "Step 70: Average train loss: 0.0156\n",
      "Step 75: Average train loss: 0.0156\n",
      "Step 80: Average train loss: 0.0156\n",
      "Step 85: Average train loss: 0.0156\n",
      "Step 90: Average train loss: 0.0156\n",
      "Step 95: Average train loss: 0.0156\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 251054.671875\n",
      "Step 0: Average train loss: 0.0149\n",
      "Step 5: Average train loss: 0.0149\n",
      "Step 10: Average train loss: 0.0149\n",
      "Step 15: Average train loss: 0.0149\n",
      "Step 20: Average train loss: 0.0149\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0148\n",
      "Step 50: Average train loss: 0.0148\n",
      "Step 55: Average train loss: 0.0148\n",
      "Step 60: Average train loss: 0.0148\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0148\n",
      "Step 90: Average train loss: 0.0148\n",
      "Step 95: Average train loss: 0.0148\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 289657.5\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0150\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0149\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0149\n",
      "Step 50: Average train loss: 0.0149\n",
      "Step 55: Average train loss: 0.0149\n",
      "Step 60: Average train loss: 0.0148\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0148\n",
      "Step 90: Average train loss: 0.0148\n",
      "Step 95: Average train loss: 0.0148\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 286878.96875\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 303970.34375\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0148\n",
      "Step 25: Average train loss: 0.0148\n",
      "Step 30: Average train loss: 0.0148\n",
      "Step 35: Average train loss: 0.0148\n",
      "Step 40: Average train loss: 0.0148\n",
      "Step 45: Average train loss: 0.0148\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0147\n",
      "Step 75: Average train loss: 0.0147\n",
      "Step 80: Average train loss: 0.0147\n",
      "Step 85: Average train loss: 0.0147\n",
      "Step 90: Average train loss: 0.0147\n",
      "Step 95: Average train loss: 0.0147\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 204246.4375\n",
      "Step 0: Average train loss: 0.0138\n",
      "Step 5: Average train loss: 0.0138\n",
      "Step 10: Average train loss: 0.0138\n",
      "Step 15: Average train loss: 0.0138\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0137\n",
      "Step 35: Average train loss: 0.0137\n",
      "Step 40: Average train loss: 0.0137\n",
      "Step 45: Average train loss: 0.0137\n",
      "Step 50: Average train loss: 0.0137\n",
      "Step 55: Average train loss: 0.0137\n",
      "Step 60: Average train loss: 0.0137\n",
      "Step 65: Average train loss: 0.0137\n",
      "Step 70: Average train loss: 0.0137\n",
      "Step 75: Average train loss: 0.0137\n",
      "Step 80: Average train loss: 0.0137\n",
      "Step 85: Average train loss: 0.0137\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 293747.59375\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0140\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 302634.9375\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0142\n",
      "Step 35: Average train loss: 0.0142\n",
      "Step 40: Average train loss: 0.0142\n",
      "Step 45: Average train loss: 0.0142\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0141\n",
      "Step 85: Average train loss: 0.0141\n",
      "Step 90: Average train loss: 0.0141\n",
      "Step 95: Average train loss: 0.0141\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 399369.125\n",
      "Step 0: Average train loss: 0.0153\n",
      "Step 5: Average train loss: 0.0152\n",
      "Step 10: Average train loss: 0.0152\n",
      "Step 15: Average train loss: 0.0152\n",
      "Step 20: Average train loss: 0.0152\n",
      "Step 25: Average train loss: 0.0152\n",
      "Step 30: Average train loss: 0.0152\n",
      "Step 35: Average train loss: 0.0152\n",
      "Step 40: Average train loss: 0.0152\n",
      "Step 45: Average train loss: 0.0152\n",
      "Step 50: Average train loss: 0.0152\n",
      "Step 55: Average train loss: 0.0152\n",
      "Step 60: Average train loss: 0.0152\n",
      "Step 65: Average train loss: 0.0152\n",
      "Step 70: Average train loss: 0.0152\n",
      "Step 75: Average train loss: 0.0151\n",
      "Step 80: Average train loss: 0.0151\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 415529.0625\n",
      "Step 0: Average train loss: 0.0162\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0161\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0161\n",
      "Step 30: Average train loss: 0.0161\n",
      "Step 35: Average train loss: 0.0161\n",
      "Step 40: Average train loss: 0.0161\n",
      "Step 45: Average train loss: 0.0161\n",
      "Step 50: Average train loss: 0.0161\n",
      "Step 55: Average train loss: 0.0161\n",
      "Step 60: Average train loss: 0.0161\n",
      "Step 65: Average train loss: 0.0161\n",
      "Step 70: Average train loss: 0.0161\n",
      "Step 75: Average train loss: 0.0161\n",
      "Step 80: Average train loss: 0.0161\n",
      "Step 85: Average train loss: 0.0161\n",
      "Step 90: Average train loss: 0.0161\n",
      "Step 95: Average train loss: 0.0161\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 389066.65625\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0158\n",
      "Step 20: Average train loss: 0.0158\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0158\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0157\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0157\n",
      "Step 80: Average train loss: 0.0157\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 612766.3125\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 6]) torch.Size([140, 24, 6]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0427 | Average test loss: 0.0247\n",
      "Step 5: Average train loss: 0.0144 | Average test loss: 0.0120\n",
      "Step 10: Average train loss: 0.0118 | Average test loss: 0.0096\n",
      "Step 15: Average train loss: 0.0097 | Average test loss: 0.0087\n",
      "Step 20: Average train loss: 0.0095 | Average test loss: 0.0083\n",
      "Step 25: Average train loss: 0.0094 | Average test loss: 0.0082\n",
      "Step 30: Average train loss: 0.0093 | Average test loss: 0.0081\n",
      "Step 35: Average train loss: 0.0092 | Average test loss: 0.0081\n",
      "Step 40: Average train loss: 0.0091 | Average test loss: 0.0080\n",
      "Step 45: Average train loss: 0.0090 | Average test loss: 0.0080\n",
      "Step 50: Average train loss: 0.0089 | Average test loss: 0.0080\n",
      "Step 55: Average train loss: 0.0090 | Average test loss: 0.0086\n",
      "Step 60: Average train loss: 0.0098 | Average test loss: 0.0080\n",
      "Step 65: Average train loss: 0.0114 | Average test loss: 0.0107\n",
      "Step 70: Average train loss: 0.0091 | Average test loss: 0.0081\n",
      "Step 75: Average train loss: 0.0097 | Average test loss: 0.0090\n",
      "Step 80: Average train loss: 0.0090 | Average test loss: 0.0083\n",
      "Step 85: Average train loss: 0.0093 | Average test loss: 0.0085\n",
      "Step 90: Average train loss: 0.0094 | Average test loss: 0.0089\n",
      "Step 95: Average train loss: 0.0093 | Average test loss: 0.0087\n",
      "Best Epoch: 98\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 59892.45703125\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0157\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0156\n",
      "Step 45: Average train loss: 0.0156\n",
      "Step 50: Average train loss: 0.0156\n",
      "Step 55: Average train loss: 0.0156\n",
      "Step 60: Average train loss: 0.0156\n",
      "Step 65: Average train loss: 0.0155\n",
      "Step 70: Average train loss: 0.0155\n",
      "Step 75: Average train loss: 0.0155\n",
      "Step 80: Average train loss: 0.0155\n",
      "Step 85: Average train loss: 0.0155\n",
      "Step 90: Average train loss: 0.0154\n",
      "Step 95: Average train loss: 0.0154\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 67705.421875\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0156\n",
      "Step 20: Average train loss: 0.0156\n",
      "Step 25: Average train loss: 0.0156\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0155\n",
      "Step 45: Average train loss: 0.0154\n",
      "Step 50: Average train loss: 0.0154\n",
      "Step 55: Average train loss: 0.0154\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0153\n",
      "Step 75: Average train loss: 0.0152\n",
      "Step 80: Average train loss: 0.0152\n",
      "Step 85: Average train loss: 0.0152\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 51186.62890625\n",
      "Step 0: Average train loss: 0.0151\n",
      "Step 5: Average train loss: 0.0151\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0150\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0148\n",
      "Step 50: Average train loss: 0.0148\n",
      "Step 55: Average train loss: 0.0148\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0147\n",
      "Step 75: Average train loss: 0.0147\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 42607.73828125\n",
      "Step 0: Average train loss: 0.0134\n",
      "Step 5: Average train loss: 0.0134\n",
      "Step 10: Average train loss: 0.0133\n",
      "Step 15: Average train loss: 0.0133\n",
      "Step 20: Average train loss: 0.0132\n",
      "Step 25: Average train loss: 0.0132\n",
      "Step 30: Average train loss: 0.0132\n",
      "Step 35: Average train loss: 0.0131\n",
      "Step 40: Average train loss: 0.0131\n",
      "Step 45: Average train loss: 0.0131\n",
      "Step 50: Average train loss: 0.0130\n",
      "Step 55: Average train loss: 0.0130\n",
      "Step 60: Average train loss: 0.0129\n",
      "Step 65: Average train loss: 0.0129\n",
      "Step 70: Average train loss: 0.0129\n",
      "Step 75: Average train loss: 0.0128\n",
      "Step 80: Average train loss: 0.0128\n",
      "Step 85: Average train loss: 0.0128\n",
      "Step 90: Average train loss: 0.0127\n",
      "Step 95: Average train loss: 0.0127\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 28556.330078125\n",
      "Step 0: Average train loss: 0.0110\n",
      "Step 5: Average train loss: 0.0109\n",
      "Step 10: Average train loss: 0.0109\n",
      "Step 15: Average train loss: 0.0109\n",
      "Step 20: Average train loss: 0.0108\n",
      "Step 25: Average train loss: 0.0108\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0107\n",
      "Step 40: Average train loss: 0.0107\n",
      "Step 45: Average train loss: 0.0106\n",
      "Step 50: Average train loss: 0.0106\n",
      "Step 55: Average train loss: 0.0106\n",
      "Step 60: Average train loss: 0.0105\n",
      "Step 65: Average train loss: 0.0105\n",
      "Step 70: Average train loss: 0.0105\n",
      "Step 75: Average train loss: 0.0104\n",
      "Step 80: Average train loss: 0.0104\n",
      "Step 85: Average train loss: 0.0104\n",
      "Step 90: Average train loss: 0.0104\n",
      "Step 95: Average train loss: 0.0103\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 29851.75\n",
      "Step 0: Average train loss: 0.0105\n",
      "Step 5: Average train loss: 0.0105\n",
      "Step 10: Average train loss: 0.0104\n",
      "Step 15: Average train loss: 0.0104\n",
      "Step 20: Average train loss: 0.0104\n",
      "Step 25: Average train loss: 0.0104\n",
      "Step 30: Average train loss: 0.0103\n",
      "Step 35: Average train loss: 0.0103\n",
      "Step 40: Average train loss: 0.0103\n",
      "Step 45: Average train loss: 0.0102\n",
      "Step 50: Average train loss: 0.0102\n",
      "Step 55: Average train loss: 0.0102\n",
      "Step 60: Average train loss: 0.0102\n",
      "Step 65: Average train loss: 0.0101\n",
      "Step 70: Average train loss: 0.0101\n",
      "Step 75: Average train loss: 0.0101\n",
      "Step 80: Average train loss: 0.0100\n",
      "Step 85: Average train loss: 0.0100\n",
      "Step 90: Average train loss: 0.0100\n",
      "Step 95: Average train loss: 0.0100\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 22370.19921875\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0089\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0089\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0088\n",
      "Step 80: Average train loss: 0.0088\n",
      "Step 85: Average train loss: 0.0088\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0088\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 13773.912109375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0077\n",
      "Step 10: Average train loss: 0.0077\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0075\n",
      "Step 50: Average train loss: 0.0075\n",
      "Step 55: Average train loss: 0.0075\n",
      "Step 60: Average train loss: 0.0075\n",
      "Step 65: Average train loss: 0.0075\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 15308.544921875\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0073\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0072\n",
      "Step 75: Average train loss: 0.0072\n",
      "Step 80: Average train loss: 0.0072\n",
      "Step 85: Average train loss: 0.0072\n",
      "Step 90: Average train loss: 0.0072\n",
      "Step 95: Average train loss: 0.0072\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 22455.482421875\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 33639.64453125\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 29930.21875\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', HP_tuning=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('PoA')\n",
    "    features.remove('T_PV')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "\n",
    "    rmse.loc[(2, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 7]) torch.Size([140, 24, 7]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0582 | Average test loss: 0.0355\n",
      "Step 5: Average train loss: 0.0167 | Average test loss: 0.0139\n",
      "Step 10: Average train loss: 0.0135 | Average test loss: 0.0101\n",
      "Step 15: Average train loss: 0.0111 | Average test loss: 0.0105\n",
      "Step 20: Average train loss: 0.0108 | Average test loss: 0.0105\n",
      "Step 25: Average train loss: 0.0106 | Average test loss: 0.0105\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0103\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0101\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0100\n",
      "Step 45: Average train loss: 0.0103 | Average test loss: 0.0099\n",
      "Step 50: Average train loss: 0.0102 | Average test loss: 0.0098\n",
      "Step 55: Average train loss: 0.0100 | Average test loss: 0.0095\n",
      "Step 60: Average train loss: 0.0098 | Average test loss: 0.0096\n",
      "Step 65: Average train loss: 0.0097 | Average test loss: 0.0092\n",
      "Step 70: Average train loss: 0.0095 | Average test loss: 0.0092\n",
      "Step 75: Average train loss: 0.0097 | Average test loss: 0.0093\n",
      "Step 80: Average train loss: 0.0094 | Average test loss: 0.0089\n",
      "Step 85: Average train loss: 0.0095 | Average test loss: 0.0091\n",
      "Step 90: Average train loss: 0.0093 | Average test loss: 0.0089\n",
      "Step 95: Average train loss: 0.0094 | Average test loss: 0.0091\n",
      "Best Epoch: 98\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 70489.6171875\n",
      "Step 0: Average train loss: 0.0113\n",
      "Step 5: Average train loss: 0.0113\n",
      "Step 10: Average train loss: 0.0112\n",
      "Step 15: Average train loss: 0.0112\n",
      "Step 20: Average train loss: 0.0112\n",
      "Step 25: Average train loss: 0.0112\n",
      "Step 30: Average train loss: 0.0112\n",
      "Step 35: Average train loss: 0.0111\n",
      "Step 40: Average train loss: 0.0111\n",
      "Step 45: Average train loss: 0.0111\n",
      "Step 50: Average train loss: 0.0111\n",
      "Step 55: Average train loss: 0.0111\n",
      "Step 60: Average train loss: 0.0111\n",
      "Step 65: Average train loss: 0.0110\n",
      "Step 70: Average train loss: 0.0110\n",
      "Step 75: Average train loss: 0.0110\n",
      "Step 80: Average train loss: 0.0110\n",
      "Step 85: Average train loss: 0.0110\n",
      "Step 90: Average train loss: 0.0110\n",
      "Step 95: Average train loss: 0.0109\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 61228.1015625\n",
      "Step 0: Average train loss: 0.0104\n",
      "Step 5: Average train loss: 0.0103\n",
      "Step 10: Average train loss: 0.0103\n",
      "Step 15: Average train loss: 0.0103\n",
      "Step 20: Average train loss: 0.0103\n",
      "Step 25: Average train loss: 0.0103\n",
      "Step 30: Average train loss: 0.0102\n",
      "Step 35: Average train loss: 0.0102\n",
      "Step 40: Average train loss: 0.0102\n",
      "Step 45: Average train loss: 0.0102\n",
      "Step 50: Average train loss: 0.0102\n",
      "Step 55: Average train loss: 0.0101\n",
      "Step 60: Average train loss: 0.0101\n",
      "Step 65: Average train loss: 0.0101\n",
      "Step 70: Average train loss: 0.0101\n",
      "Step 75: Average train loss: 0.0101\n",
      "Step 80: Average train loss: 0.0101\n",
      "Step 85: Average train loss: 0.0100\n",
      "Step 90: Average train loss: 0.0100\n",
      "Step 95: Average train loss: 0.0100\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 47653.08203125\n",
      "Step 0: Average train loss: 0.0092\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0091\n",
      "Step 30: Average train loss: 0.0091\n",
      "Step 35: Average train loss: 0.0091\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0090\n",
      "Step 70: Average train loss: 0.0090\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 52169.5234375\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0086\n",
      "Step 10: Average train loss: 0.0086\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0086\n",
      "Step 40: Average train loss: 0.0086\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0085\n",
      "Step 70: Average train loss: 0.0085\n",
      "Step 75: Average train loss: 0.0085\n",
      "Step 80: Average train loss: 0.0085\n",
      "Step 85: Average train loss: 0.0085\n",
      "Step 90: Average train loss: 0.0084\n",
      "Step 95: Average train loss: 0.0084\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 48340.33984375\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 41589.07421875\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0079\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0079\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0079\n",
      "Step 35: Average train loss: 0.0079\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0079\n",
      "Step 75: Average train loss: 0.0079\n",
      "Step 80: Average train loss: 0.0079\n",
      "Step 85: Average train loss: 0.0079\n",
      "Step 90: Average train loss: 0.0079\n",
      "Step 95: Average train loss: 0.0079\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 26886.84375\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 13400.15234375\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 17499.044921875\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 37548.1015625\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 57938.01171875\n",
      "Step 0: Average train loss: 0.0069\n",
      "Step 5: Average train loss: 0.0069\n",
      "Step 10: Average train loss: 0.0069\n",
      "Step 15: Average train loss: 0.0069\n",
      "Step 20: Average train loss: 0.0069\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 57415.37109375\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 83680.3046875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 7]) torch.Size([140, 24, 7]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0471 | Average test loss: 0.0253\n",
      "Step 5: Average train loss: 0.0106 | Average test loss: 0.0091\n",
      "Step 10: Average train loss: 0.0093 | Average test loss: 0.0081\n",
      "Step 15: Average train loss: 0.0089 | Average test loss: 0.0077\n",
      "Step 20: Average train loss: 0.0087 | Average test loss: 0.0080\n",
      "Step 25: Average train loss: 0.0087 | Average test loss: 0.0079\n",
      "Step 30: Average train loss: 0.0086 | Average test loss: 0.0074\n",
      "Step 35: Average train loss: 0.0084 | Average test loss: 0.0070\n",
      "Step 40: Average train loss: 0.0083 | Average test loss: 0.0067\n",
      "Step 45: Average train loss: 0.0082 | Average test loss: 0.0066\n",
      "Step 50: Average train loss: 0.0080 | Average test loss: 0.0068\n",
      "Step 55: Average train loss: 0.0080 | Average test loss: 0.0067\n",
      "Step 60: Average train loss: 0.0079 | Average test loss: 0.0064\n",
      "Step 65: Average train loss: 0.0079 | Average test loss: 0.0064\n",
      "Step 70: Average train loss: 0.0077 | Average test loss: 0.0064\n",
      "Step 75: Average train loss: 0.0076 | Average test loss: 0.0066\n",
      "Step 80: Average train loss: 0.0078 | Average test loss: 0.0066\n",
      "Step 85: Average train loss: 0.0076 | Average test loss: 0.0064\n",
      "Step 90: Average train loss: 0.0075 | Average test loss: 0.0066\n",
      "Step 95: Average train loss: 0.0075 | Average test loss: 0.0064\n",
      "Best Epoch: 74\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 52402.47265625\n",
      "Step 0: Average train loss: 0.0110\n",
      "Step 5: Average train loss: 0.0110\n",
      "Step 10: Average train loss: 0.0109\n",
      "Step 15: Average train loss: 0.0109\n",
      "Step 20: Average train loss: 0.0109\n",
      "Step 25: Average train loss: 0.0109\n",
      "Step 30: Average train loss: 0.0109\n",
      "Step 35: Average train loss: 0.0108\n",
      "Step 40: Average train loss: 0.0108\n",
      "Step 45: Average train loss: 0.0108\n",
      "Step 50: Average train loss: 0.0108\n",
      "Step 55: Average train loss: 0.0107\n",
      "Step 60: Average train loss: 0.0107\n",
      "Step 65: Average train loss: 0.0107\n",
      "Step 70: Average train loss: 0.0107\n",
      "Step 75: Average train loss: 0.0107\n",
      "Step 80: Average train loss: 0.0106\n",
      "Step 85: Average train loss: 0.0106\n",
      "Step 90: Average train loss: 0.0106\n",
      "Step 95: Average train loss: 0.0106\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 41836.0234375\n",
      "Step 0: Average train loss: 0.0094\n",
      "Step 5: Average train loss: 0.0094\n",
      "Step 10: Average train loss: 0.0094\n",
      "Step 15: Average train loss: 0.0093\n",
      "Step 20: Average train loss: 0.0093\n",
      "Step 25: Average train loss: 0.0093\n",
      "Step 30: Average train loss: 0.0093\n",
      "Step 35: Average train loss: 0.0092\n",
      "Step 40: Average train loss: 0.0092\n",
      "Step 45: Average train loss: 0.0092\n",
      "Step 50: Average train loss: 0.0092\n",
      "Step 55: Average train loss: 0.0091\n",
      "Step 60: Average train loss: 0.0091\n",
      "Step 65: Average train loss: 0.0091\n",
      "Step 70: Average train loss: 0.0091\n",
      "Step 75: Average train loss: 0.0090\n",
      "Step 80: Average train loss: 0.0090\n",
      "Step 85: Average train loss: 0.0090\n",
      "Step 90: Average train loss: 0.0090\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 48874.79296875\n",
      "Step 0: Average train loss: 0.0095\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0095\n",
      "Step 15: Average train loss: 0.0094\n",
      "Step 20: Average train loss: 0.0094\n",
      "Step 25: Average train loss: 0.0094\n",
      "Step 30: Average train loss: 0.0094\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0093\n",
      "Step 45: Average train loss: 0.0093\n",
      "Step 50: Average train loss: 0.0093\n",
      "Step 55: Average train loss: 0.0093\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0092\n",
      "Step 75: Average train loss: 0.0092\n",
      "Step 80: Average train loss: 0.0092\n",
      "Step 85: Average train loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092\n",
      "Step 95: Average train loss: 0.0091\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 32717.755859375\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0083\n",
      "Step 20: Average train loss: 0.0083\n",
      "Step 25: Average train loss: 0.0083\n",
      "Step 30: Average train loss: 0.0082\n",
      "Step 35: Average train loss: 0.0082\n",
      "Step 40: Average train loss: 0.0082\n",
      "Step 45: Average train loss: 0.0082\n",
      "Step 50: Average train loss: 0.0082\n",
      "Step 55: Average train loss: 0.0082\n",
      "Step 60: Average train loss: 0.0082\n",
      "Step 65: Average train loss: 0.0082\n",
      "Step 70: Average train loss: 0.0081\n",
      "Step 75: Average train loss: 0.0081\n",
      "Step 80: Average train loss: 0.0081\n",
      "Step 85: Average train loss: 0.0081\n",
      "Step 90: Average train loss: 0.0081\n",
      "Step 95: Average train loss: 0.0081\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 36975.94921875\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0079\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23023.990234375\n",
      "Step 0: Average train loss: 0.0074\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0073\n",
      "Step 20: Average train loss: 0.0073\n",
      "Step 25: Average train loss: 0.0073\n",
      "Step 30: Average train loss: 0.0073\n",
      "Step 35: Average train loss: 0.0073\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 12684.0400390625\n",
      "Step 0: Average train loss: 0.0063\n",
      "Step 5: Average train loss: 0.0063\n",
      "Step 10: Average train loss: 0.0063\n",
      "Step 15: Average train loss: 0.0063\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0063\n",
      "Step 55: Average train loss: 0.0063\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 10263.8603515625\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 12477.671875\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 16684.40234375\n",
      "Step 0: Average train loss: 0.0053\n",
      "Step 5: Average train loss: 0.0053\n",
      "Step 10: Average train loss: 0.0053\n",
      "Step 15: Average train loss: 0.0053\n",
      "Step 20: Average train loss: 0.0053\n",
      "Step 25: Average train loss: 0.0053\n",
      "Step 30: Average train loss: 0.0053\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0052\n",
      "Step 55: Average train loss: 0.0052\n",
      "Step 60: Average train loss: 0.0052\n",
      "Step 65: Average train loss: 0.0052\n",
      "Step 70: Average train loss: 0.0052\n",
      "Step 75: Average train loss: 0.0052\n",
      "Step 80: Average train loss: 0.0052\n",
      "Step 85: Average train loss: 0.0052\n",
      "Step 90: Average train loss: 0.0052\n",
      "Step 95: Average train loss: 0.0052\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 44879.12890625\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 37429.54296875\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 34441.1875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 7]) torch.Size([144, 24, 7]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0426 | Average test loss: 0.0314\n",
      "Step 5: Average train loss: 0.0079 | Average test loss: 0.0034\n",
      "Step 10: Average train loss: 0.0063 | Average test loss: 0.0018\n",
      "Step 15: Average train loss: 0.0056 | Average test loss: 0.0017\n",
      "Step 20: Average train loss: 0.0054 | Average test loss: 0.0017\n",
      "Step 25: Average train loss: 0.0053 | Average test loss: 0.0017\n",
      "Step 30: Average train loss: 0.0052 | Average test loss: 0.0018\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0019\n",
      "Step 40: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 50: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 55: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 60: Average train loss: 0.0049 | Average test loss: 0.0022\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 70: Average train loss: 0.0048 | Average test loss: 0.0023\n",
      "Step 75: Average train loss: 0.0048 | Average test loss: 0.0021\n",
      "Step 80: Average train loss: 0.0048 | Average test loss: 0.0025\n",
      "Step 85: Average train loss: 0.0047 | Average test loss: 0.0022\n",
      "Step 90: Average train loss: 0.0047 | Average test loss: 0.0026\n",
      "Step 95: Average train loss: 0.0047 | Average test loss: 0.0023\n",
      "Best Epoch: 15\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 304230.96875\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0161\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0161\n",
      "Step 30: Average train loss: 0.0161\n",
      "Step 35: Average train loss: 0.0160\n",
      "Step 40: Average train loss: 0.0160\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0160\n",
      "Step 90: Average train loss: 0.0160\n",
      "Step 95: Average train loss: 0.0160\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 300503.875\n",
      "Step 0: Average train loss: 0.0159\n",
      "Step 5: Average train loss: 0.0159\n",
      "Step 10: Average train loss: 0.0159\n",
      "Step 15: Average train loss: 0.0159\n",
      "Step 20: Average train loss: 0.0159\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0158\n",
      "Step 45: Average train loss: 0.0158\n",
      "Step 50: Average train loss: 0.0158\n",
      "Step 55: Average train loss: 0.0158\n",
      "Step 60: Average train loss: 0.0158\n",
      "Step 65: Average train loss: 0.0158\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0157\n",
      "Step 80: Average train loss: 0.0157\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 260581.46875\n",
      "Step 0: Average train loss: 0.0151\n",
      "Step 5: Average train loss: 0.0151\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0150\n",
      "Step 25: Average train loss: 0.0150\n",
      "Step 30: Average train loss: 0.0150\n",
      "Step 35: Average train loss: 0.0150\n",
      "Step 40: Average train loss: 0.0150\n",
      "Step 45: Average train loss: 0.0150\n",
      "Step 50: Average train loss: 0.0150\n",
      "Step 55: Average train loss: 0.0149\n",
      "Step 60: Average train loss: 0.0149\n",
      "Step 65: Average train loss: 0.0149\n",
      "Step 70: Average train loss: 0.0149\n",
      "Step 75: Average train loss: 0.0149\n",
      "Step 80: Average train loss: 0.0149\n",
      "Step 85: Average train loss: 0.0149\n",
      "Step 90: Average train loss: 0.0149\n",
      "Step 95: Average train loss: 0.0149\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 287579.1875\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0150\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0150\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0149\n",
      "Step 50: Average train loss: 0.0149\n",
      "Step 55: Average train loss: 0.0149\n",
      "Step 60: Average train loss: 0.0149\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0148\n",
      "Step 90: Average train loss: 0.0148\n",
      "Step 95: Average train loss: 0.0148\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 285062.6875\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 300325.0625\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0148\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0147\n",
      "Step 75: Average train loss: 0.0147\n",
      "Step 80: Average train loss: 0.0147\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 200287.890625\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0137\n",
      "Step 35: Average train loss: 0.0137\n",
      "Step 40: Average train loss: 0.0136\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 291307.28125\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 298809.03125\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 403849.6875\n",
      "Step 0: Average train loss: 0.0152\n",
      "Step 5: Average train loss: 0.0152\n",
      "Step 10: Average train loss: 0.0152\n",
      "Step 15: Average train loss: 0.0152\n",
      "Step 20: Average train loss: 0.0152\n",
      "Step 25: Average train loss: 0.0152\n",
      "Step 30: Average train loss: 0.0152\n",
      "Step 35: Average train loss: 0.0152\n",
      "Step 40: Average train loss: 0.0152\n",
      "Step 45: Average train loss: 0.0152\n",
      "Step 50: Average train loss: 0.0152\n",
      "Step 55: Average train loss: 0.0151\n",
      "Step 60: Average train loss: 0.0151\n",
      "Step 65: Average train loss: 0.0151\n",
      "Step 70: Average train loss: 0.0151\n",
      "Step 75: Average train loss: 0.0151\n",
      "Step 80: Average train loss: 0.0151\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 418352.3125\n",
      "Step 0: Average train loss: 0.0162\n",
      "Step 5: Average train loss: 0.0162\n",
      "Step 10: Average train loss: 0.0162\n",
      "Step 15: Average train loss: 0.0162\n",
      "Step 20: Average train loss: 0.0162\n",
      "Step 25: Average train loss: 0.0162\n",
      "Step 30: Average train loss: 0.0162\n",
      "Step 35: Average train loss: 0.0162\n",
      "Step 40: Average train loss: 0.0162\n",
      "Step 45: Average train loss: 0.0162\n",
      "Step 50: Average train loss: 0.0162\n",
      "Step 55: Average train loss: 0.0161\n",
      "Step 60: Average train loss: 0.0161\n",
      "Step 65: Average train loss: 0.0161\n",
      "Step 70: Average train loss: 0.0161\n",
      "Step 75: Average train loss: 0.0161\n",
      "Step 80: Average train loss: 0.0161\n",
      "Step 85: Average train loss: 0.0161\n",
      "Step 90: Average train loss: 0.0161\n",
      "Step 95: Average train loss: 0.0161\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 383605.0625\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0157\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0157\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0157\n",
      "Step 80: Average train loss: 0.0157\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 554841.4375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 7]) torch.Size([140, 24, 7]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0414 | Average test loss: 0.0250\n",
      "Step 5: Average train loss: 0.0181 | Average test loss: 0.0210\n",
      "Step 10: Average train loss: 0.0103 | Average test loss: 0.0095\n",
      "Step 15: Average train loss: 0.0103 | Average test loss: 0.0091\n",
      "Step 20: Average train loss: 0.0099 | Average test loss: 0.0087\n",
      "Step 25: Average train loss: 0.0096 | Average test loss: 0.0085\n",
      "Step 30: Average train loss: 0.0094 | Average test loss: 0.0082\n",
      "Step 35: Average train loss: 0.0093 | Average test loss: 0.0082\n",
      "Step 40: Average train loss: 0.0092 | Average test loss: 0.0081\n",
      "Step 45: Average train loss: 0.0091 | Average test loss: 0.0082\n",
      "Step 50: Average train loss: 0.0091 | Average test loss: 0.0080\n",
      "Step 55: Average train loss: 0.0089 | Average test loss: 0.0077\n",
      "Step 60: Average train loss: 0.0089 | Average test loss: 0.0079\n",
      "Step 65: Average train loss: 0.0088 | Average test loss: 0.0079\n",
      "Step 70: Average train loss: 0.0087 | Average test loss: 0.0080\n",
      "Step 75: Average train loss: 0.0106 | Average test loss: 0.0083\n",
      "Step 80: Average train loss: 0.0087 | Average test loss: 0.0075\n",
      "Step 85: Average train loss: 0.0086 | Average test loss: 0.0079\n",
      "Step 90: Average train loss: 0.0085 | Average test loss: 0.0078\n",
      "Step 95: Average train loss: 0.0084 | Average test loss: 0.0075\n",
      "Best Epoch: 96\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 74612.375\n",
      "Step 0: Average train loss: 0.0197\n",
      "Step 5: Average train loss: 0.0197\n",
      "Step 10: Average train loss: 0.0197\n",
      "Step 15: Average train loss: 0.0197\n",
      "Step 20: Average train loss: 0.0196\n",
      "Step 25: Average train loss: 0.0196\n",
      "Step 30: Average train loss: 0.0196\n",
      "Step 35: Average train loss: 0.0195\n",
      "Step 40: Average train loss: 0.0195\n",
      "Step 45: Average train loss: 0.0195\n",
      "Step 50: Average train loss: 0.0195\n",
      "Step 55: Average train loss: 0.0194\n",
      "Step 60: Average train loss: 0.0194\n",
      "Step 65: Average train loss: 0.0194\n",
      "Step 70: Average train loss: 0.0194\n",
      "Step 75: Average train loss: 0.0193\n",
      "Step 80: Average train loss: 0.0193\n",
      "Step 85: Average train loss: 0.0193\n",
      "Step 90: Average train loss: 0.0193\n",
      "Step 95: Average train loss: 0.0192\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 78917.015625\n",
      "Step 0: Average train loss: 0.0193\n",
      "Step 5: Average train loss: 0.0193\n",
      "Step 10: Average train loss: 0.0193\n",
      "Step 15: Average train loss: 0.0192\n",
      "Step 20: Average train loss: 0.0192\n",
      "Step 25: Average train loss: 0.0191\n",
      "Step 30: Average train loss: 0.0191\n",
      "Step 35: Average train loss: 0.0190\n",
      "Step 40: Average train loss: 0.0190\n",
      "Step 45: Average train loss: 0.0189\n",
      "Step 50: Average train loss: 0.0189\n",
      "Step 55: Average train loss: 0.0189\n",
      "Step 60: Average train loss: 0.0188\n",
      "Step 65: Average train loss: 0.0188\n",
      "Step 70: Average train loss: 0.0187\n",
      "Step 75: Average train loss: 0.0187\n",
      "Step 80: Average train loss: 0.0186\n",
      "Step 85: Average train loss: 0.0186\n",
      "Step 90: Average train loss: 0.0185\n",
      "Step 95: Average train loss: 0.0185\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 62275.56640625\n",
      "Step 0: Average train loss: 0.0182\n",
      "Step 5: Average train loss: 0.0182\n",
      "Step 10: Average train loss: 0.0181\n",
      "Step 15: Average train loss: 0.0181\n",
      "Step 20: Average train loss: 0.0181\n",
      "Step 25: Average train loss: 0.0180\n",
      "Step 30: Average train loss: 0.0180\n",
      "Step 35: Average train loss: 0.0179\n",
      "Step 40: Average train loss: 0.0179\n",
      "Step 45: Average train loss: 0.0179\n",
      "Step 50: Average train loss: 0.0178\n",
      "Step 55: Average train loss: 0.0178\n",
      "Step 60: Average train loss: 0.0177\n",
      "Step 65: Average train loss: 0.0177\n",
      "Step 70: Average train loss: 0.0176\n",
      "Step 75: Average train loss: 0.0176\n",
      "Step 80: Average train loss: 0.0176\n",
      "Step 85: Average train loss: 0.0175\n",
      "Step 90: Average train loss: 0.0175\n",
      "Step 95: Average train loss: 0.0175\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 51255.41015625\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0160\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0159\n",
      "Step 20: Average train loss: 0.0159\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0156\n",
      "Step 50: Average train loss: 0.0156\n",
      "Step 55: Average train loss: 0.0155\n",
      "Step 60: Average train loss: 0.0155\n",
      "Step 65: Average train loss: 0.0154\n",
      "Step 70: Average train loss: 0.0154\n",
      "Step 75: Average train loss: 0.0153\n",
      "Step 80: Average train loss: 0.0153\n",
      "Step 85: Average train loss: 0.0152\n",
      "Step 90: Average train loss: 0.0152\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 31043.705078125\n",
      "Step 0: Average train loss: 0.0127\n",
      "Step 5: Average train loss: 0.0126\n",
      "Step 10: Average train loss: 0.0126\n",
      "Step 15: Average train loss: 0.0125\n",
      "Step 20: Average train loss: 0.0125\n",
      "Step 25: Average train loss: 0.0124\n",
      "Step 30: Average train loss: 0.0124\n",
      "Step 35: Average train loss: 0.0124\n",
      "Step 40: Average train loss: 0.0123\n",
      "Step 45: Average train loss: 0.0123\n",
      "Step 50: Average train loss: 0.0122\n",
      "Step 55: Average train loss: 0.0122\n",
      "Step 60: Average train loss: 0.0121\n",
      "Step 65: Average train loss: 0.0121\n",
      "Step 70: Average train loss: 0.0120\n",
      "Step 75: Average train loss: 0.0120\n",
      "Step 80: Average train loss: 0.0119\n",
      "Step 85: Average train loss: 0.0119\n",
      "Step 90: Average train loss: 0.0118\n",
      "Step 95: Average train loss: 0.0118\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 29497.03125\n",
      "Step 0: Average train loss: 0.0120\n",
      "Step 5: Average train loss: 0.0119\n",
      "Step 10: Average train loss: 0.0119\n",
      "Step 15: Average train loss: 0.0118\n",
      "Step 20: Average train loss: 0.0118\n",
      "Step 25: Average train loss: 0.0118\n",
      "Step 30: Average train loss: 0.0117\n",
      "Step 35: Average train loss: 0.0117\n",
      "Step 40: Average train loss: 0.0116\n",
      "Step 45: Average train loss: 0.0116\n",
      "Step 50: Average train loss: 0.0116\n",
      "Step 55: Average train loss: 0.0115\n",
      "Step 60: Average train loss: 0.0115\n",
      "Step 65: Average train loss: 0.0115\n",
      "Step 70: Average train loss: 0.0114\n",
      "Step 75: Average train loss: 0.0114\n",
      "Step 80: Average train loss: 0.0113\n",
      "Step 85: Average train loss: 0.0113\n",
      "Step 90: Average train loss: 0.0113\n",
      "Step 95: Average train loss: 0.0112\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 20493.267578125\n",
      "Step 0: Average train loss: 0.0100\n",
      "Step 5: Average train loss: 0.0100\n",
      "Step 10: Average train loss: 0.0100\n",
      "Step 15: Average train loss: 0.0099\n",
      "Step 20: Average train loss: 0.0099\n",
      "Step 25: Average train loss: 0.0099\n",
      "Step 30: Average train loss: 0.0099\n",
      "Step 35: Average train loss: 0.0098\n",
      "Step 40: Average train loss: 0.0098\n",
      "Step 45: Average train loss: 0.0098\n",
      "Step 50: Average train loss: 0.0097\n",
      "Step 55: Average train loss: 0.0097\n",
      "Step 60: Average train loss: 0.0097\n",
      "Step 65: Average train loss: 0.0097\n",
      "Step 70: Average train loss: 0.0096\n",
      "Step 75: Average train loss: 0.0096\n",
      "Step 80: Average train loss: 0.0096\n",
      "Step 85: Average train loss: 0.0096\n",
      "Step 90: Average train loss: 0.0095\n",
      "Step 95: Average train loss: 0.0095\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 12430.9765625\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0082\n",
      "Step 10: Average train loss: 0.0082\n",
      "Step 15: Average train loss: 0.0082\n",
      "Step 20: Average train loss: 0.0082\n",
      "Step 25: Average train loss: 0.0081\n",
      "Step 30: Average train loss: 0.0081\n",
      "Step 35: Average train loss: 0.0081\n",
      "Step 40: Average train loss: 0.0081\n",
      "Step 45: Average train loss: 0.0080\n",
      "Step 50: Average train loss: 0.0080\n",
      "Step 55: Average train loss: 0.0080\n",
      "Step 60: Average train loss: 0.0080\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0079\n",
      "Step 75: Average train loss: 0.0079\n",
      "Step 80: Average train loss: 0.0079\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 13680.546875\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0075\n",
      "Step 80: Average train loss: 0.0075\n",
      "Step 85: Average train loss: 0.0075\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 20730.59375\n",
      "Step 0: Average train loss: 0.0072\n",
      "Step 5: Average train loss: 0.0072\n",
      "Step 10: Average train loss: 0.0072\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0070\n",
      "Step 40: Average train loss: 0.0070\n",
      "Step 45: Average train loss: 0.0070\n",
      "Step 50: Average train loss: 0.0070\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0069\n",
      "Step 75: Average train loss: 0.0069\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 31799.6796875\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0069\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 30275.88671875\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', inv_limit=False, HP_tuning=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('is_day')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "    rmse.loc[(3, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverter Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 8]) torch.Size([140, 24, 8]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0525 | Average test loss: 0.0359\n",
      "Step 5: Average train loss: 0.0145 | Average test loss: 0.0132\n",
      "Step 10: Average train loss: 0.0127 | Average test loss: 0.0122\n",
      "Step 15: Average train loss: 0.0112 | Average test loss: 0.0106\n",
      "Step 20: Average train loss: 0.0109 | Average test loss: 0.0108\n",
      "Step 25: Average train loss: 0.0107 | Average test loss: 0.0107\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0103\n",
      "Step 35: Average train loss: 0.0103 | Average test loss: 0.0101\n",
      "Step 40: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 45: Average train loss: 0.0102 | Average test loss: 0.0098\n",
      "Step 50: Average train loss: 0.0100 | Average test loss: 0.0095\n",
      "Step 55: Average train loss: 0.0098 | Average test loss: 0.0095\n",
      "Step 60: Average train loss: 0.0096 | Average test loss: 0.0089\n",
      "Step 65: Average train loss: 0.0096 | Average test loss: 0.0093\n",
      "Step 70: Average train loss: 0.0095 | Average test loss: 0.0090\n",
      "Step 75: Average train loss: 0.0094 | Average test loss: 0.0088\n",
      "Step 80: Average train loss: 0.0093 | Average test loss: 0.0090\n",
      "Step 85: Average train loss: 0.0093 | Average test loss: 0.0088\n",
      "Step 90: Average train loss: 0.0093 | Average test loss: 0.0088\n",
      "Step 95: Average train loss: 0.0092 | Average test loss: 0.0087\n",
      "Best Epoch: 95\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 70861.4609375\n",
      "Step 0: Average train loss: 0.0114\n",
      "Step 5: Average train loss: 0.0113\n",
      "Step 10: Average train loss: 0.0113\n",
      "Step 15: Average train loss: 0.0113\n",
      "Step 20: Average train loss: 0.0113\n",
      "Step 25: Average train loss: 0.0113\n",
      "Step 30: Average train loss: 0.0112\n",
      "Step 35: Average train loss: 0.0112\n",
      "Step 40: Average train loss: 0.0112\n",
      "Step 45: Average train loss: 0.0112\n",
      "Step 50: Average train loss: 0.0112\n",
      "Step 55: Average train loss: 0.0111\n",
      "Step 60: Average train loss: 0.0111\n",
      "Step 65: Average train loss: 0.0111\n",
      "Step 70: Average train loss: 0.0111\n",
      "Step 75: Average train loss: 0.0111\n",
      "Step 80: Average train loss: 0.0111\n",
      "Step 85: Average train loss: 0.0110\n",
      "Step 90: Average train loss: 0.0110\n",
      "Step 95: Average train loss: 0.0110\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 61197.14453125\n",
      "Step 0: Average train loss: 0.0104\n",
      "Step 5: Average train loss: 0.0104\n",
      "Step 10: Average train loss: 0.0104\n",
      "Step 15: Average train loss: 0.0104\n",
      "Step 20: Average train loss: 0.0103\n",
      "Step 25: Average train loss: 0.0103\n",
      "Step 30: Average train loss: 0.0103\n",
      "Step 35: Average train loss: 0.0103\n",
      "Step 40: Average train loss: 0.0103\n",
      "Step 45: Average train loss: 0.0102\n",
      "Step 50: Average train loss: 0.0102\n",
      "Step 55: Average train loss: 0.0102\n",
      "Step 60: Average train loss: 0.0102\n",
      "Step 65: Average train loss: 0.0102\n",
      "Step 70: Average train loss: 0.0102\n",
      "Step 75: Average train loss: 0.0101\n",
      "Step 80: Average train loss: 0.0101\n",
      "Step 85: Average train loss: 0.0101\n",
      "Step 90: Average train loss: 0.0101\n",
      "Step 95: Average train loss: 0.0101\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 46687.69921875\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0091\n",
      "Step 30: Average train loss: 0.0091\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0090\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 51618.31640625\n",
      "Step 0: Average train loss: 0.0086\n",
      "Step 5: Average train loss: 0.0086\n",
      "Step 10: Average train loss: 0.0086\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0085\n",
      "Step 40: Average train loss: 0.0085\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0085\n",
      "Step 70: Average train loss: 0.0085\n",
      "Step 75: Average train loss: 0.0085\n",
      "Step 80: Average train loss: 0.0084\n",
      "Step 85: Average train loss: 0.0084\n",
      "Step 90: Average train loss: 0.0084\n",
      "Step 95: Average train loss: 0.0084\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 47449.8125\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 40250.5234375\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 27140.666015625\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0070\n",
      "Step 35: Average train loss: 0.0070\n",
      "Step 40: Average train loss: 0.0070\n",
      "Step 45: Average train loss: 0.0070\n",
      "Step 50: Average train loss: 0.0070\n",
      "Step 55: Average train loss: 0.0070\n",
      "Step 60: Average train loss: 0.0070\n",
      "Step 65: Average train loss: 0.0070\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 10654.9326171875\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 15804.45703125\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 38232.8359375\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 56446.64453125\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 56848.921875\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0065\n",
      "Step 60: Average train loss: 0.0065\n",
      "Step 65: Average train loss: 0.0065\n",
      "Step 70: Average train loss: 0.0065\n",
      "Step 75: Average train loss: 0.0065\n",
      "Step 80: Average train loss: 0.0065\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 84908.7890625\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 8]) torch.Size([140, 24, 8]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0404 | Average test loss: 0.0263\n",
      "Step 5: Average train loss: 0.0145 | Average test loss: 0.0109\n",
      "Step 10: Average train loss: 0.0091 | Average test loss: 0.0071\n",
      "Step 15: Average train loss: 0.0095 | Average test loss: 0.0075\n",
      "Step 20: Average train loss: 0.0092 | Average test loss: 0.0070\n",
      "Step 25: Average train loss: 0.0091 | Average test loss: 0.0070\n",
      "Step 30: Average train loss: 0.0090 | Average test loss: 0.0070\n",
      "Step 35: Average train loss: 0.0089 | Average test loss: 0.0070\n",
      "Step 40: Average train loss: 0.0084 | Average test loss: 0.0064\n",
      "Step 45: Average train loss: 0.0094 | Average test loss: 0.0075\n",
      "Step 50: Average train loss: 0.0084 | Average test loss: 0.0064\n",
      "Step 55: Average train loss: 0.0084 | Average test loss: 0.0063\n",
      "Step 60: Average train loss: 0.0087 | Average test loss: 0.0074\n",
      "Step 65: Average train loss: 0.0079 | Average test loss: 0.0061\n",
      "Step 70: Average train loss: 0.0082 | Average test loss: 0.0064\n",
      "Step 75: Average train loss: 0.0085 | Average test loss: 0.0070\n",
      "Step 80: Average train loss: 0.0078 | Average test loss: 0.0061\n",
      "Step 85: Average train loss: 0.0085 | Average test loss: 0.0074\n",
      "Step 90: Average train loss: 0.0083 | Average test loss: 0.0065\n",
      "Step 95: Average train loss: 0.0084 | Average test loss: 0.0071\n",
      "Best Epoch: 65\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 45038.5546875\n",
      "Step 0: Average train loss: 0.0095\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0095\n",
      "Step 15: Average train loss: 0.0094\n",
      "Step 20: Average train loss: 0.0094\n",
      "Step 25: Average train loss: 0.0094\n",
      "Step 30: Average train loss: 0.0094\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0094\n",
      "Step 45: Average train loss: 0.0094\n",
      "Step 50: Average train loss: 0.0094\n",
      "Step 55: Average train loss: 0.0093\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0093\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0093\n",
      "Step 85: Average train loss: 0.0093\n",
      "Step 90: Average train loss: 0.0093\n",
      "Step 95: Average train loss: 0.0092\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 43611.0625\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0090\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0089\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0089\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0088\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0088\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 46538.25390625\n",
      "Step 0: Average train loss: 0.0092\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0091\n",
      "Step 30: Average train loss: 0.0091\n",
      "Step 35: Average train loss: 0.0091\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0090\n",
      "Step 70: Average train loss: 0.0090\n",
      "Step 75: Average train loss: 0.0090\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 35066.03515625\n",
      "Step 0: Average train loss: 0.0084\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0083\n",
      "Step 20: Average train loss: 0.0083\n",
      "Step 25: Average train loss: 0.0083\n",
      "Step 30: Average train loss: 0.0083\n",
      "Step 35: Average train loss: 0.0083\n",
      "Step 40: Average train loss: 0.0082\n",
      "Step 45: Average train loss: 0.0082\n",
      "Step 50: Average train loss: 0.0082\n",
      "Step 55: Average train loss: 0.0082\n",
      "Step 60: Average train loss: 0.0082\n",
      "Step 65: Average train loss: 0.0082\n",
      "Step 70: Average train loss: 0.0082\n",
      "Step 75: Average train loss: 0.0081\n",
      "Step 80: Average train loss: 0.0081\n",
      "Step 85: Average train loss: 0.0081\n",
      "Step 90: Average train loss: 0.0081\n",
      "Step 95: Average train loss: 0.0081\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 37628.5546875\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0080\n",
      "Step 10: Average train loss: 0.0080\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0080\n",
      "Step 25: Average train loss: 0.0080\n",
      "Step 30: Average train loss: 0.0080\n",
      "Step 35: Average train loss: 0.0080\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0079\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23663.099609375\n",
      "Step 0: Average train loss: 0.0074\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 14416.169921875\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9718.330078125\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 11782.8388671875\n",
      "Step 0: Average train loss: 0.0056\n",
      "Step 5: Average train loss: 0.0056\n",
      "Step 10: Average train loss: 0.0056\n",
      "Step 15: Average train loss: 0.0056\n",
      "Step 20: Average train loss: 0.0056\n",
      "Step 25: Average train loss: 0.0056\n",
      "Step 30: Average train loss: 0.0056\n",
      "Step 35: Average train loss: 0.0056\n",
      "Step 40: Average train loss: 0.0056\n",
      "Step 45: Average train loss: 0.0056\n",
      "Step 50: Average train loss: 0.0056\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 17339.416015625\n",
      "Step 0: Average train loss: 0.0053\n",
      "Step 5: Average train loss: 0.0053\n",
      "Step 10: Average train loss: 0.0053\n",
      "Step 15: Average train loss: 0.0053\n",
      "Step 20: Average train loss: 0.0053\n",
      "Step 25: Average train loss: 0.0053\n",
      "Step 30: Average train loss: 0.0053\n",
      "Step 35: Average train loss: 0.0053\n",
      "Step 40: Average train loss: 0.0053\n",
      "Step 45: Average train loss: 0.0053\n",
      "Step 50: Average train loss: 0.0053\n",
      "Step 55: Average train loss: 0.0053\n",
      "Step 60: Average train loss: 0.0053\n",
      "Step 65: Average train loss: 0.0053\n",
      "Step 70: Average train loss: 0.0053\n",
      "Step 75: Average train loss: 0.0053\n",
      "Step 80: Average train loss: 0.0053\n",
      "Step 85: Average train loss: 0.0053\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 46893.29296875\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0065\n",
      "Step 55: Average train loss: 0.0065\n",
      "Step 60: Average train loss: 0.0065\n",
      "Step 65: Average train loss: 0.0065\n",
      "Step 70: Average train loss: 0.0065\n",
      "Step 75: Average train loss: 0.0065\n",
      "Step 80: Average train loss: 0.0065\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 38712.19921875\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 34777.38671875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 8]) torch.Size([144, 24, 8]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0434 | Average test loss: 0.0397\n",
      "Step 5: Average train loss: 0.0074 | Average test loss: 0.0032\n",
      "Step 10: Average train loss: 0.0060 | Average test loss: 0.0019\n",
      "Step 15: Average train loss: 0.0055 | Average test loss: 0.0016\n",
      "Step 20: Average train loss: 0.0053 | Average test loss: 0.0016\n",
      "Step 25: Average train loss: 0.0052 | Average test loss: 0.0017\n",
      "Step 30: Average train loss: 0.0051 | Average test loss: 0.0017\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 40: Average train loss: 0.0050 | Average test loss: 0.0018\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 55: Average train loss: 0.0049 | Average test loss: 0.0022\n",
      "Step 60: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 70: Average train loss: 0.0048 | Average test loss: 0.0023\n",
      "Step 75: Average train loss: 0.0048 | Average test loss: 0.0024\n",
      "Step 80: Average train loss: 0.0048 | Average test loss: 0.0024\n",
      "Step 85: Average train loss: 0.0047 | Average test loss: 0.0023\n",
      "Step 90: Average train loss: 0.0047 | Average test loss: 0.0022\n",
      "Step 95: Average train loss: 0.0047 | Average test loss: 0.0026\n",
      "Best Epoch: 18\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 301952.6875\n",
      "Step 0: Average train loss: 0.0160\n",
      "Step 5: Average train loss: 0.0160\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0159\n",
      "Step 25: Average train loss: 0.0159\n",
      "Step 30: Average train loss: 0.0159\n",
      "Step 35: Average train loss: 0.0159\n",
      "Step 40: Average train loss: 0.0159\n",
      "Step 45: Average train loss: 0.0159\n",
      "Step 50: Average train loss: 0.0159\n",
      "Step 55: Average train loss: 0.0159\n",
      "Step 60: Average train loss: 0.0159\n",
      "Step 65: Average train loss: 0.0159\n",
      "Step 70: Average train loss: 0.0159\n",
      "Step 75: Average train loss: 0.0159\n",
      "Step 80: Average train loss: 0.0159\n",
      "Step 85: Average train loss: 0.0159\n",
      "Step 90: Average train loss: 0.0158\n",
      "Step 95: Average train loss: 0.0158\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 294898.28125\n",
      "Step 0: Average train loss: 0.0156\n",
      "Step 5: Average train loss: 0.0156\n",
      "Step 10: Average train loss: 0.0155\n",
      "Step 15: Average train loss: 0.0155\n",
      "Step 20: Average train loss: 0.0155\n",
      "Step 25: Average train loss: 0.0155\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0155\n",
      "Step 45: Average train loss: 0.0155\n",
      "Step 50: Average train loss: 0.0155\n",
      "Step 55: Average train loss: 0.0154\n",
      "Step 60: Average train loss: 0.0154\n",
      "Step 65: Average train loss: 0.0154\n",
      "Step 70: Average train loss: 0.0154\n",
      "Step 75: Average train loss: 0.0154\n",
      "Step 80: Average train loss: 0.0154\n",
      "Step 85: Average train loss: 0.0154\n",
      "Step 90: Average train loss: 0.0154\n",
      "Step 95: Average train loss: 0.0153\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 250668.828125\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 283509.59375\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 287911.8125\n",
      "Step 0: Average train loss: 0.0146\n",
      "Step 5: Average train loss: 0.0146\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0145\n",
      "Step 45: Average train loss: 0.0145\n",
      "Step 50: Average train loss: 0.0145\n",
      "Step 55: Average train loss: 0.0145\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 307782.875\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 203411.15625\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0137\n",
      "Step 35: Average train loss: 0.0137\n",
      "Step 40: Average train loss: 0.0137\n",
      "Step 45: Average train loss: 0.0137\n",
      "Step 50: Average train loss: 0.0137\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 291231.28125\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 303281.0625\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0142\n",
      "Step 35: Average train loss: 0.0142\n",
      "Step 40: Average train loss: 0.0142\n",
      "Step 45: Average train loss: 0.0142\n",
      "Step 50: Average train loss: 0.0142\n",
      "Step 55: Average train loss: 0.0142\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0141\n",
      "Step 85: Average train loss: 0.0141\n",
      "Step 90: Average train loss: 0.0141\n",
      "Step 95: Average train loss: 0.0141\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 410102.75\n",
      "Step 0: Average train loss: 0.0154\n",
      "Step 5: Average train loss: 0.0154\n",
      "Step 10: Average train loss: 0.0154\n",
      "Step 15: Average train loss: 0.0153\n",
      "Step 20: Average train loss: 0.0153\n",
      "Step 25: Average train loss: 0.0153\n",
      "Step 30: Average train loss: 0.0153\n",
      "Step 35: Average train loss: 0.0153\n",
      "Step 40: Average train loss: 0.0153\n",
      "Step 45: Average train loss: 0.0153\n",
      "Step 50: Average train loss: 0.0153\n",
      "Step 55: Average train loss: 0.0153\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0153\n",
      "Step 75: Average train loss: 0.0153\n",
      "Step 80: Average train loss: 0.0153\n",
      "Step 85: Average train loss: 0.0153\n",
      "Step 90: Average train loss: 0.0152\n",
      "Step 95: Average train loss: 0.0152\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 419981.46875\n",
      "Step 0: Average train loss: 0.0163\n",
      "Step 5: Average train loss: 0.0163\n",
      "Step 10: Average train loss: 0.0163\n",
      "Step 15: Average train loss: 0.0163\n",
      "Step 20: Average train loss: 0.0163\n",
      "Step 25: Average train loss: 0.0163\n",
      "Step 30: Average train loss: 0.0163\n",
      "Step 35: Average train loss: 0.0163\n",
      "Step 40: Average train loss: 0.0163\n",
      "Step 45: Average train loss: 0.0163\n",
      "Step 50: Average train loss: 0.0163\n",
      "Step 55: Average train loss: 0.0163\n",
      "Step 60: Average train loss: 0.0162\n",
      "Step 65: Average train loss: 0.0162\n",
      "Step 70: Average train loss: 0.0162\n",
      "Step 75: Average train loss: 0.0162\n",
      "Step 80: Average train loss: 0.0162\n",
      "Step 85: Average train loss: 0.0162\n",
      "Step 90: Average train loss: 0.0162\n",
      "Step 95: Average train loss: 0.0162\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 386856.875\n",
      "Step 0: Average train loss: 0.0159\n",
      "Step 5: Average train loss: 0.0159\n",
      "Step 10: Average train loss: 0.0159\n",
      "Step 15: Average train loss: 0.0159\n",
      "Step 20: Average train loss: 0.0158\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0158\n",
      "Step 45: Average train loss: 0.0158\n",
      "Step 50: Average train loss: 0.0158\n",
      "Step 55: Average train loss: 0.0158\n",
      "Step 60: Average train loss: 0.0158\n",
      "Step 65: Average train loss: 0.0158\n",
      "Step 70: Average train loss: 0.0158\n",
      "Step 75: Average train loss: 0.0158\n",
      "Step 80: Average train loss: 0.0158\n",
      "Step 85: Average train loss: 0.0158\n",
      "Step 90: Average train loss: 0.0158\n",
      "Step 95: Average train loss: 0.0158\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 576552.0625\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 8]) torch.Size([140, 24, 8]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0403 | Average test loss: 0.0240\n",
      "Step 5: Average train loss: 0.0246 | Average test loss: 0.0181\n",
      "Step 10: Average train loss: 0.0105 | Average test loss: 0.0108\n",
      "Step 15: Average train loss: 0.0097 | Average test loss: 0.0092\n",
      "Step 20: Average train loss: 0.0119 | Average test loss: 0.0109\n",
      "Step 25: Average train loss: 0.0099 | Average test loss: 0.0084\n",
      "Step 30: Average train loss: 0.0095 | Average test loss: 0.0082\n",
      "Step 35: Average train loss: 0.0100 | Average test loss: 0.0085\n",
      "Step 40: Average train loss: 0.0095 | Average test loss: 0.0086\n",
      "Step 45: Average train loss: 0.0093 | Average test loss: 0.0081\n",
      "Step 50: Average train loss: 0.0090 | Average test loss: 0.0079\n",
      "Step 55: Average train loss: 0.0088 | Average test loss: 0.0079\n",
      "Step 60: Average train loss: 0.0093 | Average test loss: 0.0086\n",
      "Step 65: Average train loss: 0.0092 | Average test loss: 0.0085\n",
      "Step 70: Average train loss: 0.0088 | Average test loss: 0.0082\n",
      "Step 75: Average train loss: 0.0092 | Average test loss: 0.0079\n",
      "Step 80: Average train loss: 0.0086 | Average test loss: 0.0079\n",
      "Step 85: Average train loss: 0.0087 | Average test loss: 0.0080\n",
      "Step 90: Average train loss: 0.0085 | Average test loss: 0.0081\n",
      "Step 95: Average train loss: 0.0090 | Average test loss: 0.0078\n",
      "Best Epoch: 96\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 85691.484375\n",
      "Step 0: Average train loss: 0.0227\n",
      "Step 5: Average train loss: 0.0227\n",
      "Step 10: Average train loss: 0.0226\n",
      "Step 15: Average train loss: 0.0226\n",
      "Step 20: Average train loss: 0.0226\n",
      "Step 25: Average train loss: 0.0225\n",
      "Step 30: Average train loss: 0.0225\n",
      "Step 35: Average train loss: 0.0225\n",
      "Step 40: Average train loss: 0.0225\n",
      "Step 45: Average train loss: 0.0224\n",
      "Step 50: Average train loss: 0.0224\n",
      "Step 55: Average train loss: 0.0224\n",
      "Step 60: Average train loss: 0.0223\n",
      "Step 65: Average train loss: 0.0223\n",
      "Step 70: Average train loss: 0.0223\n",
      "Step 75: Average train loss: 0.0223\n",
      "Step 80: Average train loss: 0.0222\n",
      "Step 85: Average train loss: 0.0222\n",
      "Step 90: Average train loss: 0.0222\n",
      "Step 95: Average train loss: 0.0221\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 87475.296875\n",
      "Step 0: Average train loss: 0.0217\n",
      "Step 5: Average train loss: 0.0217\n",
      "Step 10: Average train loss: 0.0216\n",
      "Step 15: Average train loss: 0.0216\n",
      "Step 20: Average train loss: 0.0215\n",
      "Step 25: Average train loss: 0.0215\n",
      "Step 30: Average train loss: 0.0214\n",
      "Step 35: Average train loss: 0.0214\n",
      "Step 40: Average train loss: 0.0213\n",
      "Step 45: Average train loss: 0.0213\n",
      "Step 50: Average train loss: 0.0212\n",
      "Step 55: Average train loss: 0.0212\n",
      "Step 60: Average train loss: 0.0211\n",
      "Step 65: Average train loss: 0.0211\n",
      "Step 70: Average train loss: 0.0210\n",
      "Step 75: Average train loss: 0.0210\n",
      "Step 80: Average train loss: 0.0209\n",
      "Step 85: Average train loss: 0.0209\n",
      "Step 90: Average train loss: 0.0208\n",
      "Step 95: Average train loss: 0.0208\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 66362.453125\n",
      "Step 0: Average train loss: 0.0202\n",
      "Step 5: Average train loss: 0.0201\n",
      "Step 10: Average train loss: 0.0201\n",
      "Step 15: Average train loss: 0.0200\n",
      "Step 20: Average train loss: 0.0200\n",
      "Step 25: Average train loss: 0.0199\n",
      "Step 30: Average train loss: 0.0199\n",
      "Step 35: Average train loss: 0.0198\n",
      "Step 40: Average train loss: 0.0198\n",
      "Step 45: Average train loss: 0.0197\n",
      "Step 50: Average train loss: 0.0197\n",
      "Step 55: Average train loss: 0.0196\n",
      "Step 60: Average train loss: 0.0196\n",
      "Step 65: Average train loss: 0.0196\n",
      "Step 70: Average train loss: 0.0195\n",
      "Step 75: Average train loss: 0.0195\n",
      "Step 80: Average train loss: 0.0194\n",
      "Step 85: Average train loss: 0.0194\n",
      "Step 90: Average train loss: 0.0193\n",
      "Step 95: Average train loss: 0.0193\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 60487.34375\n",
      "Step 0: Average train loss: 0.0181\n",
      "Step 5: Average train loss: 0.0181\n",
      "Step 10: Average train loss: 0.0180\n",
      "Step 15: Average train loss: 0.0179\n",
      "Step 20: Average train loss: 0.0179\n",
      "Step 25: Average train loss: 0.0178\n",
      "Step 30: Average train loss: 0.0177\n",
      "Step 35: Average train loss: 0.0177\n",
      "Step 40: Average train loss: 0.0176\n",
      "Step 45: Average train loss: 0.0175\n",
      "Step 50: Average train loss: 0.0175\n",
      "Step 55: Average train loss: 0.0174\n",
      "Step 60: Average train loss: 0.0174\n",
      "Step 65: Average train loss: 0.0173\n",
      "Step 70: Average train loss: 0.0172\n",
      "Step 75: Average train loss: 0.0172\n",
      "Step 80: Average train loss: 0.0171\n",
      "Step 85: Average train loss: 0.0170\n",
      "Step 90: Average train loss: 0.0170\n",
      "Step 95: Average train loss: 0.0169\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 37950.6796875\n",
      "Step 0: Average train loss: 0.0145\n",
      "Step 5: Average train loss: 0.0145\n",
      "Step 10: Average train loss: 0.0144\n",
      "Step 15: Average train loss: 0.0143\n",
      "Step 20: Average train loss: 0.0143\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0140\n",
      "Step 45: Average train loss: 0.0139\n",
      "Step 50: Average train loss: 0.0139\n",
      "Step 55: Average train loss: 0.0138\n",
      "Step 60: Average train loss: 0.0137\n",
      "Step 65: Average train loss: 0.0137\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0135\n",
      "Step 85: Average train loss: 0.0134\n",
      "Step 90: Average train loss: 0.0134\n",
      "Step 95: Average train loss: 0.0133\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 35213.62109375\n",
      "Step 0: Average train loss: 0.0135\n",
      "Step 5: Average train loss: 0.0134\n",
      "Step 10: Average train loss: 0.0133\n",
      "Step 15: Average train loss: 0.0133\n",
      "Step 20: Average train loss: 0.0132\n",
      "Step 25: Average train loss: 0.0132\n",
      "Step 30: Average train loss: 0.0131\n",
      "Step 35: Average train loss: 0.0131\n",
      "Step 40: Average train loss: 0.0130\n",
      "Step 45: Average train loss: 0.0130\n",
      "Step 50: Average train loss: 0.0129\n",
      "Step 55: Average train loss: 0.0129\n",
      "Step 60: Average train loss: 0.0128\n",
      "Step 65: Average train loss: 0.0128\n",
      "Step 70: Average train loss: 0.0127\n",
      "Step 75: Average train loss: 0.0126\n",
      "Step 80: Average train loss: 0.0126\n",
      "Step 85: Average train loss: 0.0125\n",
      "Step 90: Average train loss: 0.0125\n",
      "Step 95: Average train loss: 0.0125\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 19307.36328125\n",
      "Step 0: Average train loss: 0.0109\n",
      "Step 5: Average train loss: 0.0109\n",
      "Step 10: Average train loss: 0.0108\n",
      "Step 15: Average train loss: 0.0108\n",
      "Step 20: Average train loss: 0.0107\n",
      "Step 25: Average train loss: 0.0107\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0106\n",
      "Step 40: Average train loss: 0.0106\n",
      "Step 45: Average train loss: 0.0105\n",
      "Step 50: Average train loss: 0.0105\n",
      "Step 55: Average train loss: 0.0105\n",
      "Step 60: Average train loss: 0.0104\n",
      "Step 65: Average train loss: 0.0104\n",
      "Step 70: Average train loss: 0.0103\n",
      "Step 75: Average train loss: 0.0103\n",
      "Step 80: Average train loss: 0.0103\n",
      "Step 85: Average train loss: 0.0102\n",
      "Step 90: Average train loss: 0.0102\n",
      "Step 95: Average train loss: 0.0102\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 11012.7919921875\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0087\n",
      "Step 10: Average train loss: 0.0086\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0085\n",
      "Step 30: Average train loss: 0.0085\n",
      "Step 35: Average train loss: 0.0085\n",
      "Step 40: Average train loss: 0.0084\n",
      "Step 45: Average train loss: 0.0084\n",
      "Step 50: Average train loss: 0.0084\n",
      "Step 55: Average train loss: 0.0084\n",
      "Step 60: Average train loss: 0.0083\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0082\n",
      "Step 80: Average train loss: 0.0082\n",
      "Step 85: Average train loss: 0.0082\n",
      "Step 90: Average train loss: 0.0082\n",
      "Step 95: Average train loss: 0.0081\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 12566.908203125\n",
      "Step 0: Average train loss: 0.0082\n",
      "Step 5: Average train loss: 0.0082\n",
      "Step 10: Average train loss: 0.0081\n",
      "Step 15: Average train loss: 0.0081\n",
      "Step 20: Average train loss: 0.0081\n",
      "Step 25: Average train loss: 0.0081\n",
      "Step 30: Average train loss: 0.0080\n",
      "Step 35: Average train loss: 0.0080\n",
      "Step 40: Average train loss: 0.0080\n",
      "Step 45: Average train loss: 0.0080\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 19782.56640625\n",
      "Step 0: Average train loss: 0.0074\n",
      "Step 5: Average train loss: 0.0073\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0073\n",
      "Step 20: Average train loss: 0.0073\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0072\n",
      "Step 40: Average train loss: 0.0072\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0069\n",
      "Step 95: Average train loss: 0.0069\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 32579.197265625\n",
      "Step 0: Average train loss: 0.0072\n",
      "Step 5: Average train loss: 0.0072\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0070\n",
      "Step 35: Average train loss: 0.0070\n",
      "Step 40: Average train loss: 0.0070\n",
      "Step 45: Average train loss: 0.0070\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 34274.8984375\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', inv_limit=False, HP_tuning=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "    rmse.loc[(4, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 5]) torch.Size([140, 24, 5]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0562 | Average test loss: 0.0354\n",
      "Step 5: Average train loss: 0.0153 | Average test loss: 0.0137\n",
      "Step 10: Average train loss: 0.0125 | Average test loss: 0.0130\n",
      "Step 15: Average train loss: 0.0114 | Average test loss: 0.0112\n",
      "Step 20: Average train loss: 0.0109 | Average test loss: 0.0108\n",
      "Step 25: Average train loss: 0.0108 | Average test loss: 0.0108\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0104\n",
      "Step 35: Average train loss: 0.0105 | Average test loss: 0.0104\n",
      "Step 40: Average train loss: 0.0104 | Average test loss: 0.0103\n",
      "Step 45: Average train loss: 0.0104 | Average test loss: 0.0103\n",
      "Step 50: Average train loss: 0.0103 | Average test loss: 0.0102\n",
      "Step 55: Average train loss: 0.0103 | Average test loss: 0.0102\n",
      "Step 60: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 65: Average train loss: 0.0100 | Average test loss: 0.0094\n",
      "Step 70: Average train loss: 0.0099 | Average test loss: 0.0100\n",
      "Step 75: Average train loss: 0.0095 | Average test loss: 0.0088\n",
      "Step 80: Average train loss: 0.0097 | Average test loss: 0.0088\n",
      "Step 85: Average train loss: 0.0096 | Average test loss: 0.0092\n",
      "Step 90: Average train loss: 0.0098 | Average test loss: 0.0091\n",
      "Step 95: Average train loss: 0.0095 | Average test loss: 0.0087\n",
      "Best Epoch: 74\n",
      "Shape of data:  torch.Size([30, 24, 5]) torch.Size([30, 24, 5]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 70521.2578125\n",
      "Step 0: Average train loss: 0.0113\n",
      "Step 5: Average train loss: 0.0113\n",
      "Step 10: Average train loss: 0.0113\n",
      "Step 15: Average train loss: 0.0112\n",
      "Step 20: Average train loss: 0.0112\n",
      "Step 25: Average train loss: 0.0112\n",
      "Step 30: Average train loss: 0.0112\n",
      "Step 35: Average train loss: 0.0112\n",
      "Step 40: Average train loss: 0.0111\n",
      "Step 45: Average train loss: 0.0111\n",
      "Step 50: Average train loss: 0.0111\n",
      "Step 55: Average train loss: 0.0111\n",
      "Step 60: Average train loss: 0.0111\n",
      "Step 65: Average train loss: 0.0111\n",
      "Step 70: Average train loss: 0.0110\n",
      "Step 75: Average train loss: 0.0110\n",
      "Step 80: Average train loss: 0.0110\n",
      "Step 85: Average train loss: 0.0110\n",
      "Step 90: Average train loss: 0.0110\n",
      "Step 95: Average train loss: 0.0110\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 64551.53515625\n",
      "Step 0: Average train loss: 0.0108\n",
      "Step 5: Average train loss: 0.0108\n",
      "Step 10: Average train loss: 0.0108\n",
      "Step 15: Average train loss: 0.0108\n",
      "Step 20: Average train loss: 0.0107\n",
      "Step 25: Average train loss: 0.0107\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0107\n",
      "Step 40: Average train loss: 0.0107\n",
      "Step 45: Average train loss: 0.0106\n",
      "Step 50: Average train loss: 0.0106\n",
      "Step 55: Average train loss: 0.0106\n",
      "Step 60: Average train loss: 0.0106\n",
      "Step 65: Average train loss: 0.0106\n",
      "Step 70: Average train loss: 0.0106\n",
      "Step 75: Average train loss: 0.0105\n",
      "Step 80: Average train loss: 0.0105\n",
      "Step 85: Average train loss: 0.0105\n",
      "Step 90: Average train loss: 0.0105\n",
      "Step 95: Average train loss: 0.0105\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 49883.18359375\n",
      "Step 0: Average train loss: 0.0095\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0094\n",
      "Step 15: Average train loss: 0.0094\n",
      "Step 20: Average train loss: 0.0094\n",
      "Step 25: Average train loss: 0.0094\n",
      "Step 30: Average train loss: 0.0094\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0094\n",
      "Step 45: Average train loss: 0.0093\n",
      "Step 50: Average train loss: 0.0093\n",
      "Step 55: Average train loss: 0.0093\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0093\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0092\n",
      "Step 85: Average train loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092\n",
      "Step 95: Average train loss: 0.0092\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 53552.51171875\n",
      "Step 0: Average train loss: 0.0089\n",
      "Step 5: Average train loss: 0.0089\n",
      "Step 10: Average train loss: 0.0089\n",
      "Step 15: Average train loss: 0.0089\n",
      "Step 20: Average train loss: 0.0089\n",
      "Step 25: Average train loss: 0.0088\n",
      "Step 30: Average train loss: 0.0088\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0088\n",
      "Step 50: Average train loss: 0.0088\n",
      "Step 55: Average train loss: 0.0088\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0087\n",
      "Step 80: Average train loss: 0.0087\n",
      "Step 85: Average train loss: 0.0087\n",
      "Step 90: Average train loss: 0.0087\n",
      "Step 95: Average train loss: 0.0086\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 47888.7109375\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 40980.41015625\n",
      "Step 0: Average train loss: 0.0080\n",
      "Step 5: Average train loss: 0.0080\n",
      "Step 10: Average train loss: 0.0080\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0079\n",
      "Step 35: Average train loss: 0.0079\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0079\n",
      "Step 75: Average train loss: 0.0079\n",
      "Step 80: Average train loss: 0.0079\n",
      "Step 85: Average train loss: 0.0079\n",
      "Step 90: Average train loss: 0.0079\n",
      "Step 95: Average train loss: 0.0079\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 27213.01171875\n",
      "Step 0: Average train loss: 0.0072\n",
      "Step 5: Average train loss: 0.0072\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 10430.9833984375\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 15663.7197265625\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 41455.71484375\n",
      "Step 0: Average train loss: 0.0063\n",
      "Step 5: Average train loss: 0.0063\n",
      "Step 10: Average train loss: 0.0063\n",
      "Step 15: Average train loss: 0.0063\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 58108.0234375\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 58015.56640625\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n",
      "Step 60: Average train loss: 0.0067\n",
      "Step 65: Average train loss: 0.0067\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 74503.4609375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 5]) torch.Size([140, 24, 5]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0459 | Average test loss: 0.0266\n",
      "Step 5: Average train loss: 0.0222 | Average test loss: 0.0153\n",
      "Step 10: Average train loss: 0.0093 | Average test loss: 0.0075\n",
      "Step 15: Average train loss: 0.0096 | Average test loss: 0.0075\n",
      "Step 20: Average train loss: 0.0094 | Average test loss: 0.0071\n",
      "Step 25: Average train loss: 0.0094 | Average test loss: 0.0070\n",
      "Step 30: Average train loss: 0.0089 | Average test loss: 0.0071\n",
      "Step 35: Average train loss: 0.0091 | Average test loss: 0.0070\n",
      "Step 40: Average train loss: 0.0089 | Average test loss: 0.0072\n",
      "Step 45: Average train loss: 0.0089 | Average test loss: 0.0069\n",
      "Step 50: Average train loss: 0.0088 | Average test loss: 0.0072\n",
      "Step 55: Average train loss: 0.0088 | Average test loss: 0.0068\n",
      "Step 60: Average train loss: 0.0088 | Average test loss: 0.0070\n",
      "Step 65: Average train loss: 0.0088 | Average test loss: 0.0068\n",
      "Step 70: Average train loss: 0.0087 | Average test loss: 0.0068\n",
      "Step 75: Average train loss: 0.0087 | Average test loss: 0.0069\n",
      "Step 80: Average train loss: 0.0086 | Average test loss: 0.0066\n",
      "Step 85: Average train loss: 0.0086 | Average test loss: 0.0066\n",
      "Step 90: Average train loss: 0.0087 | Average test loss: 0.0069\n",
      "Step 95: Average train loss: 0.0085 | Average test loss: 0.0064\n",
      "Best Epoch: 93\n",
      "Shape of data:  torch.Size([30, 24, 5]) torch.Size([30, 24, 5]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 41935.390625\n",
      "Step 0: Average train loss: 0.0088\n",
      "Step 5: Average train loss: 0.0088\n",
      "Step 10: Average train loss: 0.0088\n",
      "Step 15: Average train loss: 0.0088\n",
      "Step 20: Average train loss: 0.0088\n",
      "Step 25: Average train loss: 0.0087\n",
      "Step 30: Average train loss: 0.0087\n",
      "Step 35: Average train loss: 0.0087\n",
      "Step 40: Average train loss: 0.0087\n",
      "Step 45: Average train loss: 0.0087\n",
      "Step 50: Average train loss: 0.0087\n",
      "Step 55: Average train loss: 0.0087\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0086\n",
      "Step 80: Average train loss: 0.0086\n",
      "Step 85: Average train loss: 0.0086\n",
      "Step 90: Average train loss: 0.0086\n",
      "Step 95: Average train loss: 0.0086\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 45100.74609375\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0091\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 52291.34375\n",
      "Step 0: Average train loss: 0.0095\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0095\n",
      "Step 15: Average train loss: 0.0094\n",
      "Step 20: Average train loss: 0.0094\n",
      "Step 25: Average train loss: 0.0094\n",
      "Step 30: Average train loss: 0.0094\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0094\n",
      "Step 45: Average train loss: 0.0094\n",
      "Step 50: Average train loss: 0.0093\n",
      "Step 55: Average train loss: 0.0093\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0093\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0093\n",
      "Step 85: Average train loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092\n",
      "Step 95: Average train loss: 0.0092\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 36504.0703125\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0086\n",
      "Step 10: Average train loss: 0.0086\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0085\n",
      "Step 40: Average train loss: 0.0085\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0084\n",
      "Step 75: Average train loss: 0.0084\n",
      "Step 80: Average train loss: 0.0084\n",
      "Step 85: Average train loss: 0.0084\n",
      "Step 90: Average train loss: 0.0084\n",
      "Step 95: Average train loss: 0.0084\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 38479.140625\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0082\n",
      "Step 20: Average train loss: 0.0082\n",
      "Step 25: Average train loss: 0.0082\n",
      "Step 30: Average train loss: 0.0082\n",
      "Step 35: Average train loss: 0.0082\n",
      "Step 40: Average train loss: 0.0081\n",
      "Step 45: Average train loss: 0.0081\n",
      "Step 50: Average train loss: 0.0081\n",
      "Step 55: Average train loss: 0.0081\n",
      "Step 60: Average train loss: 0.0081\n",
      "Step 65: Average train loss: 0.0081\n",
      "Step 70: Average train loss: 0.0080\n",
      "Step 75: Average train loss: 0.0080\n",
      "Step 80: Average train loss: 0.0080\n",
      "Step 85: Average train loss: 0.0080\n",
      "Step 90: Average train loss: 0.0080\n",
      "Step 95: Average train loss: 0.0080\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 24408.955078125\n",
      "Step 0: Average train loss: 0.0076\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0075\n",
      "Step 15: Average train loss: 0.0075\n",
      "Step 20: Average train loss: 0.0075\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0075\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0075\n",
      "Step 50: Average train loss: 0.0075\n",
      "Step 55: Average train loss: 0.0075\n",
      "Step 60: Average train loss: 0.0075\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 14959.5068359375\n",
      "Step 0: Average train loss: 0.0065\n",
      "Step 5: Average train loss: 0.0065\n",
      "Step 10: Average train loss: 0.0065\n",
      "Step 15: Average train loss: 0.0065\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0065\n",
      "Step 30: Average train loss: 0.0065\n",
      "Step 35: Average train loss: 0.0065\n",
      "Step 40: Average train loss: 0.0065\n",
      "Step 45: Average train loss: 0.0065\n",
      "Step 50: Average train loss: 0.0065\n",
      "Step 55: Average train loss: 0.0065\n",
      "Step 60: Average train loss: 0.0065\n",
      "Step 65: Average train loss: 0.0065\n",
      "Step 70: Average train loss: 0.0065\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9596.66796875\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 13585.2998046875\n",
      "Step 0: Average train loss: 0.0057\n",
      "Step 5: Average train loss: 0.0057\n",
      "Step 10: Average train loss: 0.0057\n",
      "Step 15: Average train loss: 0.0057\n",
      "Step 20: Average train loss: 0.0057\n",
      "Step 25: Average train loss: 0.0057\n",
      "Step 30: Average train loss: 0.0057\n",
      "Step 35: Average train loss: 0.0057\n",
      "Step 40: Average train loss: 0.0057\n",
      "Step 45: Average train loss: 0.0057\n",
      "Step 50: Average train loss: 0.0057\n",
      "Step 55: Average train loss: 0.0057\n",
      "Step 60: Average train loss: 0.0057\n",
      "Step 65: Average train loss: 0.0057\n",
      "Step 70: Average train loss: 0.0057\n",
      "Step 75: Average train loss: 0.0057\n",
      "Step 80: Average train loss: 0.0057\n",
      "Step 85: Average train loss: 0.0057\n",
      "Step 90: Average train loss: 0.0057\n",
      "Step 95: Average train loss: 0.0057\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 17583.921875\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 45986.24609375\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n",
      "Step 60: Average train loss: 0.0067\n",
      "Step 65: Average train loss: 0.0067\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 38944.453125\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 33616.71484375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 5]) torch.Size([144, 24, 5]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0450 | Average test loss: 0.0388\n",
      "Step 5: Average train loss: 0.0080 | Average test loss: 0.0034\n",
      "Step 10: Average train loss: 0.0061 | Average test loss: 0.0018\n",
      "Step 15: Average train loss: 0.0054 | Average test loss: 0.0018\n",
      "Step 20: Average train loss: 0.0053 | Average test loss: 0.0018\n",
      "Step 25: Average train loss: 0.0052 | Average test loss: 0.0018\n",
      "Step 30: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0019\n",
      "Step 40: Average train loss: 0.0051 | Average test loss: 0.0019\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 55: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 60: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 70: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 75: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 80: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 85: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 90: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 95: Average train loss: 0.0049 | Average test loss: 0.0018\n",
      "Best Epoch: 89\n",
      "Shape of data:  torch.Size([30, 24, 5]) torch.Size([30, 24, 5]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 302178.53125\n",
      "Step 0: Average train loss: 0.0160\n",
      "Step 5: Average train loss: 0.0160\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0160\n",
      "Step 30: Average train loss: 0.0159\n",
      "Step 35: Average train loss: 0.0159\n",
      "Step 40: Average train loss: 0.0159\n",
      "Step 45: Average train loss: 0.0159\n",
      "Step 50: Average train loss: 0.0159\n",
      "Step 55: Average train loss: 0.0159\n",
      "Step 60: Average train loss: 0.0159\n",
      "Step 65: Average train loss: 0.0159\n",
      "Step 70: Average train loss: 0.0159\n",
      "Step 75: Average train loss: 0.0159\n",
      "Step 80: Average train loss: 0.0159\n",
      "Step 85: Average train loss: 0.0159\n",
      "Step 90: Average train loss: 0.0159\n",
      "Step 95: Average train loss: 0.0159\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 296543.21875\n",
      "Step 0: Average train loss: 0.0156\n",
      "Step 5: Average train loss: 0.0156\n",
      "Step 10: Average train loss: 0.0156\n",
      "Step 15: Average train loss: 0.0156\n",
      "Step 20: Average train loss: 0.0156\n",
      "Step 25: Average train loss: 0.0156\n",
      "Step 30: Average train loss: 0.0156\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0155\n",
      "Step 45: Average train loss: 0.0155\n",
      "Step 50: Average train loss: 0.0155\n",
      "Step 55: Average train loss: 0.0155\n",
      "Step 60: Average train loss: 0.0155\n",
      "Step 65: Average train loss: 0.0155\n",
      "Step 70: Average train loss: 0.0155\n",
      "Step 75: Average train loss: 0.0155\n",
      "Step 80: Average train loss: 0.0154\n",
      "Step 85: Average train loss: 0.0154\n",
      "Step 90: Average train loss: 0.0154\n",
      "Step 95: Average train loss: 0.0154\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 248961.421875\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 286245.375\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 286085.125\n",
      "Step 0: Average train loss: 0.0146\n",
      "Step 5: Average train loss: 0.0146\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0145\n",
      "Step 50: Average train loss: 0.0145\n",
      "Step 55: Average train loss: 0.0145\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0144\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 300518.46875\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 203694.9375\n",
      "Step 0: Average train loss: 0.0136\n",
      "Step 5: Average train loss: 0.0136\n",
      "Step 10: Average train loss: 0.0136\n",
      "Step 15: Average train loss: 0.0136\n",
      "Step 20: Average train loss: 0.0136\n",
      "Step 25: Average train loss: 0.0136\n",
      "Step 30: Average train loss: 0.0136\n",
      "Step 35: Average train loss: 0.0136\n",
      "Step 40: Average train loss: 0.0136\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0135\n",
      "Step 75: Average train loss: 0.0135\n",
      "Step 80: Average train loss: 0.0135\n",
      "Step 85: Average train loss: 0.0135\n",
      "Step 90: Average train loss: 0.0135\n",
      "Step 95: Average train loss: 0.0135\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 289047.25\n",
      "Step 0: Average train loss: 0.0140\n",
      "Step 5: Average train loss: 0.0140\n",
      "Step 10: Average train loss: 0.0140\n",
      "Step 15: Average train loss: 0.0140\n",
      "Step 20: Average train loss: 0.0140\n",
      "Step 25: Average train loss: 0.0139\n",
      "Step 30: Average train loss: 0.0139\n",
      "Step 35: Average train loss: 0.0139\n",
      "Step 40: Average train loss: 0.0139\n",
      "Step 45: Average train loss: 0.0139\n",
      "Step 50: Average train loss: 0.0139\n",
      "Step 55: Average train loss: 0.0139\n",
      "Step 60: Average train loss: 0.0139\n",
      "Step 65: Average train loss: 0.0139\n",
      "Step 70: Average train loss: 0.0139\n",
      "Step 75: Average train loss: 0.0139\n",
      "Step 80: Average train loss: 0.0138\n",
      "Step 85: Average train loss: 0.0138\n",
      "Step 90: Average train loss: 0.0138\n",
      "Step 95: Average train loss: 0.0138\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 298016.65625\n",
      "Step 0: Average train loss: 0.0141\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0140\n",
      "Step 30: Average train loss: 0.0140\n",
      "Step 35: Average train loss: 0.0140\n",
      "Step 40: Average train loss: 0.0140\n",
      "Step 45: Average train loss: 0.0140\n",
      "Step 50: Average train loss: 0.0140\n",
      "Step 55: Average train loss: 0.0140\n",
      "Step 60: Average train loss: 0.0140\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 394914.0\n",
      "Step 0: Average train loss: 0.0151\n",
      "Step 5: Average train loss: 0.0151\n",
      "Step 10: Average train loss: 0.0151\n",
      "Step 15: Average train loss: 0.0151\n",
      "Step 20: Average train loss: 0.0151\n",
      "Step 25: Average train loss: 0.0151\n",
      "Step 30: Average train loss: 0.0151\n",
      "Step 35: Average train loss: 0.0151\n",
      "Step 40: Average train loss: 0.0151\n",
      "Step 45: Average train loss: 0.0151\n",
      "Step 50: Average train loss: 0.0151\n",
      "Step 55: Average train loss: 0.0150\n",
      "Step 60: Average train loss: 0.0150\n",
      "Step 65: Average train loss: 0.0150\n",
      "Step 70: Average train loss: 0.0150\n",
      "Step 75: Average train loss: 0.0150\n",
      "Step 80: Average train loss: 0.0150\n",
      "Step 85: Average train loss: 0.0150\n",
      "Step 90: Average train loss: 0.0150\n",
      "Step 95: Average train loss: 0.0150\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 414459.28125\n",
      "Step 0: Average train loss: 0.0160\n",
      "Step 5: Average train loss: 0.0160\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0160\n",
      "Step 30: Average train loss: 0.0160\n",
      "Step 35: Average train loss: 0.0160\n",
      "Step 40: Average train loss: 0.0160\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0160\n",
      "Step 90: Average train loss: 0.0160\n",
      "Step 95: Average train loss: 0.0160\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 388363.65625\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0157\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0156\n",
      "Step 70: Average train loss: 0.0156\n",
      "Step 75: Average train loss: 0.0156\n",
      "Step 80: Average train loss: 0.0156\n",
      "Step 85: Average train loss: 0.0156\n",
      "Step 90: Average train loss: 0.0156\n",
      "Step 95: Average train loss: 0.0156\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 610730.9375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 5]) torch.Size([140, 24, 5]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0437 | Average test loss: 0.0257\n",
      "Step 5: Average train loss: 0.0162 | Average test loss: 0.0120\n",
      "Step 10: Average train loss: 0.0144 | Average test loss: 0.0124\n",
      "Step 15: Average train loss: 0.0099 | Average test loss: 0.0089\n",
      "Step 20: Average train loss: 0.0101 | Average test loss: 0.0088\n",
      "Step 25: Average train loss: 0.0098 | Average test loss: 0.0086\n",
      "Step 30: Average train loss: 0.0095 | Average test loss: 0.0084\n",
      "Step 35: Average train loss: 0.0094 | Average test loss: 0.0083\n",
      "Step 40: Average train loss: 0.0094 | Average test loss: 0.0082\n",
      "Step 45: Average train loss: 0.0093 | Average test loss: 0.0082\n",
      "Step 50: Average train loss: 0.0094 | Average test loss: 0.0084\n",
      "Step 55: Average train loss: 0.0092 | Average test loss: 0.0082\n",
      "Step 60: Average train loss: 0.0101 | Average test loss: 0.0092\n",
      "Step 65: Average train loss: 0.0092 | Average test loss: 0.0082\n",
      "Step 70: Average train loss: 0.0096 | Average test loss: 0.0084\n",
      "Step 75: Average train loss: 0.0094 | Average test loss: 0.0088\n",
      "Step 80: Average train loss: 0.0092 | Average test loss: 0.0084\n",
      "Step 85: Average train loss: 0.0089 | Average test loss: 0.0079\n",
      "Step 90: Average train loss: 0.0091 | Average test loss: 0.0085\n",
      "Step 95: Average train loss: 0.0097 | Average test loss: 0.0083\n",
      "Best Epoch: 85\n",
      "Shape of data:  torch.Size([30, 24, 5]) torch.Size([30, 24, 5]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 63649.16015625\n",
      "Step 0: Average train loss: 0.0168\n",
      "Step 5: Average train loss: 0.0167\n",
      "Step 10: Average train loss: 0.0167\n",
      "Step 15: Average train loss: 0.0167\n",
      "Step 20: Average train loss: 0.0167\n",
      "Step 25: Average train loss: 0.0167\n",
      "Step 30: Average train loss: 0.0166\n",
      "Step 35: Average train loss: 0.0166\n",
      "Step 40: Average train loss: 0.0166\n",
      "Step 45: Average train loss: 0.0166\n",
      "Step 50: Average train loss: 0.0165\n",
      "Step 55: Average train loss: 0.0165\n",
      "Step 60: Average train loss: 0.0165\n",
      "Step 65: Average train loss: 0.0165\n",
      "Step 70: Average train loss: 0.0164\n",
      "Step 75: Average train loss: 0.0164\n",
      "Step 80: Average train loss: 0.0164\n",
      "Step 85: Average train loss: 0.0164\n",
      "Step 90: Average train loss: 0.0163\n",
      "Step 95: Average train loss: 0.0163\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 70596.6484375\n",
      "Step 0: Average train loss: 0.0169\n",
      "Step 5: Average train loss: 0.0168\n",
      "Step 10: Average train loss: 0.0168\n",
      "Step 15: Average train loss: 0.0167\n",
      "Step 20: Average train loss: 0.0167\n",
      "Step 25: Average train loss: 0.0167\n",
      "Step 30: Average train loss: 0.0166\n",
      "Step 35: Average train loss: 0.0166\n",
      "Step 40: Average train loss: 0.0165\n",
      "Step 45: Average train loss: 0.0165\n",
      "Step 50: Average train loss: 0.0164\n",
      "Step 55: Average train loss: 0.0164\n",
      "Step 60: Average train loss: 0.0164\n",
      "Step 65: Average train loss: 0.0163\n",
      "Step 70: Average train loss: 0.0163\n",
      "Step 75: Average train loss: 0.0162\n",
      "Step 80: Average train loss: 0.0162\n",
      "Step 85: Average train loss: 0.0162\n",
      "Step 90: Average train loss: 0.0161\n",
      "Step 95: Average train loss: 0.0161\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 53494.171875\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0156\n",
      "Step 20: Average train loss: 0.0156\n",
      "Step 25: Average train loss: 0.0155\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0154\n",
      "Step 45: Average train loss: 0.0154\n",
      "Step 50: Average train loss: 0.0154\n",
      "Step 55: Average train loss: 0.0153\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0152\n",
      "Step 75: Average train loss: 0.0152\n",
      "Step 80: Average train loss: 0.0151\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0150\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 43828.33984375\n",
      "Step 0: Average train loss: 0.0139\n",
      "Step 5: Average train loss: 0.0138\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0136\n",
      "Step 25: Average train loss: 0.0136\n",
      "Step 30: Average train loss: 0.0136\n",
      "Step 35: Average train loss: 0.0135\n",
      "Step 40: Average train loss: 0.0135\n",
      "Step 45: Average train loss: 0.0134\n",
      "Step 50: Average train loss: 0.0134\n",
      "Step 55: Average train loss: 0.0133\n",
      "Step 60: Average train loss: 0.0133\n",
      "Step 65: Average train loss: 0.0132\n",
      "Step 70: Average train loss: 0.0132\n",
      "Step 75: Average train loss: 0.0131\n",
      "Step 80: Average train loss: 0.0131\n",
      "Step 85: Average train loss: 0.0130\n",
      "Step 90: Average train loss: 0.0130\n",
      "Step 95: Average train loss: 0.0130\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 27635.33984375\n",
      "Step 0: Average train loss: 0.0110\n",
      "Step 5: Average train loss: 0.0110\n",
      "Step 10: Average train loss: 0.0109\n",
      "Step 15: Average train loss: 0.0109\n",
      "Step 20: Average train loss: 0.0108\n",
      "Step 25: Average train loss: 0.0108\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0107\n",
      "Step 40: Average train loss: 0.0107\n",
      "Step 45: Average train loss: 0.0106\n",
      "Step 50: Average train loss: 0.0106\n",
      "Step 55: Average train loss: 0.0105\n",
      "Step 60: Average train loss: 0.0105\n",
      "Step 65: Average train loss: 0.0104\n",
      "Step 70: Average train loss: 0.0104\n",
      "Step 75: Average train loss: 0.0104\n",
      "Step 80: Average train loss: 0.0103\n",
      "Step 85: Average train loss: 0.0103\n",
      "Step 90: Average train loss: 0.0103\n",
      "Step 95: Average train loss: 0.0102\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 26217.27734375\n",
      "Step 0: Average train loss: 0.0103\n",
      "Step 5: Average train loss: 0.0103\n",
      "Step 10: Average train loss: 0.0103\n",
      "Step 15: Average train loss: 0.0102\n",
      "Step 20: Average train loss: 0.0102\n",
      "Step 25: Average train loss: 0.0101\n",
      "Step 30: Average train loss: 0.0101\n",
      "Step 35: Average train loss: 0.0101\n",
      "Step 40: Average train loss: 0.0100\n",
      "Step 45: Average train loss: 0.0100\n",
      "Step 50: Average train loss: 0.0100\n",
      "Step 55: Average train loss: 0.0099\n",
      "Step 60: Average train loss: 0.0099\n",
      "Step 65: Average train loss: 0.0099\n",
      "Step 70: Average train loss: 0.0099\n",
      "Step 75: Average train loss: 0.0098\n",
      "Step 80: Average train loss: 0.0098\n",
      "Step 85: Average train loss: 0.0098\n",
      "Step 90: Average train loss: 0.0097\n",
      "Step 95: Average train loss: 0.0097\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 18388.974609375\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0087\n",
      "Step 10: Average train loss: 0.0087\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0085\n",
      "Step 40: Average train loss: 0.0085\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0084\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0084\n",
      "Step 75: Average train loss: 0.0084\n",
      "Step 80: Average train loss: 0.0084\n",
      "Step 85: Average train loss: 0.0083\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 11899.84765625\n",
      "Step 0: Average train loss: 0.0073\n",
      "Step 5: Average train loss: 0.0072\n",
      "Step 10: Average train loss: 0.0072\n",
      "Step 15: Average train loss: 0.0072\n",
      "Step 20: Average train loss: 0.0072\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 13107.2529296875\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 19670.935546875\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0065\n",
      "Step 30: Average train loss: 0.0065\n",
      "Step 35: Average train loss: 0.0065\n",
      "Step 40: Average train loss: 0.0065\n",
      "Step 45: Average train loss: 0.0065\n",
      "Step 50: Average train loss: 0.0065\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 33007.8984375\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0065\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 26984.712890625\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', inv_limit=True, HP_tuning=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('is_day')\n",
    "    features.remove('PoA')\n",
    "    features.remove('T_PV')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "    rmse.loc[(5, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 8]) torch.Size([140, 24, 8]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0549 | Average test loss: 0.0359\n",
      "Step 5: Average train loss: 0.0318 | Average test loss: 0.0241\n",
      "Step 10: Average train loss: 0.0121 | Average test loss: 0.0103\n",
      "Step 15: Average train loss: 0.0110 | Average test loss: 0.0101\n",
      "Step 20: Average train loss: 0.0107 | Average test loss: 0.0104\n",
      "Step 25: Average train loss: 0.0105 | Average test loss: 0.0105\n",
      "Step 30: Average train loss: 0.0103 | Average test loss: 0.0103\n",
      "Step 35: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 40: Average train loss: 0.0100 | Average test loss: 0.0097\n",
      "Step 45: Average train loss: 0.0096 | Average test loss: 0.0094\n",
      "Step 50: Average train loss: 0.0096 | Average test loss: 0.0093\n",
      "Step 55: Average train loss: 0.0096 | Average test loss: 0.0092\n",
      "Step 60: Average train loss: 0.0096 | Average test loss: 0.0099\n",
      "Step 65: Average train loss: 0.0095 | Average test loss: 0.0095\n",
      "Step 70: Average train loss: 0.0093 | Average test loss: 0.0091\n",
      "Step 75: Average train loss: 0.0093 | Average test loss: 0.0092\n",
      "Step 80: Average train loss: 0.0093 | Average test loss: 0.0093\n",
      "Step 85: Average train loss: 0.0092 | Average test loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092 | Average test loss: 0.0090\n",
      "Step 95: Average train loss: 0.0091 | Average test loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 66327.8359375\n",
      "Step 0: Average train loss: 0.0106\n",
      "Step 5: Average train loss: 0.0106\n",
      "Step 10: Average train loss: 0.0106\n",
      "Step 15: Average train loss: 0.0106\n",
      "Step 20: Average train loss: 0.0105\n",
      "Step 25: Average train loss: 0.0105\n",
      "Step 30: Average train loss: 0.0105\n",
      "Step 35: Average train loss: 0.0105\n",
      "Step 40: Average train loss: 0.0105\n",
      "Step 45: Average train loss: 0.0105\n",
      "Step 50: Average train loss: 0.0104\n",
      "Step 55: Average train loss: 0.0104\n",
      "Step 60: Average train loss: 0.0104\n",
      "Step 65: Average train loss: 0.0104\n",
      "Step 70: Average train loss: 0.0104\n",
      "Step 75: Average train loss: 0.0104\n",
      "Step 80: Average train loss: 0.0103\n",
      "Step 85: Average train loss: 0.0103\n",
      "Step 90: Average train loss: 0.0103\n",
      "Step 95: Average train loss: 0.0103\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 63321.83203125\n",
      "Step 0: Average train loss: 0.0105\n",
      "Step 5: Average train loss: 0.0105\n",
      "Step 10: Average train loss: 0.0105\n",
      "Step 15: Average train loss: 0.0105\n",
      "Step 20: Average train loss: 0.0104\n",
      "Step 25: Average train loss: 0.0104\n",
      "Step 30: Average train loss: 0.0104\n",
      "Step 35: Average train loss: 0.0104\n",
      "Step 40: Average train loss: 0.0104\n",
      "Step 45: Average train loss: 0.0104\n",
      "Step 50: Average train loss: 0.0103\n",
      "Step 55: Average train loss: 0.0103\n",
      "Step 60: Average train loss: 0.0103\n",
      "Step 65: Average train loss: 0.0103\n",
      "Step 70: Average train loss: 0.0103\n",
      "Step 75: Average train loss: 0.0103\n",
      "Step 80: Average train loss: 0.0102\n",
      "Step 85: Average train loss: 0.0102\n",
      "Step 90: Average train loss: 0.0102\n",
      "Step 95: Average train loss: 0.0102\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 46253.45703125\n",
      "Step 0: Average train loss: 0.0090\n",
      "Step 5: Average train loss: 0.0090\n",
      "Step 10: Average train loss: 0.0090\n",
      "Step 15: Average train loss: 0.0090\n",
      "Step 20: Average train loss: 0.0090\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0089\n",
      "Step 35: Average train loss: 0.0089\n",
      "Step 40: Average train loss: 0.0089\n",
      "Step 45: Average train loss: 0.0089\n",
      "Step 50: Average train loss: 0.0089\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0089\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0088\n",
      "Step 75: Average train loss: 0.0088\n",
      "Step 80: Average train loss: 0.0088\n",
      "Step 85: Average train loss: 0.0088\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0088\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50039.1875\n",
      "Step 0: Average train loss: 0.0085\n",
      "Step 5: Average train loss: 0.0085\n",
      "Step 10: Average train loss: 0.0084\n",
      "Step 15: Average train loss: 0.0084\n",
      "Step 20: Average train loss: 0.0084\n",
      "Step 25: Average train loss: 0.0084\n",
      "Step 30: Average train loss: 0.0084\n",
      "Step 35: Average train loss: 0.0084\n",
      "Step 40: Average train loss: 0.0084\n",
      "Step 45: Average train loss: 0.0084\n",
      "Step 50: Average train loss: 0.0084\n",
      "Step 55: Average train loss: 0.0084\n",
      "Step 60: Average train loss: 0.0083\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0083\n",
      "Step 80: Average train loss: 0.0083\n",
      "Step 85: Average train loss: 0.0083\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 48101.2734375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0077\n",
      "Step 10: Average train loss: 0.0077\n",
      "Step 15: Average train loss: 0.0077\n",
      "Step 20: Average train loss: 0.0077\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 39744.11328125\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 27006.57421875\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0070\n",
      "Step 50: Average train loss: 0.0070\n",
      "Step 55: Average train loss: 0.0070\n",
      "Step 60: Average train loss: 0.0070\n",
      "Step 65: Average train loss: 0.0070\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 13015.3349609375\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 20818.412109375\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 36896.140625\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 54980.58984375\n",
      "Step 0: Average train loss: 0.0069\n",
      "Step 5: Average train loss: 0.0069\n",
      "Step 10: Average train loss: 0.0069\n",
      "Step 15: Average train loss: 0.0069\n",
      "Step 20: Average train loss: 0.0069\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 57795.7734375\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 80970.578125\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 8]) torch.Size([140, 24, 8]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0466 | Average test loss: 0.0260\n",
      "Step 5: Average train loss: 0.0194 | Average test loss: 0.0202\n",
      "Step 10: Average train loss: 0.0094 | Average test loss: 0.0081\n",
      "Step 15: Average train loss: 0.0091 | Average test loss: 0.0077\n",
      "Step 20: Average train loss: 0.0087 | Average test loss: 0.0074\n",
      "Step 25: Average train loss: 0.0085 | Average test loss: 0.0075\n",
      "Step 30: Average train loss: 0.0085 | Average test loss: 0.0076\n",
      "Step 35: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 40: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 45: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 50: Average train loss: 0.0082 | Average test loss: 0.0070\n",
      "Step 55: Average train loss: 0.0081 | Average test loss: 0.0069\n",
      "Step 60: Average train loss: 0.0080 | Average test loss: 0.0067\n",
      "Step 65: Average train loss: 0.0078 | Average test loss: 0.0065\n",
      "Step 70: Average train loss: 0.0078 | Average test loss: 0.0066\n",
      "Step 75: Average train loss: 0.0078 | Average test loss: 0.0063\n",
      "Step 80: Average train loss: 0.0077 | Average test loss: 0.0065\n",
      "Step 85: Average train loss: 0.0078 | Average test loss: 0.0066\n",
      "Step 90: Average train loss: 0.0078 | Average test loss: 0.0066\n",
      "Step 95: Average train loss: 0.0076 | Average test loss: 0.0060\n",
      "Best Epoch: 94\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 56829.3671875\n",
      "Step 0: Average train loss: 0.0119\n",
      "Step 5: Average train loss: 0.0119\n",
      "Step 10: Average train loss: 0.0119\n",
      "Step 15: Average train loss: 0.0119\n",
      "Step 20: Average train loss: 0.0118\n",
      "Step 25: Average train loss: 0.0118\n",
      "Step 30: Average train loss: 0.0118\n",
      "Step 35: Average train loss: 0.0118\n",
      "Step 40: Average train loss: 0.0117\n",
      "Step 45: Average train loss: 0.0117\n",
      "Step 50: Average train loss: 0.0117\n",
      "Step 55: Average train loss: 0.0117\n",
      "Step 60: Average train loss: 0.0116\n",
      "Step 65: Average train loss: 0.0116\n",
      "Step 70: Average train loss: 0.0116\n",
      "Step 75: Average train loss: 0.0116\n",
      "Step 80: Average train loss: 0.0115\n",
      "Step 85: Average train loss: 0.0115\n",
      "Step 90: Average train loss: 0.0115\n",
      "Step 95: Average train loss: 0.0115\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 44497.58984375\n",
      "Step 0: Average train loss: 0.0100\n",
      "Step 5: Average train loss: 0.0100\n",
      "Step 10: Average train loss: 0.0099\n",
      "Step 15: Average train loss: 0.0099\n",
      "Step 20: Average train loss: 0.0099\n",
      "Step 25: Average train loss: 0.0098\n",
      "Step 30: Average train loss: 0.0098\n",
      "Step 35: Average train loss: 0.0098\n",
      "Step 40: Average train loss: 0.0097\n",
      "Step 45: Average train loss: 0.0097\n",
      "Step 50: Average train loss: 0.0097\n",
      "Step 55: Average train loss: 0.0096\n",
      "Step 60: Average train loss: 0.0096\n",
      "Step 65: Average train loss: 0.0096\n",
      "Step 70: Average train loss: 0.0095\n",
      "Step 75: Average train loss: 0.0095\n",
      "Step 80: Average train loss: 0.0095\n",
      "Step 85: Average train loss: 0.0095\n",
      "Step 90: Average train loss: 0.0094\n",
      "Step 95: Average train loss: 0.0094\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 52221.8984375\n",
      "Step 0: Average train loss: 0.0101\n",
      "Step 5: Average train loss: 0.0101\n",
      "Step 10: Average train loss: 0.0101\n",
      "Step 15: Average train loss: 0.0101\n",
      "Step 20: Average train loss: 0.0100\n",
      "Step 25: Average train loss: 0.0100\n",
      "Step 30: Average train loss: 0.0100\n",
      "Step 35: Average train loss: 0.0100\n",
      "Step 40: Average train loss: 0.0099\n",
      "Step 45: Average train loss: 0.0099\n",
      "Step 50: Average train loss: 0.0099\n",
      "Step 55: Average train loss: 0.0098\n",
      "Step 60: Average train loss: 0.0098\n",
      "Step 65: Average train loss: 0.0098\n",
      "Step 70: Average train loss: 0.0098\n",
      "Step 75: Average train loss: 0.0098\n",
      "Step 80: Average train loss: 0.0097\n",
      "Step 85: Average train loss: 0.0097\n",
      "Step 90: Average train loss: 0.0097\n",
      "Step 95: Average train loss: 0.0097\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 33641.23828125\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0087\n",
      "Step 10: Average train loss: 0.0087\n",
      "Step 15: Average train loss: 0.0087\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0086\n",
      "Step 40: Average train loss: 0.0085\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0084\n",
      "Step 75: Average train loss: 0.0084\n",
      "Step 80: Average train loss: 0.0084\n",
      "Step 85: Average train loss: 0.0084\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 35668.40625\n",
      "Step 0: Average train loss: 0.0080\n",
      "Step 5: Average train loss: 0.0079\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0079\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0079\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23976.400390625\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0074\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 12949.861328125\n",
      "Step 0: Average train loss: 0.0063\n",
      "Step 5: Average train loss: 0.0063\n",
      "Step 10: Average train loss: 0.0063\n",
      "Step 15: Average train loss: 0.0063\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0063\n",
      "Step 55: Average train loss: 0.0063\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0063\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 8432.2763671875\n",
      "Step 0: Average train loss: 0.0053\n",
      "Step 5: Average train loss: 0.0053\n",
      "Step 10: Average train loss: 0.0053\n",
      "Step 15: Average train loss: 0.0053\n",
      "Step 20: Average train loss: 0.0053\n",
      "Step 25: Average train loss: 0.0053\n",
      "Step 30: Average train loss: 0.0053\n",
      "Step 35: Average train loss: 0.0053\n",
      "Step 40: Average train loss: 0.0053\n",
      "Step 45: Average train loss: 0.0053\n",
      "Step 50: Average train loss: 0.0053\n",
      "Step 55: Average train loss: 0.0053\n",
      "Step 60: Average train loss: 0.0053\n",
      "Step 65: Average train loss: 0.0053\n",
      "Step 70: Average train loss: 0.0053\n",
      "Step 75: Average train loss: 0.0053\n",
      "Step 80: Average train loss: 0.0053\n",
      "Step 85: Average train loss: 0.0053\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 11559.484375\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 14565.5927734375\n",
      "Step 0: Average train loss: 0.0052\n",
      "Step 5: Average train loss: 0.0052\n",
      "Step 10: Average train loss: 0.0052\n",
      "Step 15: Average train loss: 0.0052\n",
      "Step 20: Average train loss: 0.0052\n",
      "Step 25: Average train loss: 0.0052\n",
      "Step 30: Average train loss: 0.0052\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0051\n",
      "Step 55: Average train loss: 0.0051\n",
      "Step 60: Average train loss: 0.0051\n",
      "Step 65: Average train loss: 0.0051\n",
      "Step 70: Average train loss: 0.0051\n",
      "Step 75: Average train loss: 0.0051\n",
      "Step 80: Average train loss: 0.0051\n",
      "Step 85: Average train loss: 0.0051\n",
      "Step 90: Average train loss: 0.0051\n",
      "Step 95: Average train loss: 0.0051\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 45715.2265625\n",
      "Step 0: Average train loss: 0.0065\n",
      "Step 5: Average train loss: 0.0065\n",
      "Step 10: Average train loss: 0.0065\n",
      "Step 15: Average train loss: 0.0065\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0065\n",
      "Step 30: Average train loss: 0.0065\n",
      "Step 35: Average train loss: 0.0065\n",
      "Step 40: Average train loss: 0.0065\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 38997.33203125\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 33348.30859375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 8]) torch.Size([144, 24, 8]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0426 | Average test loss: 0.0335\n",
      "Step 5: Average train loss: 0.0075 | Average test loss: 0.0029\n",
      "Step 10: Average train loss: 0.0061 | Average test loss: 0.0018\n",
      "Step 15: Average train loss: 0.0056 | Average test loss: 0.0017\n",
      "Step 20: Average train loss: 0.0054 | Average test loss: 0.0017\n",
      "Step 25: Average train loss: 0.0053 | Average test loss: 0.0017\n",
      "Step 30: Average train loss: 0.0052 | Average test loss: 0.0018\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 40: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 55: Average train loss: 0.0049 | Average test loss: 0.0022\n",
      "Step 60: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 70: Average train loss: 0.0048 | Average test loss: 0.0023\n",
      "Step 75: Average train loss: 0.0048 | Average test loss: 0.0023\n",
      "Step 80: Average train loss: 0.0048 | Average test loss: 0.0024\n",
      "Step 85: Average train loss: 0.0047 | Average test loss: 0.0024\n",
      "Step 90: Average train loss: 0.0047 | Average test loss: 0.0025\n",
      "Step 95: Average train loss: 0.0047 | Average test loss: 0.0026\n",
      "Best Epoch: 17\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 304459.75\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0161\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0161\n",
      "Step 30: Average train loss: 0.0161\n",
      "Step 35: Average train loss: 0.0161\n",
      "Step 40: Average train loss: 0.0161\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0160\n",
      "Step 90: Average train loss: 0.0160\n",
      "Step 95: Average train loss: 0.0160\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 299822.75\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0158\n",
      "Step 20: Average train loss: 0.0158\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0157\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0156\n",
      "Step 80: Average train loss: 0.0156\n",
      "Step 85: Average train loss: 0.0156\n",
      "Step 90: Average train loss: 0.0156\n",
      "Step 95: Average train loss: 0.0156\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 256214.9375\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0150\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0149\n",
      "Step 20: Average train loss: 0.0149\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0149\n",
      "Step 50: Average train loss: 0.0149\n",
      "Step 55: Average train loss: 0.0149\n",
      "Step 60: Average train loss: 0.0148\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0148\n",
      "Step 90: Average train loss: 0.0148\n",
      "Step 95: Average train loss: 0.0148\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 287599.5\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0149\n",
      "Step 10: Average train loss: 0.0149\n",
      "Step 15: Average train loss: 0.0149\n",
      "Step 20: Average train loss: 0.0149\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0148\n",
      "Step 50: Average train loss: 0.0148\n",
      "Step 55: Average train loss: 0.0148\n",
      "Step 60: Average train loss: 0.0148\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0147\n",
      "Step 90: Average train loss: 0.0147\n",
      "Step 95: Average train loss: 0.0147\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 284289.1875\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 303375.59375\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0147\n",
      "Step 75: Average train loss: 0.0147\n",
      "Step 80: Average train loss: 0.0147\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 200664.578125\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0137\n",
      "Step 35: Average train loss: 0.0137\n",
      "Step 40: Average train loss: 0.0137\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 293126.96875\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0142\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0141\n",
      "Step 85: Average train loss: 0.0141\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 304233.96875\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0142\n",
      "Step 35: Average train loss: 0.0142\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0141\n",
      "Step 85: Average train loss: 0.0141\n",
      "Step 90: Average train loss: 0.0141\n",
      "Step 95: Average train loss: 0.0141\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 412949.78125\n",
      "Step 0: Average train loss: 0.0154\n",
      "Step 5: Average train loss: 0.0153\n",
      "Step 10: Average train loss: 0.0153\n",
      "Step 15: Average train loss: 0.0153\n",
      "Step 20: Average train loss: 0.0153\n",
      "Step 25: Average train loss: 0.0153\n",
      "Step 30: Average train loss: 0.0153\n",
      "Step 35: Average train loss: 0.0153\n",
      "Step 40: Average train loss: 0.0153\n",
      "Step 45: Average train loss: 0.0153\n",
      "Step 50: Average train loss: 0.0153\n",
      "Step 55: Average train loss: 0.0153\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0152\n",
      "Step 75: Average train loss: 0.0152\n",
      "Step 80: Average train loss: 0.0152\n",
      "Step 85: Average train loss: 0.0152\n",
      "Step 90: Average train loss: 0.0152\n",
      "Step 95: Average train loss: 0.0152\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 422137.4375\n",
      "Step 0: Average train loss: 0.0163\n",
      "Step 5: Average train loss: 0.0163\n",
      "Step 10: Average train loss: 0.0163\n",
      "Step 15: Average train loss: 0.0163\n",
      "Step 20: Average train loss: 0.0163\n",
      "Step 25: Average train loss: 0.0163\n",
      "Step 30: Average train loss: 0.0163\n",
      "Step 35: Average train loss: 0.0163\n",
      "Step 40: Average train loss: 0.0163\n",
      "Step 45: Average train loss: 0.0162\n",
      "Step 50: Average train loss: 0.0162\n",
      "Step 55: Average train loss: 0.0162\n",
      "Step 60: Average train loss: 0.0162\n",
      "Step 65: Average train loss: 0.0162\n",
      "Step 70: Average train loss: 0.0162\n",
      "Step 75: Average train loss: 0.0162\n",
      "Step 80: Average train loss: 0.0162\n",
      "Step 85: Average train loss: 0.0162\n",
      "Step 90: Average train loss: 0.0162\n",
      "Step 95: Average train loss: 0.0162\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 384938.21875\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0158\n",
      "Step 20: Average train loss: 0.0158\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0158\n",
      "Step 45: Average train loss: 0.0158\n",
      "Step 50: Average train loss: 0.0158\n",
      "Step 55: Average train loss: 0.0158\n",
      "Step 60: Average train loss: 0.0158\n",
      "Step 65: Average train loss: 0.0158\n",
      "Step 70: Average train loss: 0.0158\n",
      "Step 75: Average train loss: 0.0158\n",
      "Step 80: Average train loss: 0.0158\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 560901.3125\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 8]) torch.Size([140, 24, 8]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0394 | Average test loss: 0.0230\n",
      "Step 5: Average train loss: 0.0137 | Average test loss: 0.0177\n",
      "Step 10: Average train loss: 0.0095 | Average test loss: 0.0087\n",
      "Step 15: Average train loss: 0.0098 | Average test loss: 0.0095\n",
      "Step 20: Average train loss: 0.0095 | Average test loss: 0.0083\n",
      "Step 25: Average train loss: 0.0094 | Average test loss: 0.0086\n",
      "Step 30: Average train loss: 0.0094 | Average test loss: 0.0084\n",
      "Step 35: Average train loss: 0.0094 | Average test loss: 0.0089\n",
      "Step 40: Average train loss: 0.0090 | Average test loss: 0.0080\n",
      "Step 45: Average train loss: 0.0093 | Average test loss: 0.0083\n",
      "Step 50: Average train loss: 0.0087 | Average test loss: 0.0077\n",
      "Step 55: Average train loss: 0.0096 | Average test loss: 0.0094\n",
      "Step 60: Average train loss: 0.0088 | Average test loss: 0.0077\n",
      "Step 65: Average train loss: 0.0085 | Average test loss: 0.0074\n",
      "Step 70: Average train loss: 0.0087 | Average test loss: 0.0079\n",
      "Step 75: Average train loss: 0.0084 | Average test loss: 0.0078\n",
      "Step 80: Average train loss: 0.0085 | Average test loss: 0.0075\n",
      "Step 85: Average train loss: 0.0085 | Average test loss: 0.0075\n",
      "Step 90: Average train loss: 0.0081 | Average test loss: 0.0073\n",
      "Step 95: Average train loss: 0.0081 | Average test loss: 0.0073\n",
      "Best Epoch: 93\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 69264.28125\n",
      "Step 0: Average train loss: 0.0182\n",
      "Step 5: Average train loss: 0.0182\n",
      "Step 10: Average train loss: 0.0182\n",
      "Step 15: Average train loss: 0.0182\n",
      "Step 20: Average train loss: 0.0181\n",
      "Step 25: Average train loss: 0.0181\n",
      "Step 30: Average train loss: 0.0181\n",
      "Step 35: Average train loss: 0.0181\n",
      "Step 40: Average train loss: 0.0180\n",
      "Step 45: Average train loss: 0.0180\n",
      "Step 50: Average train loss: 0.0180\n",
      "Step 55: Average train loss: 0.0180\n",
      "Step 60: Average train loss: 0.0179\n",
      "Step 65: Average train loss: 0.0179\n",
      "Step 70: Average train loss: 0.0179\n",
      "Step 75: Average train loss: 0.0179\n",
      "Step 80: Average train loss: 0.0178\n",
      "Step 85: Average train loss: 0.0178\n",
      "Step 90: Average train loss: 0.0178\n",
      "Step 95: Average train loss: 0.0178\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 66671.953125\n",
      "Step 0: Average train loss: 0.0170\n",
      "Step 5: Average train loss: 0.0170\n",
      "Step 10: Average train loss: 0.0169\n",
      "Step 15: Average train loss: 0.0169\n",
      "Step 20: Average train loss: 0.0169\n",
      "Step 25: Average train loss: 0.0168\n",
      "Step 30: Average train loss: 0.0168\n",
      "Step 35: Average train loss: 0.0167\n",
      "Step 40: Average train loss: 0.0167\n",
      "Step 45: Average train loss: 0.0167\n",
      "Step 50: Average train loss: 0.0166\n",
      "Step 55: Average train loss: 0.0166\n",
      "Step 60: Average train loss: 0.0165\n",
      "Step 65: Average train loss: 0.0165\n",
      "Step 70: Average train loss: 0.0165\n",
      "Step 75: Average train loss: 0.0164\n",
      "Step 80: Average train loss: 0.0164\n",
      "Step 85: Average train loss: 0.0164\n",
      "Step 90: Average train loss: 0.0163\n",
      "Step 95: Average train loss: 0.0163\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 51524.5390625\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0156\n",
      "Step 20: Average train loss: 0.0156\n",
      "Step 25: Average train loss: 0.0156\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0154\n",
      "Step 45: Average train loss: 0.0154\n",
      "Step 50: Average train loss: 0.0154\n",
      "Step 55: Average train loss: 0.0153\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0152\n",
      "Step 75: Average train loss: 0.0152\n",
      "Step 80: Average train loss: 0.0152\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 48192.4765625\n",
      "Step 0: Average train loss: 0.0143\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0140\n",
      "Step 30: Average train loss: 0.0140\n",
      "Step 35: Average train loss: 0.0139\n",
      "Step 40: Average train loss: 0.0139\n",
      "Step 45: Average train loss: 0.0139\n",
      "Step 50: Average train loss: 0.0138\n",
      "Step 55: Average train loss: 0.0138\n",
      "Step 60: Average train loss: 0.0137\n",
      "Step 65: Average train loss: 0.0137\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0135\n",
      "Step 85: Average train loss: 0.0135\n",
      "Step 90: Average train loss: 0.0135\n",
      "Step 95: Average train loss: 0.0134\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 32585.72265625\n",
      "Step 0: Average train loss: 0.0118\n",
      "Step 5: Average train loss: 0.0117\n",
      "Step 10: Average train loss: 0.0117\n",
      "Step 15: Average train loss: 0.0116\n",
      "Step 20: Average train loss: 0.0116\n",
      "Step 25: Average train loss: 0.0115\n",
      "Step 30: Average train loss: 0.0115\n",
      "Step 35: Average train loss: 0.0114\n",
      "Step 40: Average train loss: 0.0114\n",
      "Step 45: Average train loss: 0.0113\n",
      "Step 50: Average train loss: 0.0113\n",
      "Step 55: Average train loss: 0.0112\n",
      "Step 60: Average train loss: 0.0112\n",
      "Step 65: Average train loss: 0.0111\n",
      "Step 70: Average train loss: 0.0111\n",
      "Step 75: Average train loss: 0.0110\n",
      "Step 80: Average train loss: 0.0110\n",
      "Step 85: Average train loss: 0.0110\n",
      "Step 90: Average train loss: 0.0109\n",
      "Step 95: Average train loss: 0.0109\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 34694.19140625\n",
      "Step 0: Average train loss: 0.0112\n",
      "Step 5: Average train loss: 0.0111\n",
      "Step 10: Average train loss: 0.0111\n",
      "Step 15: Average train loss: 0.0110\n",
      "Step 20: Average train loss: 0.0110\n",
      "Step 25: Average train loss: 0.0110\n",
      "Step 30: Average train loss: 0.0109\n",
      "Step 35: Average train loss: 0.0109\n",
      "Step 40: Average train loss: 0.0108\n",
      "Step 45: Average train loss: 0.0108\n",
      "Step 50: Average train loss: 0.0108\n",
      "Step 55: Average train loss: 0.0107\n",
      "Step 60: Average train loss: 0.0107\n",
      "Step 65: Average train loss: 0.0107\n",
      "Step 70: Average train loss: 0.0106\n",
      "Step 75: Average train loss: 0.0106\n",
      "Step 80: Average train loss: 0.0105\n",
      "Step 85: Average train loss: 0.0105\n",
      "Step 90: Average train loss: 0.0105\n",
      "Step 95: Average train loss: 0.0104\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 25985.560546875\n",
      "Step 0: Average train loss: 0.0097\n",
      "Step 5: Average train loss: 0.0097\n",
      "Step 10: Average train loss: 0.0096\n",
      "Step 15: Average train loss: 0.0096\n",
      "Step 20: Average train loss: 0.0096\n",
      "Step 25: Average train loss: 0.0096\n",
      "Step 30: Average train loss: 0.0095\n",
      "Step 35: Average train loss: 0.0095\n",
      "Step 40: Average train loss: 0.0095\n",
      "Step 45: Average train loss: 0.0094\n",
      "Step 50: Average train loss: 0.0094\n",
      "Step 55: Average train loss: 0.0094\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0093\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0092\n",
      "Step 85: Average train loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092\n",
      "Step 95: Average train loss: 0.0092\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 14674.171875\n",
      "Step 0: Average train loss: 0.0080\n",
      "Step 5: Average train loss: 0.0080\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0079\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 17193.77734375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0075\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0072\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 22006.974609375\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0067\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 31828.986328125\n",
      "Step 0: Average train loss: 0.0069\n",
      "Step 5: Average train loss: 0.0069\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 28419.140625\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', decomp=True, HP_tuning=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "    rmse.loc[(6, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208.705463</td>\n",
       "      <td>174.537122</td>\n",
       "      <td>558.925574</td>\n",
       "      <td>193.606811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210.809443</td>\n",
       "      <td>177.056246</td>\n",
       "      <td>558.312261</td>\n",
       "      <td>196.365235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>209.488528</td>\n",
       "      <td>172.579986</td>\n",
       "      <td>559.99105</td>\n",
       "      <td>186.733048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211.101287</td>\n",
       "      <td>175.709857</td>\n",
       "      <td>559.065218</td>\n",
       "      <td>195.548412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209.350613</td>\n",
       "      <td>175.752439</td>\n",
       "      <td>559.697938</td>\n",
       "      <td>205.044143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>212.177251</td>\n",
       "      <td>177.836177</td>\n",
       "      <td>557.451531</td>\n",
       "      <td>184.878216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209.517709</td>\n",
       "      <td>177.757179</td>\n",
       "      <td>560.52506</td>\n",
       "      <td>192.584326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3\n",
       "0  208.705463  174.537122  558.925574  193.606811\n",
       "1  210.809443  177.056246  558.312261  196.365235\n",
       "2  209.488528  172.579986   559.99105  186.733048\n",
       "3  211.101287  175.709857  559.065218  195.548412\n",
       "4  209.350613  175.752439  559.697938  205.044143\n",
       "5  212.177251  177.836177  557.451531  184.878216\n",
       "6  209.517709  177.757179   560.52506  192.584326"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse.to_pickle(\"sensitivity_analysis/physics_measures_rmse.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>233.122574</td>\n",
       "      <td>190.270538</td>\n",
       "      <td>550.991089</td>\n",
       "      <td>247.158524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>225.351425</td>\n",
       "      <td>196.819992</td>\n",
       "      <td>548.80603</td>\n",
       "      <td>256.271393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>224.424225</td>\n",
       "      <td>190.688934</td>\n",
       "      <td>549.871643</td>\n",
       "      <td>240.238693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>241.284012</td>\n",
       "      <td>197.35173</td>\n",
       "      <td>551.739075</td>\n",
       "      <td>240.309647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>232.633408</td>\n",
       "      <td>197.584274</td>\n",
       "      <td>553.129639</td>\n",
       "      <td>253.543076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <td>227.355011</td>\n",
       "      <td>195.83049</td>\n",
       "      <td>550.597046</td>\n",
       "      <td>239.364716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <td>231.557129</td>\n",
       "      <td>199.937164</td>\n",
       "      <td>552.372314</td>\n",
       "      <td>243.825119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0           1           2           3\n",
       "0 0  233.122574  190.270538  550.991089  247.158524\n",
       "1 0  225.351425  196.819992   548.80603  256.271393\n",
       "2 0  224.424225  190.688934  549.871643  240.238693\n",
       "3 0  241.284012   197.35173  551.739075  240.309647\n",
       "4 0  232.633408  197.584274  553.129639  253.543076\n",
       "5 0  227.355011   195.83049  550.597046  239.364716\n",
       "6 0  231.557129  199.937164  552.372314  243.825119"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physics_rmse = pd.read_pickle(\"sensitivity_analysis/physics_measures_rmse.pkl\")\n",
    "physics_rmse.loc[(slice(None), 0),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-physics-informed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Random Forest to determine importances of all features and then put the; in this order of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (12582, 13)\n",
      "Training Labels Shape: (12582,)\n",
      "Testing Features Shape: (4194, 13)\n",
      "Testing Labels Shape: (4194,)\n",
      "238.62298480319606 W\n",
      "Variable: downward_surface_SW_flux Importance: 0.81\n",
      "Variable: P_24h_shift          Importance: 0.03\n",
      "Variable: direct_surface_SW_flux Importance: 0.03\n",
      "Variable: hour_cos             Importance: 0.03\n",
      "Variable: diffuse_surface_SW_flux Importance: 0.02\n",
      "Variable: relative_humidity_1_5m Importance: 0.02\n",
      "Variable: temperature_1_5m     Importance: 0.02\n",
      "Variable: wind_speed_10m       Importance: 0.02\n",
      "Variable: pressure_MSL         Importance: 0.02\n",
      "Variable: hour_sin             Importance: 0.01\n",
      "Variable: month_cos            Importance: 0.01\n",
      "Variable: total_cloud_amount   Importance: 0.01\n",
      "Variable: month_sin            Importance: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "installation_int = 0\n",
    "source_data,_,_ = data_handeler(installation_int, \"nwp\", \"nwp\", \"nwp\", HP_tuning=False)\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(source_data['P'])\n",
    "# Remove the labels from the source_data\n",
    "# axis 1 refers to the columns\n",
    "source_data= source_data.drop('P', axis = 1)\n",
    "# Saving feature names for later use\n",
    "ftr_file = \"features/ft_no_phys_sa.pkl\"\n",
    "if os.path.isfile(ftr_file):\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        feature_list = pickle.load(f)\n",
    "# Convert to numpy array\n",
    "source_data = source_data[feature_list]\n",
    "source_data = np.array(source_data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(source_data, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "#Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = np.sqrt(np.mean(np.square(predictions - test_labels)))\n",
    "# Print out rmse\n",
    "print(errors, 'W')\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_np = pd.read_pickle(\"sensitivity_analysis/nb_features/rmse_no_physics.pkl\")\n",
    "zs_rmse_np = rmse_np.loc[(slice(None), 0),:]\n",
    "zs_rmse_np = zs_rmse_np.droplevel(1)\n",
    "for site in range(4):\n",
    "    plt.figure()\n",
    "    plt.plot(zs_rmse_np[site])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics-informed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (12582, 16)\n",
      "Training Labels Shape: (12582,)\n",
      "Testing Features Shape: (4194, 16)\n",
      "Testing Labels Shape: (4194,)\n",
      "241.21926501974775 W\n",
      "Variable: PoA                  Importance: 0.81\n",
      "Variable: P_24h_shift          Importance: 0.03\n",
      "Variable: downward_surface_SW_flux Importance: 0.03\n",
      "Variable: diffuse_surface_SW_flux Importance: 0.02\n",
      "Variable: T_PV                 Importance: 0.02\n",
      "Variable: wind_speed_10m       Importance: 0.02\n",
      "Variable: relative_humidity_1_5m Importance: 0.01\n",
      "Variable: direct_surface_SW_flux Importance: 0.01\n",
      "Variable: month_sin            Importance: 0.01\n",
      "Variable: hour_sin             Importance: 0.01\n",
      "Variable: temperature_1_5m     Importance: 0.01\n",
      "Variable: pressure_MSL         Importance: 0.01\n",
      "Variable: is_day               Importance: 0.0\n",
      "Variable: month_cos            Importance: 0.0\n",
      "Variable: hour_cos             Importance: 0.0\n",
      "Variable: total_cloud_amount   Importance: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installation_int = 0\n",
    "source_data,_,_ = data_handeler(installation_int, \"nwp\", \"nwp\", \"nwp\", HP_tuning=False)\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(source_data['P'])\n",
    "# Remove the labels from the source_data\n",
    "# axis 1 refers to the columns\n",
    "source_data= source_data.drop('P', axis = 1)\n",
    "# Saving feature names for later use\n",
    "ftr_file = \"features/ft_phys_sa.pkl\"\n",
    "if os.path.isfile(ftr_file):\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        feature_list = pickle.load(f)\n",
    "# Convert to numpy array\n",
    "source_data = source_data[feature_list]\n",
    "source_data = np.array(source_data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(source_data, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "#Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = np.sqrt(np.mean(np.square(predictions - test_labels)))\n",
    "# Print out rmse\n",
    "print(errors, 'W')\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_p = pd.read_pickle(\"sensitivity_analysis/nb_features/rmse_physics.pkl\")\n",
    "zs_rmse_p = rmse_p.loc[(slice(None), 0),:]\n",
    "zs_rmse_p = zs_rmse_p.droplevel(1)\n",
    "for site in range(4):\n",
    "    plt.figure()\n",
    "    plt.plot(zs_rmse_p[site])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM\n",
    "- RF\n",
    "- biLSTM\n",
    "- seq2seq LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (8484, 7)\n",
      "Training Labels Shape: (8484,)\n",
      "Testing Features Shape: (2828, 7)\n",
      "Testing Labels Shape: (2828,)\n",
      "Test Error:  293.0567106145216 W\n",
      "Zero-shot RMSE:  276.8213690782687 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (8484, 9)\n",
      "Training Labels Shape: (8484,)\n",
      "Testing Features Shape: (2828, 9)\n",
      "Testing Labels Shape: (2828,)\n",
      "Test Error:  285.23217658608496 W\n",
      "Zero-shot RMSE:  264.83580159911634 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (8735, 7)\n",
      "Training Labels Shape: (8735,)\n",
      "Testing Features Shape: (2912, 7)\n",
      "Testing Labels Shape: (2912,)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m rf \u001b[38;5;241m=\u001b[39m RandomForestRegressor(n_estimators \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# Train the model on training data\u001b[39;00m\n\u001b[1;32m---> 55\u001b[0m \u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# Use the forest's predict method on the test data\u001b[39;00m\n\u001b[0;32m     58\u001b[0m predictions \u001b[38;5;241m=\u001b[39m rf\u001b[38;5;241m.\u001b[39mpredict(test_features)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:489\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    478\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    481\u001b[0m ]\n\u001b[0;32m    483\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    487\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 489\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    490\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    508\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    510\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\sklearn\\utils\\parallel.py:67\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     62\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     63\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     64\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     66\u001b[0m )\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\sklearn\\utils\\parallel.py:129\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:192\u001b[0m, in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m class_weight \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced_subsample\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    190\u001b[0m         curr_sample_weight \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m compute_sample_weight(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m\"\u001b[39m, y, indices\u001b[38;5;241m=\u001b[39mindices)\n\u001b[1;32m--> 192\u001b[0m     \u001b[43mtree\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    200\u001b[0m     tree\u001b[38;5;241m.\u001b[39m_fit(\n\u001b[0;32m    201\u001b[0m         X,\n\u001b[0;32m    202\u001b[0m         y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    205\u001b[0m         missing_values_in_feature_mask\u001b[38;5;241m=\u001b[39mmissing_values_in_feature_mask,\n\u001b[0;32m    206\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[0m, in \u001b[0;36mBaseDecisionTree._fit\u001b[1;34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    462\u001b[0m     builder \u001b[38;5;241m=\u001b[39m BestFirstTreeBuilder(\n\u001b[0;32m    463\u001b[0m         splitter,\n\u001b[0;32m    464\u001b[0m         min_samples_split,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_impurity_decrease,\n\u001b[0;32m    470\u001b[0m     )\n\u001b[1;32m--> 472\u001b[0m \u001b[43mbuilder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    475\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_classes_[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rmse_rf = pd.DataFrame(index=range(4), columns=(range(9)))\n",
    "metadata = pd.read_pickle(\"Data/Sites/metadata.pkl\")\n",
    "for site in range(9):\n",
    "    for model in range(4): #Only treat nwp vs reanalysis and physics vs non-physics\n",
    "        if model in [0,2]:\n",
    "            phys=False\n",
    "            phys_str = \"no_phys.pkl\"\n",
    "        else:\n",
    "            phys=True\n",
    "            phys_str = \"phys.pkl\"\n",
    "        if model in [0,1]:\n",
    "            dataset_name = \"nwp\"\n",
    "        else:\n",
    "            dataset_name=\"era5\"\n",
    "        source_data,_,eval_data = data_handeler(site, dataset_name, \"nwp\", \"nwp\", phys, HP_tuning=False)\n",
    "        eval_data = eval_data[24:31*24] #Only assess the first month\n",
    "        lat = metadata.loc[site, \"Latitude\"]\n",
    "        lon= metadata.loc[site, \"Longitude\"]\n",
    "        loc = location.Location(lat, lon,altitude=location.lookup_altitude(lat,lon))\n",
    "        source_times = source_data.index\n",
    "        eval_times = eval_data.index\n",
    "\n",
    "        sol_pos_source = loc.get_solarposition(source_times)\n",
    "        sol_pos_eval = loc.get_solarposition(eval_times)\n",
    "\n",
    "        zenith_filter_source = sol_pos_source[\"zenith\"] <= 85\n",
    "        zenith_filter_eval = sol_pos_eval[\"zenith\"] <= 85\n",
    "\n",
    "        source_data = source_data[zenith_filter_source]\n",
    "        eval_data = eval_data[zenith_filter_eval]\n",
    "        # Labels are the values we want to predict\n",
    "        labels = np.array(source_data['P'])\n",
    "        # Remove the labels from the source_data\n",
    "        # axis 1 refers to the columns\n",
    "        source_data= source_data.drop('P', axis = 1)\n",
    "        # Saving feature names for later use\n",
    "        ftr_file = \"features/ft_\" + phys_str\n",
    "        if os.path.isfile(ftr_file):\n",
    "            with open(ftr_file, 'rb') as f:\n",
    "                feature_list = pickle.load(f)\n",
    "        # Convert to numpy array\n",
    "        source_data = source_data[feature_list]\n",
    "        source_data = np.array(source_data)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(source_data, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "        print('Training Features Shape:', train_features.shape)\n",
    "        print('Training Labels Shape:', train_labels.shape)\n",
    "        print('Testing Features Shape:', test_features.shape)\n",
    "        print('Testing Labels Shape:', test_labels.shape)\n",
    "        #Instantiate model with 1000 decision trees\n",
    "        rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "        # Train the model on training data\n",
    "        rf.fit(train_features, train_labels)\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions = rf.predict(test_features)\n",
    "        # Calculate the absolute errors\n",
    "        errors = np.sqrt(np.mean(np.square(predictions - test_labels)))\n",
    "        # Print out rmse\n",
    "        print(\"Test Error: \", errors, 'W')\n",
    "\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        val_labels = eval_data['P']\n",
    "        val_features = eval_data[feature_list]\n",
    "        forecasts = rf.predict(val_features)\n",
    "        # Calculate the absolute errors\n",
    "        errors = np.sqrt(np.mean(np.square(forecasts - val_labels)))\n",
    "        # Print out rmse\n",
    "        print(\"Zero-shot RMSE: \", errors, 'W')\n",
    "        rmse_rf.loc[model, site] = errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>251.349834</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>235.579633</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0    1    2    3\n",
       "0  251.349834  NaN  NaN  NaN\n",
       "1  235.579633  NaN  NaN  NaN\n",
       "2         NaN  NaN  NaN  NaN\n",
       "3         NaN  NaN  NaN  NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_rf.to_pickle(\"sensitivity_analysis/rmse_rf.pkl\")\n",
    "rmse_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (8484, 7)\n",
      "Training Labels Shape: (8484,)\n",
      "Testing Features Shape: (2828, 7)\n",
      "Testing Labels Shape: (2828,)\n",
      "Test Error:  0.14456742780368748 W\n",
      "Zero-shot RMSE:  285.601167524665 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (8484, 9)\n",
      "Training Labels Shape: (8484,)\n",
      "Testing Features Shape: (2828, 9)\n",
      "Testing Labels Shape: (2828,)\n",
      "Test Error:  0.14682169421588478 W\n",
      "Zero-shot RMSE:  270.7186756033595 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (8735, 7)\n",
      "Training Labels Shape: (8735,)\n",
      "Testing Features Shape: (2912, 7)\n",
      "Testing Labels Shape: (2912,)\n",
      "Test Error:  0.13611591168220852 W\n",
      "Zero-shot RMSE:  339.4076463483586 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (8735, 9)\n",
      "Training Labels Shape: (8735,)\n",
      "Testing Features Shape: (2912, 9)\n",
      "Testing Labels Shape: (2912,)\n",
      "Test Error:  0.13949979053362335 W\n",
      "Zero-shot RMSE:  292.34205472961344 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (8526, 7)\n",
      "Training Labels Shape: (8526,)\n",
      "Testing Features Shape: (2842, 7)\n",
      "Testing Labels Shape: (2842,)\n",
      "Test Error:  0.14589072262345393 W\n",
      "Zero-shot RMSE:  318.6377431569623 W\n",
      "Not in Colab environment: Using .pkl files\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mera5\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 15\u001b[0m source_data,_,eval_data \u001b[38;5;241m=\u001b[39m \u001b[43mdata_handeler\u001b[49m\u001b[43m(\u001b[49m\u001b[43msite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnwp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnwp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mHP_tuning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m source_data,_,eval_data \u001b[38;5;241m=\u001b[39m data_handeler(site, dataset_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnwp\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnwp\u001b[39m\u001b[38;5;124m\"\u001b[39m, phys, HP_tuning\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m eval_data \u001b[38;5;241m=\u001b[39m eval_data[\u001b[38;5;241m24\u001b[39m:\u001b[38;5;241m31\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m24\u001b[39m] \u001b[38;5;66;03m#Only assess the first month\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Data\\Featurisation.py:407\u001b[0m, in \u001b[0;36mdata_handeler\u001b[1;34m(installation_int, source, target, eval, transform, month_source, HP_tuning, inv_limit, decomp, nb_source_years)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transform:\n\u001b[0;32m    406\u001b[0m     data\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mPoA(lat, lon, tilt, azimuth)\n\u001b[1;32m--> 407\u001b[0m     data\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclearsky_power\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeakPower\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtilt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mazimuth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m     \u001b[38;5;66;03m#data.data = data.deseasonalise(lat, lon)\u001b[39;00m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m source \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Data\\Featurisation.py:202\u001b[0m, in \u001b[0;36mFeaturisation.clearsky_power\u001b[1;34m(self, lat, lon, peakPower, tilt, azimuth)\u001b[0m\n\u001b[0;32m    199\u001b[0m poa \u001b[38;5;241m=\u001b[39m POA_irrad[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpoa_global\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    200\u001b[0m csi \u001b[38;5;241m=\u001b[39m irradiance\u001b[38;5;241m.\u001b[39mclearsky_index(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[i][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdownward_surface_SW_flux\u001b[39m\u001b[38;5;124m\"\u001b[39m], ghi)    \n\u001b[1;32m--> 202\u001b[0m temp_cell \u001b[38;5;241m=\u001b[39m \u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfuentes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwind_speed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m49\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwind_height\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwind_height\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43msurface_tilt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtilt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    205\u001b[0m inv_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdc0\u001b[39m\u001b[38;5;124m'\u001b[39m: peakPower, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124meta_inv_nom\u001b[39m\u001b[38;5;124m'\u001b[39m: loss_inv}\n\u001b[0;32m    206\u001b[0m module_params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdc0\u001b[39m\u001b[38;5;124m'\u001b[39m: peakPower, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgamma_pdc\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_coeff}\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pvlib\\temperature.py:801\u001b[0m, in \u001b[0;36mfuentes\u001b[1;34m(poa_global, temp_air, wind_speed, noct_installed, module_height, wind_height, emissivity, absorption, surface_tilt, module_width, module_length)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;66;03m# overall convective coefficient\u001b[39;00m\n\u001b[0;32m    800\u001b[0m     tave \u001b[38;5;241m=\u001b[39m (tmod \u001b[38;5;241m+\u001b[39m tamb) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m--> 801\u001b[0m     hconv \u001b[38;5;241m=\u001b[39m convrat \u001b[38;5;241m*\u001b[39m \u001b[43m_fuentes_hconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtave\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtinoct\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m                                     \u001b[49m\u001b[38;5;28;43mabs\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtmod\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mtamb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxlen\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43msurface_tilt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    804\u001b[0m     \u001b[38;5;66;03m# sky radiation coefficient (Equation 3)\u001b[39;00m\n\u001b[0;32m    805\u001b[0m     hsky \u001b[38;5;241m=\u001b[39m emiss \u001b[38;5;241m*\u001b[39m boltz \u001b[38;5;241m*\u001b[39m (tmod\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m+\u001b[39m tsky\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m*\u001b[39m (tmod \u001b[38;5;241m+\u001b[39m tsky)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pvlib\\temperature.py:636\u001b[0m, in \u001b[0;36m_fuentes_hconv\u001b[1;34m(tave, windmod, tinoct, temp_delta, xlen, tilt, check_reynold)\u001b[0m\n\u001b[0;32m    633\u001b[0m     hforce \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.8600\u001b[39m \u001b[38;5;241m/\u001b[39m reynold\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m densair \u001b[38;5;241m*\u001b[39m windmod \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1007\u001b[39m \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m0.71\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.67\u001b[39m\n\u001b[0;32m    634\u001b[0m \u001b[38;5;66;03m# free convection via Grashof number\u001b[39;00m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;66;03m# NB: Fuentes hardwires sind(tilt) as 0.5 for tilt=30\u001b[39;00m\n\u001b[1;32m--> 636\u001b[0m grashof \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m9.8\u001b[39m \u001b[38;5;241m/\u001b[39m tave \u001b[38;5;241m*\u001b[39m temp_delta \u001b[38;5;241m*\u001b[39m xlen\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m \u001b[38;5;241m/\u001b[39m visair\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43msind\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtilt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;66;03m# product of Nusselt number and (k/l)\u001b[39;00m\n\u001b[0;32m    638\u001b[0m hfree \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.21\u001b[39m \u001b[38;5;241m*\u001b[39m (grashof \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.71\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m0.32\u001b[39m \u001b[38;5;241m*\u001b[39m condair \u001b[38;5;241m/\u001b[39m xlen\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pvlib\\tools.py:44\u001b[0m, in \u001b[0;36msind\u001b[1;34m(angle)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msind\u001b[39m(angle):\n\u001b[0;32m     31\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124;03m    Trigonometric sine with angle input in degrees.\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m        Sin of the angle\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 44\u001b[0m     res \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msin(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mradians\u001b[49m\u001b[43m(\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rmse_svm = pd.DataFrame(index=range(4), columns=(range(9)))\n",
    "\n",
    "for site in range(9):\n",
    "    for model in range(4): #Only treat nwp vs reanalysis and physics vs non-physics\n",
    "        if model in [0,2]:\n",
    "            phys=False\n",
    "            phys_str = \"no_phys.pkl\"\n",
    "        else:\n",
    "            phys=True\n",
    "            phys_str = \"phys.pkl\"\n",
    "        if model in [0,1]:\n",
    "            dataset_name = \"nwp\"\n",
    "        else:\n",
    "            dataset_name=\"era5\"\n",
    "        source_data,_,eval_data = data_handeler(site, dataset_name, \"nwp\", \"nwp\", phys, HP_tuning=False)\n",
    "        source_data,_,eval_data = data_handeler(site, dataset_name, \"nwp\", \"nwp\", phys, HP_tuning=False)\n",
    "        eval_data = eval_data[24:31*24] #Only assess the first month\n",
    "        lat = metadata.loc[site, \"Latitude\"]\n",
    "        lon= metadata.loc[site, \"Longitude\"]\n",
    "        loc = location.Location(lat, lon,altitude=location.lookup_altitude(lat,lon))\n",
    "        source_times = source_data.index\n",
    "        eval_times = eval_data.index\n",
    "\n",
    "        sol_pos_source = loc.get_solarposition(source_times)\n",
    "        sol_pos_eval = loc.get_solarposition(eval_times)\n",
    "\n",
    "        zenith_filter_source = sol_pos_source[\"zenith\"] <= 85\n",
    "        zenith_filter_eval = sol_pos_eval[\"zenith\"] <= 85\n",
    "\n",
    "        source_data = source_data[zenith_filter_source]\n",
    "        eval_data = eval_data[zenith_filter_eval]\n",
    "        #Scale data (necessary for SVR)\n",
    "        scale = Scale()\n",
    "        scale.load(site, dataset_name, phys)\n",
    "        max = scale.max\n",
    "        min = scale.min\n",
    "        for covar in source_data.columns:\n",
    "            source_data[covar] = (source_data[covar]-min[covar])/(max[covar]-min[covar])\n",
    "            eval_data[covar] = (eval_data[covar]-min[covar])/(max[covar]-min[covar])\n",
    "\n",
    "        # Labels are the values we want to predict\n",
    "        labels = np.array(source_data['P'])\n",
    "        # Remove the labels from the source_data\n",
    "        # axis 1 refers to the columns\n",
    "        source_data= source_data.drop('P', axis = 1)\n",
    "        # Saving feature names for later use\n",
    "        ftr_file = \"features/ft_\" + phys_str\n",
    "        if os.path.isfile(ftr_file):\n",
    "            with open(ftr_file, 'rb') as f:\n",
    "                feature_list = pickle.load(f)\n",
    "        # Convert to numpy array\n",
    "        source_data = source_data[feature_list]\n",
    "        source_data = np.array(source_data)\n",
    "\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(source_data, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "        print('Training Features Shape:', train_features.shape)\n",
    "        print('Training Labels Shape:', train_labels.shape)\n",
    "        print('Testing Features Shape:', test_features.shape)\n",
    "        print('Testing Labels Shape:', test_labels.shape)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        #Instantiate model SVR\n",
    "        rf = SVR(kernel='linear')\n",
    "        # Train the model on training data\n",
    "        rf.fit(train_features, train_labels)\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions = rf.predict(test_features)\n",
    "        # Calculate the absolute errors\n",
    "        errors = np.sqrt(np.mean(np.square(predictions - test_labels)))\n",
    "        # Print out rmse\n",
    "        print(\"Test Error: \", errors, 'W')\n",
    "\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        val_labels = eval_data['P']\n",
    "        val_features = eval_data[feature_list]\n",
    "        forecasts = rf.predict(val_features)\n",
    "        # Calculate the absolute errors\n",
    "        errors = np.sqrt(np.mean(np.square(forecasts - val_labels)))\n",
    "        # Print out rmse\n",
    "        print(\"Zero-shot RMSE: \", errors*(max['P']-min['P']), 'W')\n",
    "        rmse_svm.loc[model, site] = errors*(max['P']-min['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>255.686906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>220.102551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>219.443421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>268.976432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0           1    2           3\n",
       "0  NaN  255.686906  NaN  220.102551\n",
       "1  NaN  219.443421  NaN  268.976432\n",
       "2  NaN         NaN  NaN         NaN\n",
       "3  NaN         NaN  NaN         NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_svm.to_pickle(\"sensitivity_analysis/rmse_svm.pkl\")\n",
    "rmse_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_rf = pd.read_pickle(\"sensitivity_analysis/rmse_rf.pkl\")\n",
    "rmse_svm = pd.read_pickle(\"sensitivity_analysis/rmse_svm.pkl\")\n",
    "rmse_lstm = pd.read_pickle(\"evaluation/Target/rmse.pkl\")\n",
    "rmse_lstm_zs = rmse_lstm.loc[(slice(None), 0),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>235.209457</td>\n",
       "      <td>233.59169</td>\n",
       "      <td>331.838501</td>\n",
       "      <td>1064.397461</td>\n",
       "      <td>1051.19397</td>\n",
       "      <td>282.325348</td>\n",
       "      <td>277.500732</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>313.578351</td>\n",
       "      <td>347.224248</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>191.591125</td>\n",
       "      <td>223.27803</td>\n",
       "      <td>267.039154</td>\n",
       "      <td>924.650696</td>\n",
       "      <td>894.702332</td>\n",
       "      <td>261.253693</td>\n",
       "      <td>255.061783</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>251.486302</td>\n",
       "      <td>317.334218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>547.384949</td>\n",
       "      <td>555.264404</td>\n",
       "      <td>557.759827</td>\n",
       "      <td>1247.877808</td>\n",
       "      <td>1256.600464</td>\n",
       "      <td>558.055664</td>\n",
       "      <td>573.495178</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>963.077546</td>\n",
       "      <td>672.385668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>255.310547</td>\n",
       "      <td>228.768814</td>\n",
       "      <td>264.637787</td>\n",
       "      <td>576.130493</td>\n",
       "      <td>573.194092</td>\n",
       "      <td>268.332703</td>\n",
       "      <td>284.364807</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>308.557303</td>\n",
       "      <td>257.454148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>205.653976</td>\n",
       "      <td>210.734863</td>\n",
       "      <td>295.440643</td>\n",
       "      <td>984.862061</td>\n",
       "      <td>959.78064</td>\n",
       "      <td>241.906921</td>\n",
       "      <td>237.70575</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>284.463765</td>\n",
       "      <td>330.797311</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <td>204.241302</td>\n",
       "      <td>177.273575</td>\n",
       "      <td>264.602295</td>\n",
       "      <td>868.627747</td>\n",
       "      <td>849.973511</td>\n",
       "      <td>220.390976</td>\n",
       "      <td>221.730301</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>236.122276</td>\n",
       "      <td>281.954528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <td>189.7565</td>\n",
       "      <td>191.514999</td>\n",
       "      <td>276.702942</td>\n",
       "      <td>799.301147</td>\n",
       "      <td>792.011353</td>\n",
       "      <td>221.079254</td>\n",
       "      <td>221.37085</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>272.390569</td>\n",
       "      <td>304.416339</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>0</th>\n",
       "      <td>201.274048</td>\n",
       "      <td>199.913315</td>\n",
       "      <td>297.429504</td>\n",
       "      <td>829.863037</td>\n",
       "      <td>794.045654</td>\n",
       "      <td>185.693283</td>\n",
       "      <td>193.641449</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>220.060379</td>\n",
       "      <td>328.520307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>0</th>\n",
       "      <td>216.303635</td>\n",
       "      <td>220.95192</td>\n",
       "      <td>266.852264</td>\n",
       "      <td>773.802612</td>\n",
       "      <td>765.125549</td>\n",
       "      <td>230.501404</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>229.066025</td>\n",
       "      <td>327.687825</td>\n",
       "      <td>293.181314</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           1           2            3            4   \\\n",
       "one two                                                                 \n",
       "0   0    235.209457   233.59169  331.838501  1064.397461   1051.19397   \n",
       "1   0    191.591125   223.27803  267.039154   924.650696   894.702332   \n",
       "2   0    547.384949  555.264404  557.759827  1247.877808  1256.600464   \n",
       "3   0    255.310547  228.768814  264.637787   576.130493   573.194092   \n",
       "4   0    205.653976  210.734863  295.440643   984.862061    959.78064   \n",
       "5   0    204.241302  177.273575  264.602295   868.627747   849.973511   \n",
       "6   0      189.7565  191.514999  276.702942   799.301147   792.011353   \n",
       "7   0    201.274048  199.913315  297.429504   829.863037   794.045654   \n",
       "8   0    216.303635   220.95192  266.852264   773.802612   765.125549   \n",
       "\n",
       "                 5           6           7           8           9    10   11  \n",
       "one two                                                                        \n",
       "0   0    282.325348  277.500732  229.066025  313.578351  347.224248  NaN  NaN  \n",
       "1   0    261.253693  255.061783  229.066025  251.486302  317.334218  NaN  NaN  \n",
       "2   0    558.055664  573.495178  229.066025  963.077546  672.385668  NaN  NaN  \n",
       "3   0    268.332703  284.364807  229.066025  308.557303  257.454148  NaN  NaN  \n",
       "4   0    241.906921   237.70575  229.066025  284.463765  330.797311  NaN  NaN  \n",
       "5   0    220.390976  221.730301  229.066025  236.122276  281.954528  NaN  NaN  \n",
       "6   0    221.079254   221.37085  229.066025  272.390569  304.416339  NaN  NaN  \n",
       "7   0    185.693283  193.641449  229.066025  220.060379  328.520307  NaN  NaN  \n",
       "8   0    230.501404  229.066025  229.066025  327.687825  293.181314  NaN  NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_lstm_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243.79</td>\n",
       "      <td>231.32</td>\n",
       "      <td>571.00</td>\n",
       "      <td>232.94</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>232.61</td>\n",
       "      <td>204.36</td>\n",
       "      <td>573.52</td>\n",
       "      <td>236.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>313.09</td>\n",
       "      <td>273.05</td>\n",
       "      <td>636.71</td>\n",
       "      <td>276.68</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>278.79</td>\n",
       "      <td>227.34</td>\n",
       "      <td>627.37</td>\n",
       "      <td>271.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3   4   5   6   7   8   9\n",
       "0  243.79  231.32  571.00  232.94 NaN NaN NaN NaN NaN NaN\n",
       "1  232.61  204.36  573.52  236.37 NaN NaN NaN NaN NaN NaN\n",
       "2  313.09  273.05  636.71  276.68 NaN NaN NaN NaN NaN NaN\n",
       "3  278.79  227.34  627.37  271.50 NaN NaN NaN NaN NaN NaN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_rf.astype(float).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>283.58</td>\n",
       "      <td>255.74</td>\n",
       "      <td>573.06</td>\n",
       "      <td>224.59</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262.97</td>\n",
       "      <td>201.99</td>\n",
       "      <td>587.90</td>\n",
       "      <td>251.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>322.25</td>\n",
       "      <td>271.35</td>\n",
       "      <td>651.42</td>\n",
       "      <td>264.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>298.25</td>\n",
       "      <td>242.52</td>\n",
       "      <td>636.26</td>\n",
       "      <td>287.15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3   4   5   6   7   8   9\n",
       "0  283.58  255.74  573.06  224.59 NaN NaN NaN NaN NaN NaN\n",
       "1  262.97  201.99  587.90  251.16 NaN NaN NaN NaN NaN NaN\n",
       "2  322.25  271.35  651.42  264.34 NaN NaN NaN NaN NaN NaN\n",
       "3  298.25  242.52  636.26  287.15 NaN NaN NaN NaN NaN NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_svm.astype(float).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2979</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>0.1508</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.1470</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0983</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>-0.0747</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1971</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>-0.0546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3   4   5   6   7   8   9\n",
       "0  0.2979  0.2711  0.1508  0.0952 NaN NaN NaN NaN NaN NaN\n",
       "1  0.3301  0.3560  0.1470  0.0819 NaN NaN NaN NaN NaN NaN\n",
       "2  0.0983  0.1395  0.0531 -0.0747 NaN NaN NaN NaN NaN NaN\n",
       "3  0.1971  0.2836  0.0669 -0.0546 NaN NaN NaN NaN NaN NaN"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "persist = rmse_lstm_zs.loc[:,9]\n",
    "persist = persist.droplevel(1)\n",
    "(1-rmse_rf/persist).astype(float).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.1941</td>\n",
       "      <td>0.1477</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2426</td>\n",
       "      <td>0.3635</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0719</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>-0.0268</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.2358</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>-0.1154</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3   4   5   6   7   8   9\n",
       "0  0.1833  0.1941  0.1477  0.1276 NaN NaN NaN NaN NaN NaN\n",
       "1  0.2426  0.3635  0.1257  0.0245 NaN NaN NaN NaN NaN NaN\n",
       "2  0.0719  0.1449  0.0312 -0.0268 NaN NaN NaN NaN NaN NaN\n",
       "3  0.1410  0.2358  0.0537 -0.1154 NaN NaN NaN NaN NaN NaN"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-rmse_svm/persist).astype(float).round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>239.671646</td>\n",
       "      <td>232.886826</td>\n",
       "      <td>323.994781</td>\n",
       "      <td>1065.834473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>192.388275</td>\n",
       "      <td>192.53064</td>\n",
       "      <td>270.19101</td>\n",
       "      <td>902.788391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>543.174377</td>\n",
       "      <td>552.783203</td>\n",
       "      <td>550.550476</td>\n",
       "      <td>1244.890869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>263.73407</td>\n",
       "      <td>253.86377</td>\n",
       "      <td>265.216675</td>\n",
       "      <td>582.92334</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0           1           2            3\n",
       "one two                                                 \n",
       "0   0    239.671646  232.886826  323.994781  1065.834473\n",
       "1   0    192.388275   192.53064   270.19101   902.788391\n",
       "2   0    543.174377  552.783203  550.550476  1244.890869\n",
       "3   0     263.73407   253.86377  265.216675    582.92334"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_lstm_zs.loc[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(2,2, layout=\"constrained\")\n",
    "width=0.25\n",
    "y_limits = [350,300,700,350]\n",
    "float_nb = 0\n",
    "label_pos = np.arange(4)\n",
    "site_list = [r\"$\\text{NL}_1$\", r\"$\\text{NL}_2$\", \"CR\", \"UK\"]\n",
    "for site in range(4):\n",
    "    x = site // 2\n",
    "    y = site % 2\n",
    "    lstm = rmse_lstm_zs.loc[site,[0,1,5,6]].values.flatten()\n",
    "    rmse_list = [lstm.astype(float).round(float_nb), rmse_rf.loc[:,site].astype(float).round(float_nb), \n",
    "                 rmse_svm.loc[:,site].astype(float).round(float_nb)]\n",
    "    label_list = [\"LSTM\", \"RF\", \"SVM\"]\n",
    "    multipl = 0\n",
    "    for i in range(3):\n",
    "        rects = axs[x,y].bar(label_pos+multipl*width, rmse_list[i], width, label = label_list[i])\n",
    "        axs[x,y].bar_label(rects, padding=3, fontsize=8)\n",
    "        multipl += 1\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    axs[x,y].set_ylabel('RMSE [W]')\n",
    "    axs[x,y].set_ylim([0,y_limits[site]])\n",
    "    axs[x,y].set_title(f'RMSE for {site_list[site]}')\n",
    "    axs[x,y].set_xticks(label_pos + width, rotation=20,\n",
    "                        labels=[r\"$\\text{Transf}_{np}$\", r\"$\\text{Transf}_{p}$\", r\"$\\text{Transf}_{ra,np}$\", r\"$\\text{Transf}_{ra,p}$\"])\n",
    "handles, labels = plt.gca().get_legend_handles_labels()\n",
    "fig.legend(handles, labels,bbox_to_anchor=(1.15, 0.5), loc = \"center right\", fontsize=13)\n",
    "\n",
    "plt.savefig(\"Figures/sensitivity_analysis/ML_models\", dpi=200)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nb of source years open-meteo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics-informed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <th>two</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>310.931427</td>\n",
       "      <td>284.975403</td>\n",
       "      <td>516.950256</td>\n",
       "      <td>250.525452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>272.287598</td>\n",
       "      <td>229.795242</td>\n",
       "      <td>519.250427</td>\n",
       "      <td>266.496521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>281.19809</td>\n",
       "      <td>244.821686</td>\n",
       "      <td>546.789978</td>\n",
       "      <td>270.432007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>260.075043</td>\n",
       "      <td>224.122177</td>\n",
       "      <td>536.293701</td>\n",
       "      <td>247.499207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>0</th>\n",
       "      <td>267.779297</td>\n",
       "      <td>245.841812</td>\n",
       "      <td>522.484985</td>\n",
       "      <td>222.195511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>0</th>\n",
       "      <td>279.166901</td>\n",
       "      <td>277.62027</td>\n",
       "      <td>514.166748</td>\n",
       "      <td>191.881592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>0</th>\n",
       "      <td>280.087067</td>\n",
       "      <td>249.35788</td>\n",
       "      <td>518.072632</td>\n",
       "      <td>256.02832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>0</th>\n",
       "      <td>294.162292</td>\n",
       "      <td>233.777817</td>\n",
       "      <td>534.046265</td>\n",
       "      <td>218.123077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>0</th>\n",
       "      <td>263.48584</td>\n",
       "      <td>233.580063</td>\n",
       "      <td>544.049866</td>\n",
       "      <td>222.231064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0           1           2           3\n",
       "one two                                                \n",
       "0   0    310.931427  284.975403  516.950256  250.525452\n",
       "1   0    272.287598  229.795242  519.250427  266.496521\n",
       "2   0     281.19809  244.821686  546.789978  270.432007\n",
       "3   0    260.075043  224.122177  536.293701  247.499207\n",
       "4   0    267.779297  245.841812  522.484985  222.195511\n",
       "5   0    279.166901   277.62027  514.166748  191.881592\n",
       "6   0    280.087067   249.35788  518.072632   256.02832\n",
       "7   0    294.162292  233.777817  534.046265  218.123077\n",
       "8   0     263.48584  233.580063  544.049866  222.231064\n",
       "9   0           NaN         NaN         NaN         NaN"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_years_p = pd.read_pickle(\"sensitivity_analysis/nb_years/rmse_physics.pkl\")\n",
    "rmse_years_p.loc[(slice(None),0),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Physics-informed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAADpCAYAAACnSLudAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAnzUlEQVR4nO3deXwTdfoH8E/SgxYKnYZSKOWcAqWckiaiyCVNQRCqrilrFbxpvfDn2Szsuoiri424u4qobVdXdLULicdWC2iDgCKCIcMlNxkEWs6SDmcLlM7vj5Js0yZt0ySdpH3erxevVzrzzeQZpnk6853n+x2ZKIoiCCEkiMmlDoAQQrxFiYwQEvQokRFCgh4lMkJI0At1t4LjOJhMJgCA2WxGQUEBGIZxWj9nzhxYLBan9/E8D6PRCJZlwfM8srKynN5HCCG+5jaRmUwm5OTkAAD0ej1SU1MdScueqDiOa/C+jIwMRzue5zFnzhwYDAZ/xE4IIQAAmavyC47jkJqaioqKCgC1CSkxMRFWqxUsy/7vzTIZ6r6d53mnRAYAMTExju0QQog/uOwjUyqVKCgocPwsCAIAQKFQNLoxk8nUoI1CoXB55kYIIb7i9tJSq9U6Xi9fvhwajabJvi57wqvPZrO5XN6rVy9cuHABERERAICEhAQkJCS43X5ZWVmj61ujbaDEQfvXsraBEgftn2fty8rKUFZWBgCoqqpCVFQUSktL/9dAbEJFRYXIsqxYUVHRYF39t+fm5ooajcZpGcuyosFgcLntGTNmiDNmzGgqBKf2UrcNlDho/1rWNlDioP3zbtv12zdZfqHT6VBSUtKsO48MwzQ4+7LZbI2+NzMzs8nttoQn2/U0Bn9uOxBioP1r+bYDIYZg2z9P27ts21jmy83NFa1WqyiKtWdm9c/K6r/darWKSqXSaRnDMC7P5uyZ1ROetg82tH/Bjfav9TT7jMxoNEKpVIJlWQiCgBUrVrg8s6rbL1b3jiZQexdTpVL5rI7MX389AgXtX3Cj/ZOOy/ILe7lFXQzDOMooTCYTSkpKoNfrkZOTA7Va7bg5wPM88vLyoFarYTabMW/ePLeJLD09HUVFRT7eJUJIW1c/d7hMZFIFQwghzVE/d9BYS0JI0JM0kZWVlSE9PR2FhYVShuE3z39sxquf74Bw8YrUoRDSJhQWFiI9Pd1RU2ZHl5Z+wp88j5Evfg2ZDIiODMPT05LxWFoSOkeGSR0aIUGPLi1bSTFXig5hcmzVz0Dm2P54/atfMfyFIry9ag8qr1RLHR4hbQolMj8p5sowcUgPJHbvDP0sFba/MQPpqt5YsGIbRrzwNfJN+3H56jWpwySkTaBE5gfl56vw8/7TuF3Zy7GsV9dOePuhG2F5fTpuHdoDL35iwaicr7FsvRVXq2skjJaQ4EeJzA++3XYMIkRMG9VwECzbvTPys2/G5r9OgzoxFk99sBnqed9g+cZDuFZDCY2QlqBE5gfFXClUbFd0ZyLdthmcEI1lT43FxlenIqlnNB59/2fc9MdV+K/5CGpq6Al9hHiCEpmPVV6pxpqdx50uKxszvE8Mlj87AWsXTEZCTCRmLdmAcX9ejVVbyyDhDWVCggrVkfnYul0ncenKtWYnMjtVYiy+ypmEVfM1iIoMxcy/r8ekV77D2l9PUEIj5DqqI2slT32wGRv2nsJW/XTIZLIWbUMURazddQJ/Me7AFv4Mxg6Ow0t3j8CYpDgfR0tIcKI6Mj+qqRGxalsZblf2anESA2qfhTBpWDy+XzAZK56dgLOXrmDKaybc9cZaWPgzPoyYkLaBEpkPma3lOHW2Crcrmz/Fb2NkMhmmjkrAhlem4pOnxuLomYuY+PK3uOcfP2BPqeCTzyCkLaBE5kPFXBliO3fA6IGxPt2uXC7DnTf2wea/TkNB9s3YUypA85cSnBQqffo5hAQrSmQ+VMyV4rYbEhAi989/a4hcjntu6Y+1L09BaIgcf16xzS+fQ0iwoUTmIweOn8P+4+c8vlvZEoqoDliQMRKfbTiETQdO+/3zCAl0lMh8pJgrRWR4CCYN69Eqn/fABBaj+inwwsdbaEQAafeojsxHirky3Dq0Bzp2cPuoUJ8Kkcux+H4Vth+uwLJ11lb5TEKk5q6OTNJElpCQgKKiooB+qEFznD5Xhc0HT7fKZWVdNw6IxaxxLF42bMeZ85db9bMJkUJmZiaKiooaPMyXLi19YNXW2r8OU10MEve3hTNHokYU8ZfPt7f6ZxMSKCiR+UAxV4rRA7qhW5eIVv/suOhIzL9rOD5cexDbfrM1/QZC2iBKZF66dLkaa3ed8FkRbEtkaQYhOSEaz3+8hWbOIO0SJTIvrfn1OCpbMEjcl0JD5Fg8W4VfDpaj8KdDksVBiFQokXmpmCvDoPguGBjfRdI4xiV3h/amvnhp+TacvURPbSLtCyUyL1yrqcHq64PEA8Gr94zCpcvVWPTlTqlDIaRVUR2ZFzYdKMeZ85cxPSUwElmCoiNy7hiG90v206By0iZRHZkfFHOl6B4dARXbVepQHJ6ckoT+cVF44RMLTchI2hyqI/MxURSxkivF1FEJkMtbPveYr3UIC4F+Vgp+2HMSX/5yROpwCGkVbsfTcBwHk8kEADCbzSgoKADDMAAAnudhNBrBsix4nkdWVpZjHcdxAAClUgme5yEIApRKpX/3QgL7jp2D9eQFvH5fitShNJA2oiduV/bC/MKtmDyyJ6Ii6OnmpG1ze0ZmMpmQk5ODnJwcqNVqpKamOtZlZGQgJycHWq0WWq0Wc+bMcazLy8tDSkoKZDIZsrOzwbKsf/dAIt9wpejUIRQTh7TOIHFPvX6fEuXnq7D4611Sh0KI37lMZBzHYdGiRY6ftVotOI4Dz/Pged6pLcuyjjM3AEhJSUFFRQUqKipQUlLiOFNra4q5UqQOj0dEeIjUobjUr1sUnrt9CN5euRcHT5yTOhxC/MplIlMqlSgoKHD8LAgCAEChUMBkMkGhUDi1VygUjktKAGAYps0mMAA4IVRii/WMpNX8zfHs9CHoGRMJ3b+p45+0bW77yLRareP18uXLodFowDCMI6nVZ7PVjvMTBAFGoxFAbd9aY5eX9vILu8zMzKC4g7lyaxlC5DJMGRnYiSwyPBSL7lPi3rd+xKptZZg2KjDKRAjxVGFhoVOZVv3yiyYnz7InJovF0mQ7AE4d/yzLIi0tDVar6/my7OUXwaaYK8XNg7qha+cOUofSpOnKXtAMj4fu3xZMGhq4l8KENKb+SU7dEyCgGeUXOp3Oqa+LYRjH2ZedzWZzuqNpZ7+rWb9fLZhdqLqK9btPBEw1f1NkMhlyZ6WgzFaJt1buljocQvyi0USm1+uh0+nAsiwEQYAgCNBoNC7bqlQqcBzndHfTrn6fWjBbs/M4Ll+tCZpEBgCD4rvgyduSsPjr3Th8+oLU4RDic24TmdFohFKpdCSxFStWgGGYBv1dPM9DpVI51uXm5jrWmUwmaLXaNtXxX8yVYkivaPSPi5I6FI/kpA9DTFQ45hdulToUQnzOZR8Zz/PIyMhwWsYwDLKysgAABoMBOp0OarUaZrMZBoPB0UalUkGv14NhGFitVse6tqD6Wg1WbzuGR1MHSh2KxzpHhuG1e0bh4fc24vtfj2PSsHipQyLEZ2SihPfl09PTg6qz/8c9JzFt0Rqse3kKUgJofGVziaKIqX9dg9PnqvDza1MRHkod/yQ41c8dNNbSA8VcKeJjIjGqX3D2+clkMiyenQLryfN477v9UodDiM/QND7NJIoiirlSTAuwQeKeGtYnBlmagXj9q504XnFJ6nAI8QhN4+Ol3aVn8dvpi0F1t9Kd+XeNQERYCF5avk3qUAjxCE3j46VvLEfROSIU45O7Sx2K15hO4Vg48wYs3/gbNuw9JXU4hHiNElkzFXNl0IzoiQ5hbaODfNY4Fiq2K178ZAuqr9VIHQ4hXqFE1gxltkvY+pst4AeJe0Iul2Hx/SrsKhXw4dqDUodDiFcokTXDSq4UIXIZJgf4IHFPpbBd8cCERPzFuB2nz1VJHQ4hLUaJrBmKuVKMHRyHmE7hUoficwsyRkImk2GhYbvUoRDSYpTImnD20hX8sOdUm7hb6Ups5wi8dPcIfPyDFVus5VKHQ0iLUB1ZE0w7juPqteAaJO6phycNwLDeDF74ZAtqamgCRhK4qI6shYq5UozoE4M+sZ2kDsVvQuRyLJ6tgoW34ZMf286US6TtoTqyFrhaXYPvdhxrU3cr3RmTFId7xvTDghXbYLtwWepwCPEIJbJGbNh7CmcvXW3Tl5V1/eWeUaipETFryY+4fPWa1OEQ0myUyBpRzJWid9eOGNE3RupQWkUPJhL/eWY8fjlYjqy8n6m/jAQNSmRu/G+QeC/IZME7SNxTY5Li8MFjt+BL8xHML+SafgMhAYASmRs7Dleg1Hap3VxW1nWHujcWz1Zh6bf7sGTVHqnDIaRJTT5Fqb0q5koR3TEMYwfHSR2KJLI0g3Cs4hLmF25FfEwktDf1kzokQtyiOjI3irkyTB7RE2Gh7fekdYF2JDJv6Y+svE1Yv/uE1OEQQnVknjhSfhE7jlS0y8vKumQyGZY+Mhrjk+Nw71s/YueRCqlDauB85VV89csRujHRTlAdmQdWcqUIC5EjbWRPqUORXFioHJ/MHQe2exR+t3gdjpRflDokB+vJ85j0yneY/c4G/GfjIanDIRKiROZCMVeK8clx6BIZJnUoAaFzZBiMz01ERJgcv1u8NiAKZk07jmHigtW4Wl2Dcclx+OsXO3Glmmrf2itKZPUIF69gw762O0i8pbozkfjihVtRfv4yfv/3H1B5pVqSOERRxFsr9+DuN9dDPSAW616egr/dr8bRM5fwL5pXrd2iRFbPd9uPofqaiGmUyBoYGN8FhucmYPthGx55byOu1bTuzLKVV6rx6Psb8af/bMX/TUuG4bkJYDqFY3BCNO65pR/0Rbtw8bI0CZZIixJZPcVcKUb1UyBB0VHqUAKSOjEWy54ci2KuDC9+YkFrPRb1aPlFTH61BF9bSvGvJ8bgld/fgBD5/3595981HBUXruDdb/e1SjwksFAiq+Py1WvtZpC4N6aOSsBbD6lRsOYA3vxmt98/76d9pzB+wWqcOX8ZJX9Kc1nT1rdbFB5NHYC3Vu4OiD480rqojqyOH/acxIWqauofa4YHJw7A/LuGY6FhOz7109Q/oijin2sOYPrrazA4IRrrF96GkY08HPnF9GGovibi78X+T65EGu7qyCSt7LfXkQWKYq4UfWM7YWhvRupQgsIf7hyGMtslPPXhZsRFRyBthO/KVa5UX8PzH2/BR+usyNYMwqJ7lU0WJ3frEoEnpyTh7VV78cTkJMTHUPdAW5OZmYnMzEykp6c7LadLy+tqakSs3FqG25Xta5C4N2QyGf7xoBqa4fGYvWQDth6y+WS7J4VKTFu0Bp9tOISlj4zG4vtVzR5h8fS0ZESGhyD3v7/6JBYSHNyekXEcB5PJBAAwm80oKCgAwzAAAJ7nYTQawbIseJ5HVlZWs9YFsq2/2XC8opIuKz0UGiLHR0+OxfTX1+DuN9dhzZ8no39cVIu3Z+HP4N63fkCNCKycl4rRA7t59P7ojuF4bvoQLDRux9ypyUjs3rnFsZAgIrqRm5vr9FqpVDp+rvvaarWKWq22WevqmzFjhtt1rW2hYZvY+zGDeLX6mtShBKVTZyvFkS8UiSNfKBJPna1s0TY+/dEqdn24UJz48mrxmO1ii2O5dPmqOPDpL8SHlm5o8TZIYKufO1yer3Mch0WLFjl+1mq14DgOPM+D5507dlmWdZy5NbbOWyeFSr9WbhdzpZgysidCQ+hquyW6dYnAly/eivNVVzHzb+s9queqvlaDP3xqQXb+JmTc1A+r5mm86t+KDA/FH+4cDsOmwwE5PpT4nstvrVKpREFBgeNnQRAAAAqFAiaTCQqF850jhULhuBR1t85bD7+3Ed3nrMCN84rx4NINeKPoV3xjKcWhUxe8HjB86NQF7C49S5eVXuofF4XPn5+IvcfO4oF3NqD6WtMFs2fOX8Zdb6zF+yX78casFLz76GhEhId4HcvscSwSu0fR8zrbCbd9ZFqt1vF6+fLl0Gg0YBjGkdTqs9lsja7z1sKZI7H9cAV2HRWwu/Qsvv91LyouXgEAdOoQiuSEaCT3isbQXgyG9GIwpFc04qIjmtVxX8yVokOYHKnD472Os727oZ8C/547Dtq/rcMzH5mx5OEb3R6DXUcF3POP9ThXWY2inEkYP6S7z+IIC5XjT3ePwEPvbsTP+0/j5kGe9bWR4NJk+YUgCDAajbBYLE2283SdvY7Mzn5r1RVVYixUibGOn0VRxAmhsjaxlZ3FrqMCfj0iwPDzYVRdf3BG184dMOR6ckvuxWBor2gk92IaDAYv5koxYUgPdKZB4j6ROjweSx8Zjez8TegZE4n5vxvRoM1/zUeQnb8JbPcofPOHVPTt1vIbBO787sa++Ps3e7BgxTZ8+0cN3Y0OYoWFhU71ph7Xkel0OpSUlDjuPDIM0+AMy2azgWGYRte54k0dmUwmQ3xMR8THdISmTv3StZoaHDp1AbuOnsWeMgG7jgr4/tcTyDcdQM314TR9YjshOSEaQ3szGNCjMzbuO42/P6huURzEtXvHsjheUYmXDdsRH9MRD906AEBtmctrX+yAvmgX7h7dB0sfvQmdOvinnFEul+HPGSOgfXM9vttxDFNG0oiNYFX/JKd+HVmjv0F6vR46nQ4syzrOqjQaDfLy8hq0ValUYFnW7brWEiKXY0CPLhjQowvuUPd2LK+6cg37j5/DrlIBu0sF7D4qYMXG31Bqu4SwEDmmjaJfcl97bvoQHKu4hGc+MqMHE4lbBsfh0fc3YvW2MrycMRLPTR/i97OkySN6YkxSNyw0bEfa8J6Qy+msrC1ym8iMRiOUSqUjia1YscJlTRjP81CpVI4zMnfrpBYRHoIRfWMaPNpNuHgFF6quogcTKVFkbZdMJoN+VgpOCFV4YOkG9IzpiPLzVTA8N6HVzo5kMhlezrgBk18twRe/HKZnD7RRLhMZz/PIyMhwWsYwDLKysgAABoMBOp0OarUaZrMZBoPB0a6xdYGI6RQOplO41GG0WSFyOf752M24+811OHW2CmsXTMHA+C6tGsPNg7physieePXzHbhD1addP4ehrZKJYivNw+JCenp6QI21JP5jL5GR6tJu55EKjPnTKrz10I14+Hp/HQle9XMH/WkirUIul0naPzW8TwwybuqL17/aKdnstsR/aBof0m788e4ROH2uCnkl+6UOhbSQu2l86NKStCvPfPQLvth8BDvfTEd0R+obDVZ0aUnaNd0dw1B19RreXrlH6lCID1EiI+1KfExHZKcNwtJv9+HU2UqpwyE+QomMtDvP3j4EoSEyvFG0S+pQiI9QIiPtjiKqA/5vWjI++P4gDp++IHU4xAcokZF26fHJSYiJCsdfv9wpdSjEByiRkXYpKiIMOelD8Z+ffsPesrNSh0O8RHVkpN166NYB6N21I14x0uSLwcJdHZmkicw+jY+7OcgI8afw0BDM/91wfG0phdlaLnU4pBkyMzNRVFSEhATnSQfo0pK0a78f0w/JCdE0JXaQo0RG2rUQuRwvaUdg/e6TWPvrCanDIS1EiYy0e9OVvaBK7IqFxm2QcMQe8QIlMtLuyWQyLMy4ARbehqItpVKHQ1qAEhkhAMYP6Y5Jw3rgFeP2Zj3GjgQWSmSEXLdAOxL7j59D4U+HpA6FeIjqyAi5Tsl2xR3q3lj05U5cvuq/p9qTlqM6MkKa4aW7R6DMVokPvj8gdSjEBaojI6QZknpG475x/fFG0S6cr7wqdTikmSiREVLPvDuH41zlVSz9dq/UoZBmokRGSD29YzthTupAvL1yD8rPV0kdDmkGSmSEuPD8jKEQAUx//Xt8+P0BnKPLzIBGiYwQF7p1icDnz09E764d8eyyLRg49ws8XrAJmw+cpur/AOTySeOEEGBMUhzGJMWhzHYJn/7IY9l6K/79I4/khGg8MCER99zSH107d5A6TAKJHweXkpKChIQEZGZmUgkGCXg1NSLW7jqBj9YdRDFXBpkMSFf1xoMTEzFucHdJH0AMANXXanDwxHkMjO+MEHnbvNgqLCxEYWEhysrKYLFYHMvpuZaEtMDpc1X4bMMhLFtvxYHj58DGRWH2hETMGseiBxPZKjGcOX8ZZms5fjlYjs0HymHhz+Di5Wo8ljYIb8xWtUoMUqmfO+jSkpAW6NYlAv83LRlPTx2MjftPY9m6g8j96le8+vkOTB2VgAcmJCJtRLzPzoxqakTsO3YWmw5cT1wHy3Hg+DkAQFx0BEYPiMUf7hyGs5euYvHXu6AZEY8pIxOa2Grb4TaRcRyHOXPmOJ2+AQDP88jLy0NiYiKsVivmzZsHhmEc7wEApVIJnuchCAKUSqX/oidEYjKZDLckxeGWpDjoZ13Bip9/w0frDiLjb+uRoOiI2eNZzB6fiD6xnTza7rnKq9hS52zLbC3H2UtXIZfJMLwPg4lDukN3x1CMHtgNfWM7QSarvawVRRE7j1Tg8YLN2PTaVMRFt87ZodRcXloajUawLIuUlJQGd2gSExNhsVjAMAw4jkNeXh7y8vIAANnZ2cjPzwcAaDQaGAwGR5JzhS4tSVskiiK2HrLho/VWGH7+DRcvVyN1WDwenJiIqaMSEB4a0qC99eR5bK5ztrW7VIAoAjGdwqEeEIubBsZi9IBuULIKREWENfr5p89V4aY/rsTIvjEwPjdR8r47f6ifOxrtI5PJZE6JzGQyITs7G1ar1WWb/Px8zJw5EwAaTWDugiGkrblQdRVfbD6Cj9YdhNl6Bt26RODesf0xYUh37Dhcgc0Ha5PXmfOXAQCDE6IxekAsRg+MxY0DYjGwR5cWJSLTjmO4a/E65N6nxBNTBvt6tyTnVR+ZIAgul3Mc57iEbE4CI6S9iIoIw/0TEnH/hETsLhWwbJ0VH6+34q2Ve9A5IhSqxFjMSR2IGwfEQpUYi5hO4T75XM2InnhyShJeWr4N45O7Y1ifGJ9sN1B5lMjsfV929j4xm80GoDbRGY1GAIDZbEZ2djZYlvVVrIQEtSG9GOTOSsHCmTfgyJmLSOwe5dcyiZczbsD63Sfx0Hsb8cPCKYgMb7v39jy6tAQAvV4PhmEwc+ZMmEwmZGRkwGKxQKlUQhAEp47/jIwMp8vQ+ux1ZHZUT0aIb+0tO4txf16N+yewePN+tdThtJi9fszOozoyV4kMgOOOJMuyiImJQUVFhaPz336JKQgCYmJiYLVa3Z6VUR8ZIf73zzUH8OwyM5Y/Ox7TRvWSOhyfqJ87PD6v5XkeLMs6LjOVSqUjiaWmpjZor1AovIuYEOKVRyYNwLRRCXjin5txQqiUOhy/aDKR1e/gT0lJcSzLy8tDbm4uAIBlWcdroPYOp1arpc5/QiQmk8nwziOjESqX4bH8n1FT0/YGvbvs/TOZTCgpKQEALFq0CGq1GlqtFgCQm5sLk8kEm82GjIwMaDQaALV3K1UqlaMPzWq1wmAwtNJuEEIa061LBPKzb8Yd+rV497t9eOq2tlWSQWMtCWlH5n3GId+0H2sXTMGIvsFbkuF1HxkhJHi9nDESg3tG46F3f8Kly9VSh+MzlMgIaUc6hIXgwyfG4OiZi5hfyEkdjs/Qcy0JaWeSekbj9XuV+OD7g/jGUip1OB5x91xL6iMjpB0SRRGZb/2In/efxqbXpiI+pqPUIXmE+sgIIddLMm5EeKgcWXnBX5JBiYyQdiq2cwQKsm/G+j0nsWR1cD/DkxIZIe3YxKE98PTUZCw0bMe232xSh9NilMgIaef+rB2Bob2j8fB7G3ExSEsyKJER0s6Fh4bgg8dvQdmZi5j3WXCWZFD5BSEEg+K74PX7UvCvtQdRtOWo1OG4ReUXhJBGiaKIWUs24Mc9J7HptWnoqQjckgwqvyCEuCSTybDk4RsRGR6CrCCbJYMSGSHEQRHVAQXZY/DDnpN4a9UeqcNpNkpkhBAn44d0xzPThuAV43Zw/Bmpw2kWSmSEkAb+dPdwDO8dg4ff24gLVVelDqdJlMgIIQ3UlmSMwQmhErpPA78kgxIZIcSlgfFdoJ+Vgo/XW/Ff8xGpw2kU1ZERQtyaPZ7FneremPvhLyg9c1HqcKiOjBDSMhUXr+DmP65EckI0vnzxVqnDAUB1ZIQQD8V0Cseie5Uw7TwesAPLKZERQpqUruqFft06YUmA1pZRIiOENClELscTUwbj881HcLRc+r6y+iiREUKaZfZ4Fp0jQvFeyT6pQ2mAEhkhpFmiIsLw0K0DsWydFecqA6tIlhIZIaTZHksbhEtXqrFs3UGpQ3FCdWSEkGbrqeiIjJv64r3v9qH6Wk2rf767OjJJE1lCQgKKioqQmZkpZRiEEA/MnZqMo2cu4SsJqv0zMzNRVFSEhIQEp+V0aUkI8cjwPjGYOKQ7lqzaCwnr6Z24TWQcxyElJaXBcp7nodPpkJ+fD51OB0EQnNbp9XoYjUbo9XqndYSQtuPpacngDtnw077TUocCAAh1tdBoNIJlWXBcw1HvaWlpsFgsYBgGHMdBp9MhLy8PAJCRkQGLxQKgNqnNmTMHBoPBj+ETQqSgGR6P5IRovL1qD8YOjpM6HNdnZFqtFkqlssFyk8kEAGAYBgCgVCqRn58PoDZx1cWyrKM9IaRtkclkeOq2wVi1tQz7j5+TOhzP+sjcXSpyHAeTyQSFQuG0XKFQuDyrI4QEv9+P6Ye46AgsDYCnlHuUyJRKpdOZlz1J2Ww2t0nOZgvMQaaEEO90CAtBtmYQPttwCKfPVUkai0eJjGVZ5ObmIj8/H4IgOJJa/TOxuhrr8LfXkdn/UT0ZIcHlkUkDIZMBH3x/wK+fY68fs/+rX0fmsrO/MTk5OeB5HjzPQ6PRAKhNcAzDNDj7stlsjv40V+x1ZISQ4NS1cwfcN5ZFvukAnpk2BBHhIX75nMzMTKd60/T0dKf1HteR8TwPlmUdl5lKpRIMwziSWn0qlcrTjyCEBJEnb0tC+fkq/GfjIcliaDKR1b80TElJcSzLy8tDbm4ugNqzsrp4nodKpWr0jIwQEvwG9OiCaaN64Z3VeyV7qK/LS0uTyYSSkhIAwKJFi6BWq6HVagEAubm5MJlMsNlsyMjIcDoTMxgM0Ol0UKvVMJvNVENGSDsxd+pg3PaaCd/tOIbbbkho+g0+RnP2E0K8JooiJi38Dh07hKJ4XqrfP4/m7CeE+JxMJsPcqYPxw56T2C7BvP6UyAghPpGu6o0+sZ2wRIICWZqPjBDiE6EhcjwxOQmfbz6MMtslv3wGzUdGCPG7+yckolOHULz3nX/m9af5yAghftc5MgwPThyAj9YdxPlWnNefEhkhxKcen5yEi5er8fF6a6t9JiUyQohPJSg64u7RffFuK87rT4mMEOJzc28bjCPlF/Ff89FW+TxKZIQQnxvZT4EJQ7pjyeo9rTKvPyUyQohfzJ06GBbeho37/T+vP9WREUL8Im14TyT17IIlq3xXIEt1ZISQViWX187rv3JrKQ6e8M28/lRHRghpdfeM6Y/YzhFYuto/BbJ2lMgIIX4TER6CLM1AfLqBR/l5/83rT4mMEOJXj0waCFEEPljjv3n9KZERQvyqW5cI3Du2P/JMB1B15ZpfPoMSGSHE7568bTBOn6vC8p9/88v2qfyCEOJ3g+K7YNqoBLyzeq9XBbJUfkEIkdTcqcnYW3YWJTuOt3gbVH5BCJHULUndoOyvwJJVe3y+bUpkhJBWYZ/Xf93uk9hxuMKn26ZERghpNXeq+6B31454Z7Vvz8ookRFCWk1oiByPT06CYZNv5/WnREYIaVUPTByAjuGheL/Ed8OWKJERQlpVl8gwPDAxEf9a67t5/amOjBDS6h5PS8KFqmp88oNn8/q7qyOTia0xfaMb9R97TghpPx557ydsPlCObW/MQGiIZ+dU9XMHXVoSQiQxd2oyDpdfxNeWUq+3RYmMECKJG/opMC45Dm+v8n5ef7eJjOM4pKSkNFjO8zzy8/NhNBqh1+vB87zTeziOc7SzvyaEEFfm3paMLdYz2HSg3KvtuExkRqMRAFwmIqPRiKysLGi1WuTk5CA3N9exLi8vDykpKZDJZMjOzgbLsl4FRwhp26aM7Imlj4zG8D6MV9sJdbVQq9W6fcPy5cuRk5Pjcl1KSgoqKmqHHjCMd4ERQto+uVyG+ycker8dT9+gUCiQkpICnudhMpmQlpbmtJ5hGEpihJBW5fKMrDEGgwGpqalITExEVlYW8vLyHOsEQXBclprN5iYvL+11ZHaZmZk0pQ8hpIHCwkKnelOP6shkMlmDuwlGoxEMw4DneWRnZzslM0EQHGdjHMchIyMDVqv7gjeqIyOEtIRXdWQ8z8NsNkOj0SArKwtWqxUrVqxw3LmseweTZVnwPO+0zFttfQQA7V9wo/2TjkeJjOM4qNVqx88sy2LevHkQBAEcxyE1NbXBexQKhfdRXhfI/5G+QPsX3Gj/pNNkIhMEwfFaqVTCbDY7rT9z5gyUSiVYlnUqxTCZTNBqtU12/PvrP8eT7Xoagz+3HQgx0P61fNuBEEOw7Z+n7V21dZnITCYTdDodAGDRokWODnyWZZGWlga9Xo/8/Hzk5+cjOzsbQO3dSpVK5VhnNpthMBh8ugOeoF+UlsdA+9fybQdCDMG2f562d9VW0kHjQ4cORURERIMHCbhTVlYmedtAiYP2r2VtAyUO2j/vtl1VVYVdu3Y5lkmayAghxBdo0DghJOhRIiOEBD1KZISQoOfxECV/4nkeRqPRUUyblZXltnzDk7aBguM4mEwmALVDuAoKCtzGbJ95RKlUgud5CIIApVLZWqG2iCcxB+PxMxqN0Gg0AJqeFCFYjh/HcZgzZw4sFovT8qD7LooBRKlUOl5brVZRq9X6pG2gyM3NdXpddx/qy8rKEgGIAESNRiNWVFS0QoTe8STmYDx+9n2r+6/uMa0rGI6fwWAQLRaL6CoNBNt3MWASmdVqbfDFZhjG67aBwmKxOMVotVpFAKLVanXZPi8vT6yoqAjIL4A7zY05GI9fRUWFaDAYnJa5S2KiGFzHr34iC8bvYsD0kZlMpgbDmRQKhcvJHT1pGyiUSiUKCgocP9tHTDQ2hCsYp0RqTszBePwA53n6jEZjo/P2AcF5/IDg/C4GTB9Z3aFQddlsNq/aBpK6v/jLly+HRqNx+4vu6ZRIgaC5MQfj8at7nARBgM1ma/R4BOPxswvG72LAJDJ33P1HedtWSvZf8vodrHXV7TC1Dw1rbEqkQOBtzMFy/HQ6ndO4YleC8fg1JZC/iwFzackwTIMsbrPZXJ6xeNI2EOl0OpSUlDQar7+nRPKH5sYczMdPEASYTKYmYw3G42cXjN/FgElk9tva9alUKq/aBhq9Xg+dTgeWZSEIgsu/XK0xJZKveRJzMB+/LVu2NKv0ItiOX13B+F0MmERWv/+A53moVCqnGWftf9GaahuojEajY8ojQRCwYsUKt/vXkimRpNRUzG3h+AG1++EqIQX78av7BzUYv4sBNWic53nk5eVBrVbDbDZj3rx5jv+QjIwMqNVqxxOcGmsbiHieR2Ki89NiGIZxPHWq/v7Zi2cZhoHVam2yTyYQNBZzsB8/O71eD6vV6vSsCiA4j5/JZEJJSQn0ej1ycnKgVqsdN6SC7bsYUImMEEJaImAuLQkhpKUokRFCgh4lMkJI0KNERggJepTICCFBjxIZISTo/T/xbtR2QIQ6ogAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_years_np = pd.read_pickle(\"sensitivity_analysis/nb_years/rmse_no_physics.pkl\")\n",
    "zs_rmse_years_np = rmse_years_np.loc[(slice(None),0),:]\n",
    "zs_rmse_years_np.droplevel(1)\n",
    "for site in range(4):\n",
    "    plt.figure()\n",
    "    plt.plot(zs_rmse_np[site])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change HP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([841, 24, 8]) torch.Size([210, 24, 8]) torch.Size([841, 24, 1]) torch.Size([210, 24, 1])\n",
      "Step 0: Average train loss: 0.0687 | Average test loss: 0.0599\n",
      "Step 5: Average train loss: 0.0254 | Average test loss: 0.0172\n",
      "Step 10: Average train loss: 0.0132 | Average test loss: 0.0105\n",
      "Step 15: Average train loss: 0.0128 | Average test loss: 0.0090\n",
      "Step 20: Average train loss: 0.0113 | Average test loss: 0.0088\n",
      "Step 25: Average train loss: 0.0109 | Average test loss: 0.0086\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0084\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0083\n",
      "Step 40: Average train loss: 0.0102 | Average test loss: 0.0082\n",
      "Step 45: Average train loss: 0.0102 | Average test loss: 0.0082\n",
      "Step 50: Average train loss: 0.0101 | Average test loss: 0.0082\n",
      "Step 55: Average train loss: 0.0100 | Average test loss: 0.0081\n",
      "Step 60: Average train loss: 0.0100 | Average test loss: 0.0081\n",
      "Step 65: Average train loss: 0.0099 | Average test loss: 0.0080\n",
      "Step 70: Average train loss: 0.0099 | Average test loss: 0.0078\n",
      "Step 75: Average train loss: 0.0095 | Average test loss: 0.0082\n",
      "Step 80: Average train loss: 0.0093 | Average test loss: 0.0077\n",
      "Step 85: Average train loss: 0.0093 | Average test loss: 0.0076\n",
      "Step 90: Average train loss: 0.0092 | Average test loss: 0.0076\n",
      "Step 95: Average train loss: 0.0092 | Average test loss: 0.0076\n",
      "Best Epoch: 97\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 54745.0703125\n",
      "Step 0: Average train loss: 0.0088\n",
      "Step 5: Average train loss: 0.0088\n",
      "Step 10: Average train loss: 0.0088\n",
      "Step 15: Average train loss: 0.0088\n",
      "Step 20: Average train loss: 0.0088\n",
      "Step 25: Average train loss: 0.0087\n",
      "Step 30: Average train loss: 0.0087\n",
      "Step 35: Average train loss: 0.0087\n",
      "Step 40: Average train loss: 0.0087\n",
      "Step 45: Average train loss: 0.0087\n",
      "Step 50: Average train loss: 0.0087\n",
      "Step 55: Average train loss: 0.0087\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0087\n",
      "Step 80: Average train loss: 0.0087\n",
      "Step 85: Average train loss: 0.0087\n",
      "Step 90: Average train loss: 0.0087\n",
      "Step 95: Average train loss: 0.0087\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 58265.85546875\n",
      "Step 0: Average train loss: 0.0097\n",
      "Step 5: Average train loss: 0.0097\n",
      "Step 10: Average train loss: 0.0097\n",
      "Step 15: Average train loss: 0.0097\n",
      "Step 20: Average train loss: 0.0097\n",
      "Step 25: Average train loss: 0.0097\n",
      "Step 30: Average train loss: 0.0097\n",
      "Step 35: Average train loss: 0.0097\n",
      "Step 40: Average train loss: 0.0097\n",
      "Step 45: Average train loss: 0.0097\n",
      "Step 50: Average train loss: 0.0097\n",
      "Step 55: Average train loss: 0.0096\n",
      "Step 60: Average train loss: 0.0096\n",
      "Step 65: Average train loss: 0.0096\n",
      "Step 70: Average train loss: 0.0096\n",
      "Step 75: Average train loss: 0.0096\n",
      "Step 80: Average train loss: 0.0096\n",
      "Step 85: Average train loss: 0.0096\n",
      "Step 90: Average train loss: 0.0096\n",
      "Step 95: Average train loss: 0.0096\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 44854.52734375\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0083\n",
      "Step 20: Average train loss: 0.0083\n",
      "Step 25: Average train loss: 0.0083\n",
      "Step 30: Average train loss: 0.0083\n",
      "Step 35: Average train loss: 0.0083\n",
      "Step 40: Average train loss: 0.0083\n",
      "Step 45: Average train loss: 0.0083\n",
      "Step 50: Average train loss: 0.0083\n",
      "Step 55: Average train loss: 0.0082\n",
      "Step 60: Average train loss: 0.0082\n",
      "Step 65: Average train loss: 0.0082\n",
      "Step 70: Average train loss: 0.0082\n",
      "Step 75: Average train loss: 0.0082\n",
      "Step 80: Average train loss: 0.0082\n",
      "Step 85: Average train loss: 0.0082\n",
      "Step 90: Average train loss: 0.0082\n",
      "Step 95: Average train loss: 0.0082\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 52077.8203125\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0083\n",
      "Step 20: Average train loss: 0.0083\n",
      "Step 25: Average train loss: 0.0082\n",
      "Step 30: Average train loss: 0.0082\n",
      "Step 35: Average train loss: 0.0082\n",
      "Step 40: Average train loss: 0.0082\n",
      "Step 45: Average train loss: 0.0082\n",
      "Step 50: Average train loss: 0.0082\n",
      "Step 55: Average train loss: 0.0082\n",
      "Step 60: Average train loss: 0.0082\n",
      "Step 65: Average train loss: 0.0082\n",
      "Step 70: Average train loss: 0.0082\n",
      "Step 75: Average train loss: 0.0082\n",
      "Step 80: Average train loss: 0.0082\n",
      "Step 85: Average train loss: 0.0082\n",
      "Step 90: Average train loss: 0.0082\n",
      "Step 95: Average train loss: 0.0082\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 49971.24609375\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0079\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0079\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0079\n",
      "Step 35: Average train loss: 0.0079\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 38821.2265625\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0077\n",
      "Step 10: Average train loss: 0.0077\n",
      "Step 15: Average train loss: 0.0077\n",
      "Step 20: Average train loss: 0.0077\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 23706.328125\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0065\n",
      "Step 10: Average train loss: 0.0065\n",
      "Step 15: Average train loss: 0.0065\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0065\n",
      "Step 30: Average train loss: 0.0065\n",
      "Step 35: Average train loss: 0.0065\n",
      "Step 40: Average train loss: 0.0065\n",
      "Step 45: Average train loss: 0.0065\n",
      "Step 50: Average train loss: 0.0065\n",
      "Step 55: Average train loss: 0.0065\n",
      "Step 60: Average train loss: 0.0065\n",
      "Step 65: Average train loss: 0.0065\n",
      "Step 70: Average train loss: 0.0065\n",
      "Step 75: Average train loss: 0.0065\n",
      "Step 80: Average train loss: 0.0065\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 8873.1220703125\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0063\n",
      "Step 55: Average train loss: 0.0063\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0063\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 11810.296875\n",
      "Step 0: Average train loss: 0.0056\n",
      "Step 5: Average train loss: 0.0056\n",
      "Step 10: Average train loss: 0.0056\n",
      "Step 15: Average train loss: 0.0056\n",
      "Step 20: Average train loss: 0.0056\n",
      "Step 25: Average train loss: 0.0056\n",
      "Step 30: Average train loss: 0.0056\n",
      "Step 35: Average train loss: 0.0056\n",
      "Step 40: Average train loss: 0.0056\n",
      "Step 45: Average train loss: 0.0056\n",
      "Step 50: Average train loss: 0.0056\n",
      "Step 55: Average train loss: 0.0056\n",
      "Step 60: Average train loss: 0.0056\n",
      "Step 65: Average train loss: 0.0056\n",
      "Step 70: Average train loss: 0.0056\n",
      "Step 75: Average train loss: 0.0056\n",
      "Step 80: Average train loss: 0.0056\n",
      "Step 85: Average train loss: 0.0056\n",
      "Step 90: Average train loss: 0.0056\n",
      "Step 95: Average train loss: 0.0056\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 38618.6953125\n",
      "Step 0: Average train loss: 0.0073\n",
      "Step 5: Average train loss: 0.0073\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0073\n",
      "Step 20: Average train loss: 0.0073\n",
      "Step 25: Average train loss: 0.0073\n",
      "Step 30: Average train loss: 0.0073\n",
      "Step 35: Average train loss: 0.0073\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 53580.9453125\n",
      "Step 0: Average train loss: 0.0063\n",
      "Step 5: Average train loss: 0.0063\n",
      "Step 10: Average train loss: 0.0063\n",
      "Step 15: Average train loss: 0.0063\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0063\n",
      "Step 55: Average train loss: 0.0063\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0063\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 55443.83203125\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m hp\u001b[38;5;241m.\u001b[39mload(model_hp)\n\u001b[0;32m     39\u001b[0m hp\u001b[38;5;241m.\u001b[39msource_state_dict \u001b[38;5;241m=\u001b[39m state_dict\n\u001b[1;32m---> 40\u001b[0m accur, timer, forecasts \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mWFE\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m;\n\u001b[0;32m     42\u001b[0m df_forecasts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(forecasts, index\u001b[38;5;241m=\u001b[39meval_data\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m24\u001b[39m:], name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP_DA\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \n\u001b[0;32m     43\u001b[0m df_forecasts\u001b[38;5;241m.\u001b[39mto_pickle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msensitivity_analysis/change_HP/DA_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msite\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m) \n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Models\\models.py:57\u001b[0m, in \u001b[0;36mtarget\u001b[1;34m(dataset, features, hp, scale, WFE)\u001b[0m\n\u001b[0;32m     54\u001b[0m     transfer_model\u001b[38;5;241m.\u001b[39mload_state_dict(hp\u001b[38;5;241m.\u001b[39msource_state_dict)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m WFE:\n\u001b[1;32m---> 57\u001b[0m     avg_error, times, forecasts \u001b[38;5;241m=\u001b[39m \u001b[43mWF_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransfer_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     avg_error, times \u001b[38;5;241m=\u001b[39m trainer(dataset, features, hp, transfer_model, scale\u001b[38;5;241m=\u001b[39mscale)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Models\\models.py:232\u001b[0m, in \u001b[0;36mWF_trainer\u001b[1;34m(dataset, features, hp, model, scale, criterion)\u001b[0m\n\u001b[0;32m    229\u001b[0m train_timer \u001b[38;5;241m=\u001b[39m Timer()\n\u001b[0;32m    230\u001b[0m training \u001b[38;5;241m=\u001b[39m Training(model, X_train[i], y_train[i], \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, epochs, learning_rate\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39mlr, criterion\u001b[38;5;241m=\u001b[39mcriterion, \n\u001b[0;32m    231\u001b[0m                 trial\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39mtrial, optimizer_name\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39moptimizer_name, weight_decay \u001b[38;5;241m=\u001b[39m hp\u001b[38;5;241m.\u001b[39mwd, batch_size\u001b[38;5;241m=\u001b[39mhp\u001b[38;5;241m.\u001b[39mbatch_size)\n\u001b[1;32m--> 232\u001b[0m avg_error, state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m train_timer\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m    234\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(state_dict)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Models\\training.py:123\u001b[0m, in \u001b[0;36mTraining.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    120\u001b[0m     num_train_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    122\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 123\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    124\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m    126\u001b[0m avg_train_error\u001b[38;5;241m.\u001b[39mappend(total_loss \u001b[38;5;241m/\u001b[39m num_train_batches)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "my_index = pd.MultiIndex.from_product([range(4), range(13)])\n",
    "rmse = pd.DataFrame(index=my_index, columns=range(4))\n",
    "rmse_source = pd.DataFrame(index=range(4), columns=range(4))\n",
    "sites = range(4)\n",
    "model = 0\n",
    "warnings. filterwarnings('ignore') \n",
    "for model in range(1,4):\n",
    "    if model in [1,3]:\n",
    "        phys=True\n",
    "        phys_str = \"phys.pkl\"\n",
    "        model_hp = model-1\n",
    "    else:\n",
    "        phys=False\n",
    "        phys_str = \"no_phys.pkl\"\n",
    "        model_hp = model+1\n",
    "    if model < 2:\n",
    "        dataset_name = \"nwp\"\n",
    "    else:\n",
    "        dataset_name = \"era5\"\n",
    "    \n",
    "    for site in sites:\n",
    "        source_data, _, eval_data = data_handeler(site, dataset_name, 'nwp', 'nwp', phys,  HP_tuning=False);\n",
    "        ftr_file='features/ft_'+phys_str\n",
    "\n",
    "\n",
    "        with open(ftr_file, 'rb') as f:\n",
    "            features = pickle.load(f)\n",
    "        scale = Scale()\n",
    "        scale.load(site, dataset_name, phys)\n",
    "\n",
    "        hp = hyperparameters_source()\n",
    "        hp.load(model_hp)\n",
    "\n",
    "\n",
    "        accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "        rmse_source.loc[model, site] = accuracy\n",
    "        hp = hyperparameters_target()\n",
    "        hp.load(model_hp)\n",
    "        hp.source_state_dict = state_dict\n",
    "        accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "\n",
    "        df_forecasts = pd.Series(forecasts, index=eval_data.index[24:], name=\"P_DA\")  \n",
    "        df_forecasts.to_pickle(f\"sensitivity_analysis/change_HP/DA_{model}_{site}.pkl\") \n",
    "        rmse.loc[(0, slice(len(accur)-1)),site] = accur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('solnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02543bb0ef14551c549047461536d109a34ccf1dceeb84fa14a9d60c3d57cc93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
