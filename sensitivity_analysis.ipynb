{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Data.Featurisation import data_handeler\n",
    "from Models.models import source, target\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import os\n",
    "from scale import Scale\n",
    "from hyperparameters.hyperparameters import hyperparameters_source, hyperparameters_target\n",
    "import torch\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Physics-informed measures\n",
    "- is_day\n",
    "- PoA, T_PV\n",
    "- inverter limit\n",
    "- decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calclations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IS DAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_index = pd.MultiIndex.from_product([range(7), range(13)])\n",
    "rmse = pd.DataFrame(index=my_index, columns=range(4))\n",
    "sites = range(4)\n",
    "model = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([841, 24, 7]) torch.Size([210, 24, 7]) torch.Size([841, 24, 1]) torch.Size([210, 24, 1])\n",
      "Step 0: Average train loss: 0.0505 | Average test loss: 0.0386\n",
      "Step 5: Average train loss: 0.0131 | Average test loss: 0.0099\n",
      "Step 10: Average train loss: 0.0117 | Average test loss: 0.0095\n",
      "Step 15: Average train loss: 0.0111 | Average test loss: 0.0090\n",
      "Step 20: Average train loss: 0.0108 | Average test loss: 0.0089\n",
      "Step 25: Average train loss: 0.0106 | Average test loss: 0.0088\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0087\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0087\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0086\n",
      "Step 45: Average train loss: 0.0101 | Average test loss: 0.0087\n",
      "Step 50: Average train loss: 0.0099 | Average test loss: 0.0085\n",
      "Step 55: Average train loss: 0.0096 | Average test loss: 0.0083\n",
      "Step 60: Average train loss: 0.0102 | Average test loss: 0.0096\n",
      "Step 65: Average train loss: 0.0095 | Average test loss: 0.0085\n",
      "Step 70: Average train loss: 0.0093 | Average test loss: 0.0084\n",
      "Step 75: Average train loss: 0.0098 | Average test loss: 0.0105\n",
      "Step 80: Average train loss: 0.0094 | Average test loss: 0.0086\n",
      "Step 85: Average train loss: 0.0091 | Average test loss: 0.0083\n",
      "Step 90: Average train loss: 0.0094 | Average test loss: 0.0090\n",
      "Step 95: Average train loss: 0.0091 | Average test loss: 0.0081\n",
      "Best Epoch: 93\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 55069.78515625\n",
      "Step 0: Average train loss: 0.0088\n",
      "Step 5: Average train loss: 0.0088\n",
      "Step 10: Average train loss: 0.0088\n",
      "Step 15: Average train loss: 0.0088\n",
      "Step 20: Average train loss: 0.0088\n",
      "Step 25: Average train loss: 0.0088\n",
      "Step 30: Average train loss: 0.0088\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0087\n",
      "Step 50: Average train loss: 0.0087\n",
      "Step 55: Average train loss: 0.0087\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0087\n",
      "Step 80: Average train loss: 0.0087\n",
      "Step 85: Average train loss: 0.0087\n",
      "Step 90: Average train loss: 0.0087\n",
      "Step 95: Average train loss: 0.0087\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 56403.37890625\n",
      "Step 0: Average train loss: 0.0090\n",
      "Step 5: Average train loss: 0.0090\n",
      "Step 10: Average train loss: 0.0090\n",
      "Step 15: Average train loss: 0.0090\n",
      "Step 20: Average train loss: 0.0090\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0090\n",
      "Step 70: Average train loss: 0.0090\n",
      "Step 75: Average train loss: 0.0090\n",
      "Step 80: Average train loss: 0.0090\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 46440.70703125\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0083\n",
      "Step 20: Average train loss: 0.0083\n",
      "Step 25: Average train loss: 0.0083\n",
      "Step 30: Average train loss: 0.0083\n",
      "Step 35: Average train loss: 0.0083\n",
      "Step 40: Average train loss: 0.0083\n",
      "Step 45: Average train loss: 0.0083\n",
      "Step 50: Average train loss: 0.0083\n",
      "Step 55: Average train loss: 0.0083\n",
      "Step 60: Average train loss: 0.0083\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0083\n",
      "Step 80: Average train loss: 0.0082\n",
      "Step 85: Average train loss: 0.0082\n",
      "Step 90: Average train loss: 0.0082\n",
      "Step 95: Average train loss: 0.0082\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50566.69921875\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0081\n",
      "Step 10: Average train loss: 0.0081\n",
      "Step 15: Average train loss: 0.0081\n",
      "Step 20: Average train loss: 0.0081\n",
      "Step 25: Average train loss: 0.0081\n",
      "Step 30: Average train loss: 0.0081\n",
      "Step 35: Average train loss: 0.0081\n",
      "Step 40: Average train loss: 0.0081\n",
      "Step 45: Average train loss: 0.0081\n",
      "Step 50: Average train loss: 0.0081\n",
      "Step 55: Average train loss: 0.0081\n",
      "Step 60: Average train loss: 0.0081\n",
      "Step 65: Average train loss: 0.0081\n",
      "Step 70: Average train loss: 0.0081\n",
      "Step 75: Average train loss: 0.0081\n",
      "Step 80: Average train loss: 0.0081\n",
      "Step 85: Average train loss: 0.0081\n",
      "Step 90: Average train loss: 0.0081\n",
      "Step 95: Average train loss: 0.0080\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 50750.734375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0077\n",
      "Step 10: Average train loss: 0.0077\n",
      "Step 15: Average train loss: 0.0077\n",
      "Step 20: Average train loss: 0.0077\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0076\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 39372.72265625\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0077\n",
      "Step 10: Average train loss: 0.0077\n",
      "Step 15: Average train loss: 0.0077\n",
      "Step 20: Average train loss: 0.0077\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 26353.955078125\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0069\n",
      "Step 10: Average train loss: 0.0069\n",
      "Step 15: Average train loss: 0.0069\n",
      "Step 20: Average train loss: 0.0069\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0069\n",
      "Step 75: Average train loss: 0.0069\n",
      "Step 80: Average train loss: 0.0069\n",
      "Step 85: Average train loss: 0.0069\n",
      "Step 90: Average train loss: 0.0069\n",
      "Step 95: Average train loss: 0.0069\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9927.32421875\n",
      "Step 0: Average train loss: 0.0058\n",
      "Step 5: Average train loss: 0.0058\n",
      "Step 10: Average train loss: 0.0058\n",
      "Step 15: Average train loss: 0.0058\n",
      "Step 20: Average train loss: 0.0058\n",
      "Step 25: Average train loss: 0.0058\n",
      "Step 30: Average train loss: 0.0058\n",
      "Step 35: Average train loss: 0.0058\n",
      "Step 40: Average train loss: 0.0058\n",
      "Step 45: Average train loss: 0.0058\n",
      "Step 50: Average train loss: 0.0058\n",
      "Step 55: Average train loss: 0.0057\n",
      "Step 60: Average train loss: 0.0057\n",
      "Step 65: Average train loss: 0.0057\n",
      "Step 70: Average train loss: 0.0057\n",
      "Step 75: Average train loss: 0.0057\n",
      "Step 80: Average train loss: 0.0057\n",
      "Step 85: Average train loss: 0.0057\n",
      "Step 90: Average train loss: 0.0057\n",
      "Step 95: Average train loss: 0.0057\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 13903.013671875\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0058\n",
      "Step 25: Average train loss: 0.0058\n",
      "Step 30: Average train loss: 0.0058\n",
      "Step 35: Average train loss: 0.0058\n",
      "Step 40: Average train loss: 0.0058\n",
      "Step 45: Average train loss: 0.0058\n",
      "Step 50: Average train loss: 0.0058\n",
      "Step 55: Average train loss: 0.0058\n",
      "Step 60: Average train loss: 0.0058\n",
      "Step 65: Average train loss: 0.0058\n",
      "Step 70: Average train loss: 0.0058\n",
      "Step 75: Average train loss: 0.0058\n",
      "Step 80: Average train loss: 0.0058\n",
      "Step 85: Average train loss: 0.0058\n",
      "Step 90: Average train loss: 0.0058\n",
      "Step 95: Average train loss: 0.0058\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 42595.94921875\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 54259.5546875\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n",
      "Step 60: Average train loss: 0.0067\n",
      "Step 65: Average train loss: 0.0067\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 56196.90625\n",
      "Step 0: Average train loss: 0.0065\n",
      "Step 5: Average train loss: 0.0065\n",
      "Step 10: Average train loss: 0.0065\n",
      "Step 15: Average train loss: 0.0065\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0065\n",
      "Step 30: Average train loss: 0.0065\n",
      "Step 35: Average train loss: 0.0065\n",
      "Step 40: Average train loss: 0.0065\n",
      "Step 45: Average train loss: 0.0065\n",
      "Step 50: Average train loss: 0.0065\n",
      "Step 55: Average train loss: 0.0065\n",
      "Step 60: Average train loss: 0.0065\n",
      "Step 65: Average train loss: 0.0065\n",
      "Step 70: Average train loss: 0.0065\n",
      "Step 75: Average train loss: 0.0065\n",
      "Step 80: Average train loss: 0.0065\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 81298.0\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([839, 24, 7]) torch.Size([210, 24, 7]) torch.Size([839, 24, 1]) torch.Size([210, 24, 1])\n",
      "Step 0: Average train loss: 0.0474 | Average test loss: 0.0301\n",
      "Step 5: Average train loss: 0.0100 | Average test loss: 0.0075\n",
      "Step 10: Average train loss: 0.0095 | Average test loss: 0.0065\n",
      "Step 15: Average train loss: 0.0095 | Average test loss: 0.0076\n",
      "Step 20: Average train loss: 0.0091 | Average test loss: 0.0070\n",
      "Step 25: Average train loss: 0.0090 | Average test loss: 0.0075\n",
      "Step 30: Average train loss: 0.0090 | Average test loss: 0.0062\n",
      "Step 35: Average train loss: 0.0090 | Average test loss: 0.0072\n",
      "Step 40: Average train loss: 0.0089 | Average test loss: 0.0063\n",
      "Step 45: Average train loss: 0.0087 | Average test loss: 0.0065\n",
      "Step 50: Average train loss: 0.0086 | Average test loss: 0.0061\n",
      "Step 55: Average train loss: 0.0087 | Average test loss: 0.0067\n",
      "Step 60: Average train loss: 0.0083 | Average test loss: 0.0057\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m hp \u001b[38;5;241m=\u001b[39m hyperparameters_source()\n\u001b[0;32m     16\u001b[0m hp\u001b[38;5;241m.\u001b[39mload(model)\n\u001b[1;32m---> 19\u001b[0m accuracy, state_dict, timer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m;\n\u001b[0;32m     21\u001b[0m hp \u001b[38;5;241m=\u001b[39m hyperparameters_target()\n\u001b[0;32m     22\u001b[0m hp\u001b[38;5;241m.\u001b[39mload(model)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Models\\models.py:38\u001b[0m, in \u001b[0;36msource\u001b[1;34m(dataset, features, hp, scale)\u001b[0m\n\u001b[0;32m     34\u001b[0m     input_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(features)\n\u001b[0;32m     36\u001b[0m source_model \u001b[38;5;241m=\u001b[39m LSTM(input_size,hp\u001b[38;5;241m.\u001b[39mn_nodes,hp\u001b[38;5;241m.\u001b[39mn_layers, forecast_period, hp\u001b[38;5;241m.\u001b[39mdropout, hp\u001b[38;5;241m.\u001b[39mbd, day_index)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 38\u001b[0m avg_error, source_state_dict, timer \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hp\u001b[38;5;241m.\u001b[39mtrial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_error, source_state_dict, timer\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Models\\models.py:157\u001b[0m, in \u001b[0;36mtrainer\u001b[1;34m(dataset, features, hp, model, scale, criterion)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hp\u001b[38;5;241m.\u001b[39mtrial \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    156\u001b[0m     timer \u001b[38;5;241m=\u001b[39m Timer()\n\u001b[1;32m--> 157\u001b[0m     avg_error, state_dict \u001b[38;5;241m=\u001b[39m \u001b[43mtraining\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     timer\u001b[38;5;241m.\u001b[39mstop()\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Models\\training.py:116\u001b[0m, in \u001b[0;36mTraining.fit\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28minput\u001b[39m, output \u001b[38;5;129;01min\u001b[39;00m batches:\n\u001b[1;32m--> 116\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m     output \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[0;32m    118\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(prediction, output)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\SolNet-2\\Models\\lstm.py:58\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     56\u001b[0m     input_new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\n\u001b[1;32m---> 58\u001b[0m hidden, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_new\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbd:                   \n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m hidden\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:878\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    875\u001b[0m         hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m    877\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 878\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_weights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbidirectional\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_first\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mlstm(\u001b[38;5;28minput\u001b[39m, batch_sizes, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias,\n\u001b[0;32m    882\u001b[0m                       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', HP_tuning=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('is_day')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "\n",
    "    rmse.loc[(0, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 6]) torch.Size([140, 24, 6]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0581 | Average test loss: 0.0352\n",
      "Step 5: Average train loss: 0.0281 | Average test loss: 0.0189\n",
      "Step 10: Average train loss: 0.0129 | Average test loss: 0.0128\n",
      "Step 15: Average train loss: 0.0119 | Average test loss: 0.0108\n",
      "Step 20: Average train loss: 0.0111 | Average test loss: 0.0101\n",
      "Step 25: Average train loss: 0.0107 | Average test loss: 0.0104\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0103\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0101\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0100\n",
      "Step 45: Average train loss: 0.0101 | Average test loss: 0.0096\n",
      "Step 50: Average train loss: 0.0100 | Average test loss: 0.0093\n",
      "Step 55: Average train loss: 0.0099 | Average test loss: 0.0094\n",
      "Step 60: Average train loss: 0.0096 | Average test loss: 0.0089\n",
      "Step 65: Average train loss: 0.0096 | Average test loss: 0.0088\n",
      "Step 70: Average train loss: 0.0098 | Average test loss: 0.0095\n",
      "Step 75: Average train loss: 0.0095 | Average test loss: 0.0088\n",
      "Step 80: Average train loss: 0.0096 | Average test loss: 0.0087\n",
      "Step 85: Average train loss: 0.0096 | Average test loss: 0.0089\n",
      "Step 90: Average train loss: 0.0095 | Average test loss: 0.0089\n",
      "Step 95: Average train loss: 0.0095 | Average test loss: 0.0089\n",
      "Best Epoch: 74\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 67267.3671875\n",
      "Step 0: Average train loss: 0.0108\n",
      "Step 5: Average train loss: 0.0108\n",
      "Step 10: Average train loss: 0.0108\n",
      "Step 15: Average train loss: 0.0107\n",
      "Step 20: Average train loss: 0.0107\n",
      "Step 25: Average train loss: 0.0107\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0107\n",
      "Step 40: Average train loss: 0.0107\n",
      "Step 45: Average train loss: 0.0106\n",
      "Step 50: Average train loss: 0.0106\n",
      "Step 55: Average train loss: 0.0106\n",
      "Step 60: Average train loss: 0.0106\n",
      "Step 65: Average train loss: 0.0106\n",
      "Step 70: Average train loss: 0.0105\n",
      "Step 75: Average train loss: 0.0105\n",
      "Step 80: Average train loss: 0.0105\n",
      "Step 85: Average train loss: 0.0105\n",
      "Step 90: Average train loss: 0.0105\n",
      "Step 95: Average train loss: 0.0105\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 61848.84375\n",
      "Step 0: Average train loss: 0.0104\n",
      "Step 5: Average train loss: 0.0104\n",
      "Step 10: Average train loss: 0.0103\n",
      "Step 15: Average train loss: 0.0103\n",
      "Step 20: Average train loss: 0.0103\n",
      "Step 25: Average train loss: 0.0103\n",
      "Step 30: Average train loss: 0.0103\n",
      "Step 35: Average train loss: 0.0102\n",
      "Step 40: Average train loss: 0.0102\n",
      "Step 45: Average train loss: 0.0102\n",
      "Step 50: Average train loss: 0.0102\n",
      "Step 55: Average train loss: 0.0102\n",
      "Step 60: Average train loss: 0.0101\n",
      "Step 65: Average train loss: 0.0101\n",
      "Step 70: Average train loss: 0.0101\n",
      "Step 75: Average train loss: 0.0101\n",
      "Step 80: Average train loss: 0.0101\n",
      "Step 85: Average train loss: 0.0101\n",
      "Step 90: Average train loss: 0.0100\n",
      "Step 95: Average train loss: 0.0100\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 48361.44921875\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0090\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0089\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0089\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0088\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0088\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50584.52734375\n",
      "Step 0: Average train loss: 0.0085\n",
      "Step 5: Average train loss: 0.0085\n",
      "Step 10: Average train loss: 0.0085\n",
      "Step 15: Average train loss: 0.0085\n",
      "Step 20: Average train loss: 0.0085\n",
      "Step 25: Average train loss: 0.0084\n",
      "Step 30: Average train loss: 0.0084\n",
      "Step 35: Average train loss: 0.0084\n",
      "Step 40: Average train loss: 0.0084\n",
      "Step 45: Average train loss: 0.0084\n",
      "Step 50: Average train loss: 0.0084\n",
      "Step 55: Average train loss: 0.0084\n",
      "Step 60: Average train loss: 0.0084\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0083\n",
      "Step 80: Average train loss: 0.0083\n",
      "Step 85: Average train loss: 0.0083\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 46891.515625\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0076\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 42090.41015625\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 28787.296875\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 12834.37109375\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 16912.67578125\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 39538.83984375\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 57669.7109375\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 58464.8671875\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 74974.3671875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 6]) torch.Size([140, 24, 6]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0524 | Average test loss: 0.0257\n",
      "Step 5: Average train loss: 0.0172 | Average test loss: 0.0167\n",
      "Step 10: Average train loss: 0.0093 | Average test loss: 0.0074\n",
      "Step 15: Average train loss: 0.0102 | Average test loss: 0.0085\n",
      "Step 20: Average train loss: 0.0091 | Average test loss: 0.0074\n",
      "Step 25: Average train loss: 0.0092 | Average test loss: 0.0073\n",
      "Step 30: Average train loss: 0.0090 | Average test loss: 0.0071\n",
      "Step 35: Average train loss: 0.0089 | Average test loss: 0.0071\n",
      "Step 40: Average train loss: 0.0089 | Average test loss: 0.0071\n",
      "Step 45: Average train loss: 0.0087 | Average test loss: 0.0070\n",
      "Step 50: Average train loss: 0.0087 | Average test loss: 0.0068\n",
      "Step 55: Average train loss: 0.0088 | Average test loss: 0.0066\n",
      "Step 60: Average train loss: 0.0089 | Average test loss: 0.0069\n",
      "Step 65: Average train loss: 0.0089 | Average test loss: 0.0070\n",
      "Step 70: Average train loss: 0.0086 | Average test loss: 0.0068\n",
      "Step 75: Average train loss: 0.0084 | Average test loss: 0.0065\n",
      "Step 80: Average train loss: 0.0082 | Average test loss: 0.0063\n",
      "Step 85: Average train loss: 0.0081 | Average test loss: 0.0062\n",
      "Step 90: Average train loss: 0.0080 | Average test loss: 0.0062\n",
      "Step 95: Average train loss: 0.0079 | Average test loss: 0.0060\n",
      "Best Epoch: 93\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 53166.72265625\n",
      "Step 0: Average train loss: 0.0111\n",
      "Step 5: Average train loss: 0.0111\n",
      "Step 10: Average train loss: 0.0111\n",
      "Step 15: Average train loss: 0.0111\n",
      "Step 20: Average train loss: 0.0111\n",
      "Step 25: Average train loss: 0.0111\n",
      "Step 30: Average train loss: 0.0110\n",
      "Step 35: Average train loss: 0.0110\n",
      "Step 40: Average train loss: 0.0110\n",
      "Step 45: Average train loss: 0.0110\n",
      "Step 50: Average train loss: 0.0110\n",
      "Step 55: Average train loss: 0.0109\n",
      "Step 60: Average train loss: 0.0109\n",
      "Step 65: Average train loss: 0.0109\n",
      "Step 70: Average train loss: 0.0109\n",
      "Step 75: Average train loss: 0.0109\n",
      "Step 80: Average train loss: 0.0108\n",
      "Step 85: Average train loss: 0.0108\n",
      "Step 90: Average train loss: 0.0108\n",
      "Step 95: Average train loss: 0.0108\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 46638.984375\n",
      "Step 0: Average train loss: 0.0102\n",
      "Step 5: Average train loss: 0.0101\n",
      "Step 10: Average train loss: 0.0101\n",
      "Step 15: Average train loss: 0.0101\n",
      "Step 20: Average train loss: 0.0101\n",
      "Step 25: Average train loss: 0.0100\n",
      "Step 30: Average train loss: 0.0100\n",
      "Step 35: Average train loss: 0.0100\n",
      "Step 40: Average train loss: 0.0100\n",
      "Step 45: Average train loss: 0.0099\n",
      "Step 50: Average train loss: 0.0099\n",
      "Step 55: Average train loss: 0.0099\n",
      "Step 60: Average train loss: 0.0099\n",
      "Step 65: Average train loss: 0.0098\n",
      "Step 70: Average train loss: 0.0098\n",
      "Step 75: Average train loss: 0.0098\n",
      "Step 80: Average train loss: 0.0098\n",
      "Step 85: Average train loss: 0.0098\n",
      "Step 90: Average train loss: 0.0097\n",
      "Step 95: Average train loss: 0.0097\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 52891.1796875\n",
      "Step 0: Average train loss: 0.0102\n",
      "Step 5: Average train loss: 0.0102\n",
      "Step 10: Average train loss: 0.0102\n",
      "Step 15: Average train loss: 0.0101\n",
      "Step 20: Average train loss: 0.0101\n",
      "Step 25: Average train loss: 0.0101\n",
      "Step 30: Average train loss: 0.0101\n",
      "Step 35: Average train loss: 0.0101\n",
      "Step 40: Average train loss: 0.0100\n",
      "Step 45: Average train loss: 0.0100\n",
      "Step 50: Average train loss: 0.0100\n",
      "Step 55: Average train loss: 0.0100\n",
      "Step 60: Average train loss: 0.0100\n",
      "Step 65: Average train loss: 0.0099\n",
      "Step 70: Average train loss: 0.0099\n",
      "Step 75: Average train loss: 0.0099\n",
      "Step 80: Average train loss: 0.0099\n",
      "Step 85: Average train loss: 0.0099\n",
      "Step 90: Average train loss: 0.0098\n",
      "Step 95: Average train loss: 0.0098\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 33174.09375\n",
      "Step 0: Average train loss: 0.0088\n",
      "Step 5: Average train loss: 0.0088\n",
      "Step 10: Average train loss: 0.0087\n",
      "Step 15: Average train loss: 0.0087\n",
      "Step 20: Average train loss: 0.0087\n",
      "Step 25: Average train loss: 0.0087\n",
      "Step 30: Average train loss: 0.0087\n",
      "Step 35: Average train loss: 0.0087\n",
      "Step 40: Average train loss: 0.0086\n",
      "Step 45: Average train loss: 0.0086\n",
      "Step 50: Average train loss: 0.0086\n",
      "Step 55: Average train loss: 0.0086\n",
      "Step 60: Average train loss: 0.0086\n",
      "Step 65: Average train loss: 0.0085\n",
      "Step 70: Average train loss: 0.0085\n",
      "Step 75: Average train loss: 0.0085\n",
      "Step 80: Average train loss: 0.0085\n",
      "Step 85: Average train loss: 0.0085\n",
      "Step 90: Average train loss: 0.0085\n",
      "Step 95: Average train loss: 0.0084\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 34521.9765625\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0081\n",
      "Step 10: Average train loss: 0.0080\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0080\n",
      "Step 25: Average train loss: 0.0080\n",
      "Step 30: Average train loss: 0.0080\n",
      "Step 35: Average train loss: 0.0080\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23388.98046875\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0075\n",
      "Step 10: Average train loss: 0.0075\n",
      "Step 15: Average train loss: 0.0075\n",
      "Step 20: Average train loss: 0.0075\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0074\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 12837.6474609375\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0063\n",
      "Step 55: Average train loss: 0.0063\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0063\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 8805.205078125\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 11746.576171875\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 15589.7529296875\n",
      "Step 0: Average train loss: 0.0052\n",
      "Step 5: Average train loss: 0.0052\n",
      "Step 10: Average train loss: 0.0052\n",
      "Step 15: Average train loss: 0.0052\n",
      "Step 20: Average train loss: 0.0052\n",
      "Step 25: Average train loss: 0.0052\n",
      "Step 30: Average train loss: 0.0052\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0052\n",
      "Step 55: Average train loss: 0.0052\n",
      "Step 60: Average train loss: 0.0052\n",
      "Step 65: Average train loss: 0.0052\n",
      "Step 70: Average train loss: 0.0052\n",
      "Step 75: Average train loss: 0.0052\n",
      "Step 80: Average train loss: 0.0052\n",
      "Step 85: Average train loss: 0.0052\n",
      "Step 90: Average train loss: 0.0052\n",
      "Step 95: Average train loss: 0.0052\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 45858.41015625\n",
      "Step 0: Average train loss: 0.0065\n",
      "Step 5: Average train loss: 0.0065\n",
      "Step 10: Average train loss: 0.0065\n",
      "Step 15: Average train loss: 0.0065\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 37543.17578125\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 31712.857421875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 6]) torch.Size([144, 24, 6]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0488 | Average test loss: 0.0421\n",
      "Step 5: Average train loss: 0.0085 | Average test loss: 0.0037\n",
      "Step 10: Average train loss: 0.0068 | Average test loss: 0.0023\n",
      "Step 15: Average train loss: 0.0057 | Average test loss: 0.0017\n",
      "Step 20: Average train loss: 0.0053 | Average test loss: 0.0018\n",
      "Step 25: Average train loss: 0.0052 | Average test loss: 0.0018\n",
      "Step 30: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 40: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 55: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 60: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 65: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 70: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 75: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 80: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 85: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 90: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 95: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Best Epoch: 15\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 303629.0\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0160\n",
      "Step 30: Average train loss: 0.0160\n",
      "Step 35: Average train loss: 0.0160\n",
      "Step 40: Average train loss: 0.0160\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0159\n",
      "Step 90: Average train loss: 0.0159\n",
      "Step 95: Average train loss: 0.0159\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 297376.1875\n",
      "Step 0: Average train loss: 0.0155\n",
      "Step 5: Average train loss: 0.0155\n",
      "Step 10: Average train loss: 0.0155\n",
      "Step 15: Average train loss: 0.0155\n",
      "Step 20: Average train loss: 0.0155\n",
      "Step 25: Average train loss: 0.0155\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0154\n",
      "Step 40: Average train loss: 0.0154\n",
      "Step 45: Average train loss: 0.0154\n",
      "Step 50: Average train loss: 0.0154\n",
      "Step 55: Average train loss: 0.0154\n",
      "Step 60: Average train loss: 0.0154\n",
      "Step 65: Average train loss: 0.0154\n",
      "Step 70: Average train loss: 0.0154\n",
      "Step 75: Average train loss: 0.0154\n",
      "Step 80: Average train loss: 0.0153\n",
      "Step 85: Average train loss: 0.0153\n",
      "Step 90: Average train loss: 0.0153\n",
      "Step 95: Average train loss: 0.0153\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 244038.109375\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 287812.15625\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 288650.34375\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 306827.09375\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 201934.328125\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0136\n",
      "Step 30: Average train loss: 0.0136\n",
      "Step 35: Average train loss: 0.0136\n",
      "Step 40: Average train loss: 0.0136\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 290399.71875\n",
      "Step 0: Average train loss: 0.0141\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0140\n",
      "Step 25: Average train loss: 0.0140\n",
      "Step 30: Average train loss: 0.0140\n",
      "Step 35: Average train loss: 0.0140\n",
      "Step 40: Average train loss: 0.0140\n",
      "Step 45: Average train loss: 0.0140\n",
      "Step 50: Average train loss: 0.0140\n",
      "Step 55: Average train loss: 0.0140\n",
      "Step 60: Average train loss: 0.0140\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0139\n",
      "Step 80: Average train loss: 0.0139\n",
      "Step 85: Average train loss: 0.0139\n",
      "Step 90: Average train loss: 0.0139\n",
      "Step 95: Average train loss: 0.0139\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 297489.59375\n",
      "Step 0: Average train loss: 0.0141\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 396815.375\n",
      "Step 0: Average train loss: 0.0152\n",
      "Step 5: Average train loss: 0.0152\n",
      "Step 10: Average train loss: 0.0152\n",
      "Step 15: Average train loss: 0.0152\n",
      "Step 20: Average train loss: 0.0151\n",
      "Step 25: Average train loss: 0.0151\n",
      "Step 30: Average train loss: 0.0151\n",
      "Step 35: Average train loss: 0.0151\n",
      "Step 40: Average train loss: 0.0151\n",
      "Step 45: Average train loss: 0.0151\n",
      "Step 50: Average train loss: 0.0151\n",
      "Step 55: Average train loss: 0.0151\n",
      "Step 60: Average train loss: 0.0151\n",
      "Step 65: Average train loss: 0.0151\n",
      "Step 70: Average train loss: 0.0151\n",
      "Step 75: Average train loss: 0.0151\n",
      "Step 80: Average train loss: 0.0151\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 414641.96875\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0161\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0161\n",
      "Step 30: Average train loss: 0.0161\n",
      "Step 35: Average train loss: 0.0161\n",
      "Step 40: Average train loss: 0.0161\n",
      "Step 45: Average train loss: 0.0161\n",
      "Step 50: Average train loss: 0.0161\n",
      "Step 55: Average train loss: 0.0161\n",
      "Step 60: Average train loss: 0.0161\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0160\n",
      "Step 90: Average train loss: 0.0160\n",
      "Step 95: Average train loss: 0.0160\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 389849.25\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0157\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0157\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0157\n",
      "Step 80: Average train loss: 0.0157\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 628029.9375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 6]) torch.Size([140, 24, 6]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0376 | Average test loss: 0.0253\n",
      "Step 5: Average train loss: 0.0303 | Average test loss: 0.0245\n",
      "Step 10: Average train loss: 0.0111 | Average test loss: 0.0100\n",
      "Step 15: Average train loss: 0.0095 | Average test loss: 0.0086\n",
      "Step 20: Average train loss: 0.0097 | Average test loss: 0.0084\n",
      "Step 25: Average train loss: 0.0094 | Average test loss: 0.0083\n",
      "Step 30: Average train loss: 0.0093 | Average test loss: 0.0081\n",
      "Step 35: Average train loss: 0.0092 | Average test loss: 0.0081\n",
      "Step 40: Average train loss: 0.0092 | Average test loss: 0.0080\n",
      "Step 45: Average train loss: 0.0091 | Average test loss: 0.0080\n",
      "Step 50: Average train loss: 0.0089 | Average test loss: 0.0080\n",
      "Step 55: Average train loss: 0.0088 | Average test loss: 0.0081\n",
      "Step 60: Average train loss: 0.0093 | Average test loss: 0.0091\n",
      "Step 65: Average train loss: 0.0114 | Average test loss: 0.0168\n",
      "Step 70: Average train loss: 0.0092 | Average test loss: 0.0082\n",
      "Step 75: Average train loss: 0.0095 | Average test loss: 0.0091\n",
      "Step 80: Average train loss: 0.0091 | Average test loss: 0.0082\n",
      "Step 85: Average train loss: 0.0097 | Average test loss: 0.0091\n",
      "Step 90: Average train loss: 0.0092 | Average test loss: 0.0085\n",
      "Step 95: Average train loss: 0.0095 | Average test loss: 0.0087\n",
      "Best Epoch: 46\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 74778.6328125\n",
      "Step 0: Average train loss: 0.0198\n",
      "Step 5: Average train loss: 0.0197\n",
      "Step 10: Average train loss: 0.0197\n",
      "Step 15: Average train loss: 0.0197\n",
      "Step 20: Average train loss: 0.0196\n",
      "Step 25: Average train loss: 0.0196\n",
      "Step 30: Average train loss: 0.0196\n",
      "Step 35: Average train loss: 0.0196\n",
      "Step 40: Average train loss: 0.0195\n",
      "Step 45: Average train loss: 0.0195\n",
      "Step 50: Average train loss: 0.0195\n",
      "Step 55: Average train loss: 0.0194\n",
      "Step 60: Average train loss: 0.0194\n",
      "Step 65: Average train loss: 0.0194\n",
      "Step 70: Average train loss: 0.0194\n",
      "Step 75: Average train loss: 0.0193\n",
      "Step 80: Average train loss: 0.0193\n",
      "Step 85: Average train loss: 0.0193\n",
      "Step 90: Average train loss: 0.0193\n",
      "Step 95: Average train loss: 0.0192\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 84285.65625\n",
      "Step 0: Average train loss: 0.0204\n",
      "Step 5: Average train loss: 0.0204\n",
      "Step 10: Average train loss: 0.0203\n",
      "Step 15: Average train loss: 0.0203\n",
      "Step 20: Average train loss: 0.0202\n",
      "Step 25: Average train loss: 0.0202\n",
      "Step 30: Average train loss: 0.0201\n",
      "Step 35: Average train loss: 0.0201\n",
      "Step 40: Average train loss: 0.0200\n",
      "Step 45: Average train loss: 0.0200\n",
      "Step 50: Average train loss: 0.0199\n",
      "Step 55: Average train loss: 0.0199\n",
      "Step 60: Average train loss: 0.0198\n",
      "Step 65: Average train loss: 0.0198\n",
      "Step 70: Average train loss: 0.0197\n",
      "Step 75: Average train loss: 0.0197\n",
      "Step 80: Average train loss: 0.0196\n",
      "Step 85: Average train loss: 0.0196\n",
      "Step 90: Average train loss: 0.0195\n",
      "Step 95: Average train loss: 0.0195\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 59954.01171875\n",
      "Step 0: Average train loss: 0.0184\n",
      "Step 5: Average train loss: 0.0184\n",
      "Step 10: Average train loss: 0.0183\n",
      "Step 15: Average train loss: 0.0183\n",
      "Step 20: Average train loss: 0.0182\n",
      "Step 25: Average train loss: 0.0182\n",
      "Step 30: Average train loss: 0.0181\n",
      "Step 35: Average train loss: 0.0181\n",
      "Step 40: Average train loss: 0.0180\n",
      "Step 45: Average train loss: 0.0180\n",
      "Step 50: Average train loss: 0.0180\n",
      "Step 55: Average train loss: 0.0179\n",
      "Step 60: Average train loss: 0.0179\n",
      "Step 65: Average train loss: 0.0178\n",
      "Step 70: Average train loss: 0.0178\n",
      "Step 75: Average train loss: 0.0177\n",
      "Step 80: Average train loss: 0.0177\n",
      "Step 85: Average train loss: 0.0177\n",
      "Step 90: Average train loss: 0.0176\n",
      "Step 95: Average train loss: 0.0176\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 51597.7109375\n",
      "Step 0: Average train loss: 0.0162\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0159\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0156\n",
      "Step 55: Average train loss: 0.0156\n",
      "Step 60: Average train loss: 0.0155\n",
      "Step 65: Average train loss: 0.0155\n",
      "Step 70: Average train loss: 0.0154\n",
      "Step 75: Average train loss: 0.0154\n",
      "Step 80: Average train loss: 0.0153\n",
      "Step 85: Average train loss: 0.0153\n",
      "Step 90: Average train loss: 0.0152\n",
      "Step 95: Average train loss: 0.0152\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 32845.98828125\n",
      "Step 0: Average train loss: 0.0129\n",
      "Step 5: Average train loss: 0.0129\n",
      "Step 10: Average train loss: 0.0128\n",
      "Step 15: Average train loss: 0.0128\n",
      "Step 20: Average train loss: 0.0127\n",
      "Step 25: Average train loss: 0.0127\n",
      "Step 30: Average train loss: 0.0126\n",
      "Step 35: Average train loss: 0.0126\n",
      "Step 40: Average train loss: 0.0125\n",
      "Step 45: Average train loss: 0.0125\n",
      "Step 50: Average train loss: 0.0124\n",
      "Step 55: Average train loss: 0.0124\n",
      "Step 60: Average train loss: 0.0123\n",
      "Step 65: Average train loss: 0.0123\n",
      "Step 70: Average train loss: 0.0122\n",
      "Step 75: Average train loss: 0.0122\n",
      "Step 80: Average train loss: 0.0121\n",
      "Step 85: Average train loss: 0.0121\n",
      "Step 90: Average train loss: 0.0120\n",
      "Step 95: Average train loss: 0.0120\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 29022.861328125\n",
      "Step 0: Average train loss: 0.0120\n",
      "Step 5: Average train loss: 0.0120\n",
      "Step 10: Average train loss: 0.0119\n",
      "Step 15: Average train loss: 0.0119\n",
      "Step 20: Average train loss: 0.0119\n",
      "Step 25: Average train loss: 0.0118\n",
      "Step 30: Average train loss: 0.0118\n",
      "Step 35: Average train loss: 0.0117\n",
      "Step 40: Average train loss: 0.0117\n",
      "Step 45: Average train loss: 0.0117\n",
      "Step 50: Average train loss: 0.0116\n",
      "Step 55: Average train loss: 0.0116\n",
      "Step 60: Average train loss: 0.0115\n",
      "Step 65: Average train loss: 0.0115\n",
      "Step 70: Average train loss: 0.0115\n",
      "Step 75: Average train loss: 0.0114\n",
      "Step 80: Average train loss: 0.0114\n",
      "Step 85: Average train loss: 0.0114\n",
      "Step 90: Average train loss: 0.0113\n",
      "Step 95: Average train loss: 0.0113\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 17421.53125\n",
      "Step 0: Average train loss: 0.0099\n",
      "Step 5: Average train loss: 0.0099\n",
      "Step 10: Average train loss: 0.0098\n",
      "Step 15: Average train loss: 0.0098\n",
      "Step 20: Average train loss: 0.0098\n",
      "Step 25: Average train loss: 0.0098\n",
      "Step 30: Average train loss: 0.0097\n",
      "Step 35: Average train loss: 0.0097\n",
      "Step 40: Average train loss: 0.0097\n",
      "Step 45: Average train loss: 0.0097\n",
      "Step 50: Average train loss: 0.0096\n",
      "Step 55: Average train loss: 0.0096\n",
      "Step 60: Average train loss: 0.0096\n",
      "Step 65: Average train loss: 0.0096\n",
      "Step 70: Average train loss: 0.0095\n",
      "Step 75: Average train loss: 0.0095\n",
      "Step 80: Average train loss: 0.0095\n",
      "Step 85: Average train loss: 0.0095\n",
      "Step 90: Average train loss: 0.0094\n",
      "Step 95: Average train loss: 0.0094\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 10573.5927734375\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0081\n",
      "Step 10: Average train loss: 0.0080\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0080\n",
      "Step 25: Average train loss: 0.0080\n",
      "Step 30: Average train loss: 0.0080\n",
      "Step 35: Average train loss: 0.0079\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 12707.326171875\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0077\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0075\n",
      "Step 85: Average train loss: 0.0075\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 21180.630859375\n",
      "Step 0: Average train loss: 0.0073\n",
      "Step 5: Average train loss: 0.0073\n",
      "Step 10: Average train loss: 0.0072\n",
      "Step 15: Average train loss: 0.0072\n",
      "Step 20: Average train loss: 0.0072\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0072\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 35223.64453125\n",
      "Step 0: Average train loss: 0.0073\n",
      "Step 5: Average train loss: 0.0073\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0073\n",
      "Step 20: Average train loss: 0.0073\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0072\n",
      "Step 40: Average train loss: 0.0072\n",
      "Step 45: Average train loss: 0.0072\n",
      "Step 50: Average train loss: 0.0072\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 31464.666015625\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', inv_limit=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('PoA')\n",
    "    features.remove('T_PV')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "\n",
    "    rmse.loc[(1, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PoA and T_PV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 6]) torch.Size([140, 24, 6]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0502 | Average test loss: 0.0360\n",
      "Step 5: Average train loss: 0.0167 | Average test loss: 0.0148\n",
      "Step 10: Average train loss: 0.0121 | Average test loss: 0.0105\n",
      "Step 15: Average train loss: 0.0112 | Average test loss: 0.0110\n",
      "Step 20: Average train loss: 0.0109 | Average test loss: 0.0111\n",
      "Step 25: Average train loss: 0.0106 | Average test loss: 0.0106\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0104\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0103\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0102\n",
      "Step 45: Average train loss: 0.0103 | Average test loss: 0.0100\n",
      "Step 50: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 55: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 60: Average train loss: 0.0099 | Average test loss: 0.0103\n",
      "Step 65: Average train loss: 0.0099 | Average test loss: 0.0094\n",
      "Step 70: Average train loss: 0.0097 | Average test loss: 0.0091\n",
      "Step 75: Average train loss: 0.0096 | Average test loss: 0.0085\n",
      "Step 80: Average train loss: 0.0097 | Average test loss: 0.0090\n",
      "Step 85: Average train loss: 0.0096 | Average test loss: 0.0091\n",
      "Step 90: Average train loss: 0.0096 | Average test loss: 0.0094\n",
      "Step 95: Average train loss: 0.0095 | Average test loss: 0.0091\n",
      "Best Epoch: 75\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 65121.46484375\n",
      "Step 0: Average train loss: 0.0104\n",
      "Step 5: Average train loss: 0.0104\n",
      "Step 10: Average train loss: 0.0104\n",
      "Step 15: Average train loss: 0.0104\n",
      "Step 20: Average train loss: 0.0104\n",
      "Step 25: Average train loss: 0.0103\n",
      "Step 30: Average train loss: 0.0103\n",
      "Step 35: Average train loss: 0.0103\n",
      "Step 40: Average train loss: 0.0103\n",
      "Step 45: Average train loss: 0.0103\n",
      "Step 50: Average train loss: 0.0103\n",
      "Step 55: Average train loss: 0.0103\n",
      "Step 60: Average train loss: 0.0102\n",
      "Step 65: Average train loss: 0.0102\n",
      "Step 70: Average train loss: 0.0102\n",
      "Step 75: Average train loss: 0.0102\n",
      "Step 80: Average train loss: 0.0102\n",
      "Step 85: Average train loss: 0.0102\n",
      "Step 90: Average train loss: 0.0102\n",
      "Step 95: Average train loss: 0.0101\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 60707.51171875\n",
      "Step 0: Average train loss: 0.0101\n",
      "Step 5: Average train loss: 0.0101\n",
      "Step 10: Average train loss: 0.0101\n",
      "Step 15: Average train loss: 0.0101\n",
      "Step 20: Average train loss: 0.0101\n",
      "Step 25: Average train loss: 0.0101\n",
      "Step 30: Average train loss: 0.0100\n",
      "Step 35: Average train loss: 0.0100\n",
      "Step 40: Average train loss: 0.0100\n",
      "Step 45: Average train loss: 0.0100\n",
      "Step 50: Average train loss: 0.0100\n",
      "Step 55: Average train loss: 0.0100\n",
      "Step 60: Average train loss: 0.0099\n",
      "Step 65: Average train loss: 0.0099\n",
      "Step 70: Average train loss: 0.0099\n",
      "Step 75: Average train loss: 0.0099\n",
      "Step 80: Average train loss: 0.0099\n",
      "Step 85: Average train loss: 0.0099\n",
      "Step 90: Average train loss: 0.0099\n",
      "Step 95: Average train loss: 0.0099\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 47778.41796875\n",
      "Step 0: Average train loss: 0.0089\n",
      "Step 5: Average train loss: 0.0089\n",
      "Step 10: Average train loss: 0.0089\n",
      "Step 15: Average train loss: 0.0089\n",
      "Step 20: Average train loss: 0.0089\n",
      "Step 25: Average train loss: 0.0089\n",
      "Step 30: Average train loss: 0.0089\n",
      "Step 35: Average train loss: 0.0089\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0088\n",
      "Step 50: Average train loss: 0.0088\n",
      "Step 55: Average train loss: 0.0088\n",
      "Step 60: Average train loss: 0.0088\n",
      "Step 65: Average train loss: 0.0088\n",
      "Step 70: Average train loss: 0.0088\n",
      "Step 75: Average train loss: 0.0088\n",
      "Step 80: Average train loss: 0.0087\n",
      "Step 85: Average train loss: 0.0087\n",
      "Step 90: Average train loss: 0.0087\n",
      "Step 95: Average train loss: 0.0087\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50219.8671875\n",
      "Step 0: Average train loss: 0.0084\n",
      "Step 5: Average train loss: 0.0084\n",
      "Step 10: Average train loss: 0.0084\n",
      "Step 15: Average train loss: 0.0084\n",
      "Step 20: Average train loss: 0.0084\n",
      "Step 25: Average train loss: 0.0084\n",
      "Step 30: Average train loss: 0.0084\n",
      "Step 35: Average train loss: 0.0084\n",
      "Step 40: Average train loss: 0.0083\n",
      "Step 45: Average train loss: 0.0083\n",
      "Step 50: Average train loss: 0.0083\n",
      "Step 55: Average train loss: 0.0083\n",
      "Step 60: Average train loss: 0.0083\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0083\n",
      "Step 80: Average train loss: 0.0083\n",
      "Step 85: Average train loss: 0.0083\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 46789.765625\n",
      "Step 0: Average train loss: 0.0076\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0076\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0075\n",
      "Step 80: Average train loss: 0.0075\n",
      "Step 85: Average train loss: 0.0075\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 41911.16015625\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 28038.72265625\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 12810.890625\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 16887.2578125\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 39564.09375\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 57004.9765625\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 57737.48828125\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 74691.0390625\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 6]) torch.Size([140, 24, 6]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0478 | Average test loss: 0.0266\n",
      "Step 5: Average train loss: 0.0201 | Average test loss: 0.0214\n",
      "Step 10: Average train loss: 0.0103 | Average test loss: 0.0082\n",
      "Step 15: Average train loss: 0.0088 | Average test loss: 0.0070\n",
      "Step 20: Average train loss: 0.0086 | Average test loss: 0.0071\n",
      "Step 25: Average train loss: 0.0086 | Average test loss: 0.0075\n",
      "Step 30: Average train loss: 0.0085 | Average test loss: 0.0073\n",
      "Step 35: Average train loss: 0.0084 | Average test loss: 0.0071\n",
      "Step 40: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 45: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 50: Average train loss: 0.0083 | Average test loss: 0.0070\n",
      "Step 55: Average train loss: 0.0083 | Average test loss: 0.0070\n",
      "Step 60: Average train loss: 0.0082 | Average test loss: 0.0069\n",
      "Step 65: Average train loss: 0.0082 | Average test loss: 0.0069\n",
      "Step 70: Average train loss: 0.0082 | Average test loss: 0.0067\n",
      "Step 75: Average train loss: 0.0081 | Average test loss: 0.0068\n",
      "Step 80: Average train loss: 0.0080 | Average test loss: 0.0064\n",
      "Step 85: Average train loss: 0.0082 | Average test loss: 0.0070\n",
      "Step 90: Average train loss: 0.0080 | Average test loss: 0.0065\n",
      "Step 95: Average train loss: 0.0078 | Average test loss: 0.0064\n",
      "Best Epoch: 81\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 49173.5390625\n",
      "Step 0: Average train loss: 0.0103\n",
      "Step 5: Average train loss: 0.0103\n",
      "Step 10: Average train loss: 0.0103\n",
      "Step 15: Average train loss: 0.0102\n",
      "Step 20: Average train loss: 0.0102\n",
      "Step 25: Average train loss: 0.0102\n",
      "Step 30: Average train loss: 0.0102\n",
      "Step 35: Average train loss: 0.0102\n",
      "Step 40: Average train loss: 0.0101\n",
      "Step 45: Average train loss: 0.0101\n",
      "Step 50: Average train loss: 0.0101\n",
      "Step 55: Average train loss: 0.0101\n",
      "Step 60: Average train loss: 0.0100\n",
      "Step 65: Average train loss: 0.0100\n",
      "Step 70: Average train loss: 0.0100\n",
      "Step 75: Average train loss: 0.0100\n",
      "Step 80: Average train loss: 0.0100\n",
      "Step 85: Average train loss: 0.0099\n",
      "Step 90: Average train loss: 0.0099\n",
      "Step 95: Average train loss: 0.0099\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 40701.0625\n",
      "Step 0: Average train loss: 0.0090\n",
      "Step 5: Average train loss: 0.0090\n",
      "Step 10: Average train loss: 0.0089\n",
      "Step 15: Average train loss: 0.0089\n",
      "Step 20: Average train loss: 0.0089\n",
      "Step 25: Average train loss: 0.0089\n",
      "Step 30: Average train loss: 0.0088\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0088\n",
      "Step 50: Average train loss: 0.0087\n",
      "Step 55: Average train loss: 0.0087\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0086\n",
      "Step 75: Average train loss: 0.0086\n",
      "Step 80: Average train loss: 0.0086\n",
      "Step 85: Average train loss: 0.0086\n",
      "Step 90: Average train loss: 0.0085\n",
      "Step 95: Average train loss: 0.0085\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 45484.8125\n",
      "Step 0: Average train loss: 0.0090\n",
      "Step 5: Average train loss: 0.0089\n",
      "Step 10: Average train loss: 0.0089\n",
      "Step 15: Average train loss: 0.0089\n",
      "Step 20: Average train loss: 0.0089\n",
      "Step 25: Average train loss: 0.0088\n",
      "Step 30: Average train loss: 0.0088\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0088\n",
      "Step 50: Average train loss: 0.0087\n",
      "Step 55: Average train loss: 0.0087\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0087\n",
      "Step 80: Average train loss: 0.0086\n",
      "Step 85: Average train loss: 0.0086\n",
      "Step 90: Average train loss: 0.0086\n",
      "Step 95: Average train loss: 0.0086\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 30598.328125\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 34212.140625\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0075\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0074\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 24337.439453125\n",
      "Step 0: Average train loss: 0.0072\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 13900.984375\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9998.7041015625\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0053\n",
      "Step 80: Average train loss: 0.0053\n",
      "Step 85: Average train loss: 0.0053\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 12317.9052734375\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 15190.595703125\n",
      "Step 0: Average train loss: 0.0052\n",
      "Step 5: Average train loss: 0.0052\n",
      "Step 10: Average train loss: 0.0052\n",
      "Step 15: Average train loss: 0.0052\n",
      "Step 20: Average train loss: 0.0052\n",
      "Step 25: Average train loss: 0.0052\n",
      "Step 30: Average train loss: 0.0052\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0052\n",
      "Step 55: Average train loss: 0.0052\n",
      "Step 60: Average train loss: 0.0052\n",
      "Step 65: Average train loss: 0.0052\n",
      "Step 70: Average train loss: 0.0051\n",
      "Step 75: Average train loss: 0.0051\n",
      "Step 80: Average train loss: 0.0051\n",
      "Step 85: Average train loss: 0.0051\n",
      "Step 90: Average train loss: 0.0051\n",
      "Step 95: Average train loss: 0.0051\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 43903.515625\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0063\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 37544.5390625\n",
      "Step 0: Average train loss: 0.0058\n",
      "Step 5: Average train loss: 0.0058\n",
      "Step 10: Average train loss: 0.0058\n",
      "Step 15: Average train loss: 0.0058\n",
      "Step 20: Average train loss: 0.0058\n",
      "Step 25: Average train loss: 0.0058\n",
      "Step 30: Average train loss: 0.0058\n",
      "Step 35: Average train loss: 0.0058\n",
      "Step 40: Average train loss: 0.0058\n",
      "Step 45: Average train loss: 0.0058\n",
      "Step 50: Average train loss: 0.0058\n",
      "Step 55: Average train loss: 0.0058\n",
      "Step 60: Average train loss: 0.0058\n",
      "Step 65: Average train loss: 0.0058\n",
      "Step 70: Average train loss: 0.0058\n",
      "Step 75: Average train loss: 0.0058\n",
      "Step 80: Average train loss: 0.0058\n",
      "Step 85: Average train loss: 0.0058\n",
      "Step 90: Average train loss: 0.0058\n",
      "Step 95: Average train loss: 0.0058\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 30423.712890625\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 6]) torch.Size([144, 24, 6]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0483 | Average test loss: 0.0271\n",
      "Step 5: Average train loss: 0.0063 | Average test loss: 0.0102\n",
      "Step 10: Average train loss: 0.0059 | Average test loss: 0.0031\n",
      "Step 15: Average train loss: 0.0058 | Average test loss: 0.0018\n",
      "Step 20: Average train loss: 0.0054 | Average test loss: 0.0019\n",
      "Step 25: Average train loss: 0.0052 | Average test loss: 0.0019\n",
      "Step 30: Average train loss: 0.0052 | Average test loss: 0.0020\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0020\n",
      "Step 40: Average train loss: 0.0051 | Average test loss: 0.0021\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0022\n",
      "Step 55: Average train loss: 0.0049 | Average test loss: 0.0019\n",
      "Step 60: Average train loss: 0.0049 | Average test loss: 0.0022\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0019\n",
      "Step 70: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 75: Average train loss: 0.0049 | Average test loss: 0.0019\n",
      "Step 80: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 85: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 90: Average train loss: 0.0049 | Average test loss: 0.0024\n",
      "Step 95: Average train loss: 0.0048 | Average test loss: 0.0020\n",
      "Best Epoch: 13\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 306571.125\n",
      "Step 0: Average train loss: 0.0162\n",
      "Step 5: Average train loss: 0.0162\n",
      "Step 10: Average train loss: 0.0162\n",
      "Step 15: Average train loss: 0.0162\n",
      "Step 20: Average train loss: 0.0162\n",
      "Step 25: Average train loss: 0.0162\n",
      "Step 30: Average train loss: 0.0162\n",
      "Step 35: Average train loss: 0.0162\n",
      "Step 40: Average train loss: 0.0162\n",
      "Step 45: Average train loss: 0.0162\n",
      "Step 50: Average train loss: 0.0162\n",
      "Step 55: Average train loss: 0.0161\n",
      "Step 60: Average train loss: 0.0161\n",
      "Step 65: Average train loss: 0.0161\n",
      "Step 70: Average train loss: 0.0161\n",
      "Step 75: Average train loss: 0.0161\n",
      "Step 80: Average train loss: 0.0161\n",
      "Step 85: Average train loss: 0.0161\n",
      "Step 90: Average train loss: 0.0161\n",
      "Step 95: Average train loss: 0.0161\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 300408.25\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0158\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0156\n",
      "Step 70: Average train loss: 0.0156\n",
      "Step 75: Average train loss: 0.0156\n",
      "Step 80: Average train loss: 0.0156\n",
      "Step 85: Average train loss: 0.0156\n",
      "Step 90: Average train loss: 0.0156\n",
      "Step 95: Average train loss: 0.0156\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 251054.671875\n",
      "Step 0: Average train loss: 0.0149\n",
      "Step 5: Average train loss: 0.0149\n",
      "Step 10: Average train loss: 0.0149\n",
      "Step 15: Average train loss: 0.0149\n",
      "Step 20: Average train loss: 0.0149\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0148\n",
      "Step 50: Average train loss: 0.0148\n",
      "Step 55: Average train loss: 0.0148\n",
      "Step 60: Average train loss: 0.0148\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0148\n",
      "Step 90: Average train loss: 0.0148\n",
      "Step 95: Average train loss: 0.0148\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 289657.5\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0150\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0149\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0149\n",
      "Step 50: Average train loss: 0.0149\n",
      "Step 55: Average train loss: 0.0149\n",
      "Step 60: Average train loss: 0.0148\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0148\n",
      "Step 90: Average train loss: 0.0148\n",
      "Step 95: Average train loss: 0.0148\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 286878.96875\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 303970.34375\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0148\n",
      "Step 25: Average train loss: 0.0148\n",
      "Step 30: Average train loss: 0.0148\n",
      "Step 35: Average train loss: 0.0148\n",
      "Step 40: Average train loss: 0.0148\n",
      "Step 45: Average train loss: 0.0148\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0147\n",
      "Step 75: Average train loss: 0.0147\n",
      "Step 80: Average train loss: 0.0147\n",
      "Step 85: Average train loss: 0.0147\n",
      "Step 90: Average train loss: 0.0147\n",
      "Step 95: Average train loss: 0.0147\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 204246.4375\n",
      "Step 0: Average train loss: 0.0138\n",
      "Step 5: Average train loss: 0.0138\n",
      "Step 10: Average train loss: 0.0138\n",
      "Step 15: Average train loss: 0.0138\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0137\n",
      "Step 35: Average train loss: 0.0137\n",
      "Step 40: Average train loss: 0.0137\n",
      "Step 45: Average train loss: 0.0137\n",
      "Step 50: Average train loss: 0.0137\n",
      "Step 55: Average train loss: 0.0137\n",
      "Step 60: Average train loss: 0.0137\n",
      "Step 65: Average train loss: 0.0137\n",
      "Step 70: Average train loss: 0.0137\n",
      "Step 75: Average train loss: 0.0137\n",
      "Step 80: Average train loss: 0.0137\n",
      "Step 85: Average train loss: 0.0137\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 293747.59375\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0140\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 302634.9375\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0142\n",
      "Step 35: Average train loss: 0.0142\n",
      "Step 40: Average train loss: 0.0142\n",
      "Step 45: Average train loss: 0.0142\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0141\n",
      "Step 85: Average train loss: 0.0141\n",
      "Step 90: Average train loss: 0.0141\n",
      "Step 95: Average train loss: 0.0141\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 399369.125\n",
      "Step 0: Average train loss: 0.0153\n",
      "Step 5: Average train loss: 0.0152\n",
      "Step 10: Average train loss: 0.0152\n",
      "Step 15: Average train loss: 0.0152\n",
      "Step 20: Average train loss: 0.0152\n",
      "Step 25: Average train loss: 0.0152\n",
      "Step 30: Average train loss: 0.0152\n",
      "Step 35: Average train loss: 0.0152\n",
      "Step 40: Average train loss: 0.0152\n",
      "Step 45: Average train loss: 0.0152\n",
      "Step 50: Average train loss: 0.0152\n",
      "Step 55: Average train loss: 0.0152\n",
      "Step 60: Average train loss: 0.0152\n",
      "Step 65: Average train loss: 0.0152\n",
      "Step 70: Average train loss: 0.0152\n",
      "Step 75: Average train loss: 0.0151\n",
      "Step 80: Average train loss: 0.0151\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 415529.0625\n",
      "Step 0: Average train loss: 0.0162\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0161\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0161\n",
      "Step 30: Average train loss: 0.0161\n",
      "Step 35: Average train loss: 0.0161\n",
      "Step 40: Average train loss: 0.0161\n",
      "Step 45: Average train loss: 0.0161\n",
      "Step 50: Average train loss: 0.0161\n",
      "Step 55: Average train loss: 0.0161\n",
      "Step 60: Average train loss: 0.0161\n",
      "Step 65: Average train loss: 0.0161\n",
      "Step 70: Average train loss: 0.0161\n",
      "Step 75: Average train loss: 0.0161\n",
      "Step 80: Average train loss: 0.0161\n",
      "Step 85: Average train loss: 0.0161\n",
      "Step 90: Average train loss: 0.0161\n",
      "Step 95: Average train loss: 0.0161\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 389066.65625\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0158\n",
      "Step 20: Average train loss: 0.0158\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0158\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0157\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0157\n",
      "Step 80: Average train loss: 0.0157\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 612766.3125\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 6]) torch.Size([140, 24, 6]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0427 | Average test loss: 0.0247\n",
      "Step 5: Average train loss: 0.0144 | Average test loss: 0.0120\n",
      "Step 10: Average train loss: 0.0118 | Average test loss: 0.0096\n",
      "Step 15: Average train loss: 0.0097 | Average test loss: 0.0087\n",
      "Step 20: Average train loss: 0.0095 | Average test loss: 0.0083\n",
      "Step 25: Average train loss: 0.0094 | Average test loss: 0.0082\n",
      "Step 30: Average train loss: 0.0093 | Average test loss: 0.0081\n",
      "Step 35: Average train loss: 0.0092 | Average test loss: 0.0081\n",
      "Step 40: Average train loss: 0.0091 | Average test loss: 0.0080\n",
      "Step 45: Average train loss: 0.0090 | Average test loss: 0.0080\n",
      "Step 50: Average train loss: 0.0089 | Average test loss: 0.0080\n",
      "Step 55: Average train loss: 0.0090 | Average test loss: 0.0086\n",
      "Step 60: Average train loss: 0.0098 | Average test loss: 0.0080\n",
      "Step 65: Average train loss: 0.0114 | Average test loss: 0.0107\n",
      "Step 70: Average train loss: 0.0091 | Average test loss: 0.0081\n",
      "Step 75: Average train loss: 0.0097 | Average test loss: 0.0090\n",
      "Step 80: Average train loss: 0.0090 | Average test loss: 0.0083\n",
      "Step 85: Average train loss: 0.0093 | Average test loss: 0.0085\n",
      "Step 90: Average train loss: 0.0094 | Average test loss: 0.0089\n",
      "Step 95: Average train loss: 0.0093 | Average test loss: 0.0087\n",
      "Best Epoch: 98\n",
      "Shape of data:  torch.Size([30, 24, 6]) torch.Size([30, 24, 6]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 59892.45703125\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0157\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0156\n",
      "Step 45: Average train loss: 0.0156\n",
      "Step 50: Average train loss: 0.0156\n",
      "Step 55: Average train loss: 0.0156\n",
      "Step 60: Average train loss: 0.0156\n",
      "Step 65: Average train loss: 0.0155\n",
      "Step 70: Average train loss: 0.0155\n",
      "Step 75: Average train loss: 0.0155\n",
      "Step 80: Average train loss: 0.0155\n",
      "Step 85: Average train loss: 0.0155\n",
      "Step 90: Average train loss: 0.0154\n",
      "Step 95: Average train loss: 0.0154\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 67705.421875\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0156\n",
      "Step 20: Average train loss: 0.0156\n",
      "Step 25: Average train loss: 0.0156\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0155\n",
      "Step 45: Average train loss: 0.0154\n",
      "Step 50: Average train loss: 0.0154\n",
      "Step 55: Average train loss: 0.0154\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0153\n",
      "Step 75: Average train loss: 0.0152\n",
      "Step 80: Average train loss: 0.0152\n",
      "Step 85: Average train loss: 0.0152\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 51186.62890625\n",
      "Step 0: Average train loss: 0.0151\n",
      "Step 5: Average train loss: 0.0151\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0150\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0148\n",
      "Step 50: Average train loss: 0.0148\n",
      "Step 55: Average train loss: 0.0148\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0147\n",
      "Step 75: Average train loss: 0.0147\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 42607.73828125\n",
      "Step 0: Average train loss: 0.0134\n",
      "Step 5: Average train loss: 0.0134\n",
      "Step 10: Average train loss: 0.0133\n",
      "Step 15: Average train loss: 0.0133\n",
      "Step 20: Average train loss: 0.0132\n",
      "Step 25: Average train loss: 0.0132\n",
      "Step 30: Average train loss: 0.0132\n",
      "Step 35: Average train loss: 0.0131\n",
      "Step 40: Average train loss: 0.0131\n",
      "Step 45: Average train loss: 0.0131\n",
      "Step 50: Average train loss: 0.0130\n",
      "Step 55: Average train loss: 0.0130\n",
      "Step 60: Average train loss: 0.0129\n",
      "Step 65: Average train loss: 0.0129\n",
      "Step 70: Average train loss: 0.0129\n",
      "Step 75: Average train loss: 0.0128\n",
      "Step 80: Average train loss: 0.0128\n",
      "Step 85: Average train loss: 0.0128\n",
      "Step 90: Average train loss: 0.0127\n",
      "Step 95: Average train loss: 0.0127\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 28556.330078125\n",
      "Step 0: Average train loss: 0.0110\n",
      "Step 5: Average train loss: 0.0109\n",
      "Step 10: Average train loss: 0.0109\n",
      "Step 15: Average train loss: 0.0109\n",
      "Step 20: Average train loss: 0.0108\n",
      "Step 25: Average train loss: 0.0108\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0107\n",
      "Step 40: Average train loss: 0.0107\n",
      "Step 45: Average train loss: 0.0106\n",
      "Step 50: Average train loss: 0.0106\n",
      "Step 55: Average train loss: 0.0106\n",
      "Step 60: Average train loss: 0.0105\n",
      "Step 65: Average train loss: 0.0105\n",
      "Step 70: Average train loss: 0.0105\n",
      "Step 75: Average train loss: 0.0104\n",
      "Step 80: Average train loss: 0.0104\n",
      "Step 85: Average train loss: 0.0104\n",
      "Step 90: Average train loss: 0.0104\n",
      "Step 95: Average train loss: 0.0103\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 29851.75\n",
      "Step 0: Average train loss: 0.0105\n",
      "Step 5: Average train loss: 0.0105\n",
      "Step 10: Average train loss: 0.0104\n",
      "Step 15: Average train loss: 0.0104\n",
      "Step 20: Average train loss: 0.0104\n",
      "Step 25: Average train loss: 0.0104\n",
      "Step 30: Average train loss: 0.0103\n",
      "Step 35: Average train loss: 0.0103\n",
      "Step 40: Average train loss: 0.0103\n",
      "Step 45: Average train loss: 0.0102\n",
      "Step 50: Average train loss: 0.0102\n",
      "Step 55: Average train loss: 0.0102\n",
      "Step 60: Average train loss: 0.0102\n",
      "Step 65: Average train loss: 0.0101\n",
      "Step 70: Average train loss: 0.0101\n",
      "Step 75: Average train loss: 0.0101\n",
      "Step 80: Average train loss: 0.0100\n",
      "Step 85: Average train loss: 0.0100\n",
      "Step 90: Average train loss: 0.0100\n",
      "Step 95: Average train loss: 0.0100\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 22370.19921875\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0089\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0089\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0088\n",
      "Step 80: Average train loss: 0.0088\n",
      "Step 85: Average train loss: 0.0088\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0088\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 13773.912109375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0077\n",
      "Step 10: Average train loss: 0.0077\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0076\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0075\n",
      "Step 50: Average train loss: 0.0075\n",
      "Step 55: Average train loss: 0.0075\n",
      "Step 60: Average train loss: 0.0075\n",
      "Step 65: Average train loss: 0.0075\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 15308.544921875\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0073\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0072\n",
      "Step 75: Average train loss: 0.0072\n",
      "Step 80: Average train loss: 0.0072\n",
      "Step 85: Average train loss: 0.0072\n",
      "Step 90: Average train loss: 0.0072\n",
      "Step 95: Average train loss: 0.0072\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 22455.482421875\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 33639.64453125\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 29930.21875\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp');\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('PoA')\n",
    "    features.remove('T_PV')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "\n",
    "    rmse.loc[(2, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 7]) torch.Size([140, 24, 7]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0582 | Average test loss: 0.0355\n",
      "Step 5: Average train loss: 0.0167 | Average test loss: 0.0139\n",
      "Step 10: Average train loss: 0.0135 | Average test loss: 0.0101\n",
      "Step 15: Average train loss: 0.0111 | Average test loss: 0.0105\n",
      "Step 20: Average train loss: 0.0108 | Average test loss: 0.0105\n",
      "Step 25: Average train loss: 0.0106 | Average test loss: 0.0105\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0103\n",
      "Step 35: Average train loss: 0.0104 | Average test loss: 0.0101\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0100\n",
      "Step 45: Average train loss: 0.0103 | Average test loss: 0.0099\n",
      "Step 50: Average train loss: 0.0102 | Average test loss: 0.0098\n",
      "Step 55: Average train loss: 0.0100 | Average test loss: 0.0095\n",
      "Step 60: Average train loss: 0.0098 | Average test loss: 0.0096\n",
      "Step 65: Average train loss: 0.0097 | Average test loss: 0.0092\n",
      "Step 70: Average train loss: 0.0095 | Average test loss: 0.0092\n",
      "Step 75: Average train loss: 0.0097 | Average test loss: 0.0093\n",
      "Step 80: Average train loss: 0.0094 | Average test loss: 0.0089\n",
      "Step 85: Average train loss: 0.0095 | Average test loss: 0.0091\n",
      "Step 90: Average train loss: 0.0093 | Average test loss: 0.0089\n",
      "Step 95: Average train loss: 0.0094 | Average test loss: 0.0091\n",
      "Best Epoch: 98\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 70489.6171875\n",
      "Step 0: Average train loss: 0.0113\n",
      "Step 5: Average train loss: 0.0113\n",
      "Step 10: Average train loss: 0.0112\n",
      "Step 15: Average train loss: 0.0112\n",
      "Step 20: Average train loss: 0.0112\n",
      "Step 25: Average train loss: 0.0112\n",
      "Step 30: Average train loss: 0.0112\n",
      "Step 35: Average train loss: 0.0111\n",
      "Step 40: Average train loss: 0.0111\n",
      "Step 45: Average train loss: 0.0111\n",
      "Step 50: Average train loss: 0.0111\n",
      "Step 55: Average train loss: 0.0111\n",
      "Step 60: Average train loss: 0.0111\n",
      "Step 65: Average train loss: 0.0110\n",
      "Step 70: Average train loss: 0.0110\n",
      "Step 75: Average train loss: 0.0110\n",
      "Step 80: Average train loss: 0.0110\n",
      "Step 85: Average train loss: 0.0110\n",
      "Step 90: Average train loss: 0.0110\n",
      "Step 95: Average train loss: 0.0109\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 61228.1015625\n",
      "Step 0: Average train loss: 0.0104\n",
      "Step 5: Average train loss: 0.0103\n",
      "Step 10: Average train loss: 0.0103\n",
      "Step 15: Average train loss: 0.0103\n",
      "Step 20: Average train loss: 0.0103\n",
      "Step 25: Average train loss: 0.0103\n",
      "Step 30: Average train loss: 0.0102\n",
      "Step 35: Average train loss: 0.0102\n",
      "Step 40: Average train loss: 0.0102\n",
      "Step 45: Average train loss: 0.0102\n",
      "Step 50: Average train loss: 0.0102\n",
      "Step 55: Average train loss: 0.0101\n",
      "Step 60: Average train loss: 0.0101\n",
      "Step 65: Average train loss: 0.0101\n",
      "Step 70: Average train loss: 0.0101\n",
      "Step 75: Average train loss: 0.0101\n",
      "Step 80: Average train loss: 0.0101\n",
      "Step 85: Average train loss: 0.0100\n",
      "Step 90: Average train loss: 0.0100\n",
      "Step 95: Average train loss: 0.0100\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 47653.08203125\n",
      "Step 0: Average train loss: 0.0092\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0091\n",
      "Step 30: Average train loss: 0.0091\n",
      "Step 35: Average train loss: 0.0091\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0090\n",
      "Step 70: Average train loss: 0.0090\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 52169.5234375\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0086\n",
      "Step 10: Average train loss: 0.0086\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0086\n",
      "Step 40: Average train loss: 0.0086\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0085\n",
      "Step 70: Average train loss: 0.0085\n",
      "Step 75: Average train loss: 0.0085\n",
      "Step 80: Average train loss: 0.0085\n",
      "Step 85: Average train loss: 0.0085\n",
      "Step 90: Average train loss: 0.0084\n",
      "Step 95: Average train loss: 0.0084\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 48340.33984375\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 41589.07421875\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0079\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0079\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0079\n",
      "Step 35: Average train loss: 0.0079\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0079\n",
      "Step 75: Average train loss: 0.0079\n",
      "Step 80: Average train loss: 0.0079\n",
      "Step 85: Average train loss: 0.0079\n",
      "Step 90: Average train loss: 0.0079\n",
      "Step 95: Average train loss: 0.0079\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 26886.84375\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 13400.15234375\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 17499.044921875\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 37548.1015625\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 57938.01171875\n",
      "Step 0: Average train loss: 0.0069\n",
      "Step 5: Average train loss: 0.0069\n",
      "Step 10: Average train loss: 0.0069\n",
      "Step 15: Average train loss: 0.0069\n",
      "Step 20: Average train loss: 0.0069\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 57415.37109375\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 83680.3046875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 7]) torch.Size([140, 24, 7]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0471 | Average test loss: 0.0253\n",
      "Step 5: Average train loss: 0.0106 | Average test loss: 0.0091\n",
      "Step 10: Average train loss: 0.0093 | Average test loss: 0.0081\n",
      "Step 15: Average train loss: 0.0089 | Average test loss: 0.0077\n",
      "Step 20: Average train loss: 0.0087 | Average test loss: 0.0080\n",
      "Step 25: Average train loss: 0.0087 | Average test loss: 0.0079\n",
      "Step 30: Average train loss: 0.0086 | Average test loss: 0.0074\n",
      "Step 35: Average train loss: 0.0084 | Average test loss: 0.0070\n",
      "Step 40: Average train loss: 0.0083 | Average test loss: 0.0067\n",
      "Step 45: Average train loss: 0.0082 | Average test loss: 0.0066\n",
      "Step 50: Average train loss: 0.0080 | Average test loss: 0.0068\n",
      "Step 55: Average train loss: 0.0080 | Average test loss: 0.0067\n",
      "Step 60: Average train loss: 0.0079 | Average test loss: 0.0064\n",
      "Step 65: Average train loss: 0.0079 | Average test loss: 0.0064\n",
      "Step 70: Average train loss: 0.0077 | Average test loss: 0.0064\n",
      "Step 75: Average train loss: 0.0076 | Average test loss: 0.0066\n",
      "Step 80: Average train loss: 0.0078 | Average test loss: 0.0066\n",
      "Step 85: Average train loss: 0.0076 | Average test loss: 0.0064\n",
      "Step 90: Average train loss: 0.0075 | Average test loss: 0.0066\n",
      "Step 95: Average train loss: 0.0075 | Average test loss: 0.0064\n",
      "Best Epoch: 74\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 52402.47265625\n",
      "Step 0: Average train loss: 0.0110\n",
      "Step 5: Average train loss: 0.0110\n",
      "Step 10: Average train loss: 0.0109\n",
      "Step 15: Average train loss: 0.0109\n",
      "Step 20: Average train loss: 0.0109\n",
      "Step 25: Average train loss: 0.0109\n",
      "Step 30: Average train loss: 0.0109\n",
      "Step 35: Average train loss: 0.0108\n",
      "Step 40: Average train loss: 0.0108\n",
      "Step 45: Average train loss: 0.0108\n",
      "Step 50: Average train loss: 0.0108\n",
      "Step 55: Average train loss: 0.0107\n",
      "Step 60: Average train loss: 0.0107\n",
      "Step 65: Average train loss: 0.0107\n",
      "Step 70: Average train loss: 0.0107\n",
      "Step 75: Average train loss: 0.0107\n",
      "Step 80: Average train loss: 0.0106\n",
      "Step 85: Average train loss: 0.0106\n",
      "Step 90: Average train loss: 0.0106\n",
      "Step 95: Average train loss: 0.0106\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 41836.0234375\n",
      "Step 0: Average train loss: 0.0094\n",
      "Step 5: Average train loss: 0.0094\n",
      "Step 10: Average train loss: 0.0094\n",
      "Step 15: Average train loss: 0.0093\n",
      "Step 20: Average train loss: 0.0093\n",
      "Step 25: Average train loss: 0.0093\n",
      "Step 30: Average train loss: 0.0093\n",
      "Step 35: Average train loss: 0.0092\n",
      "Step 40: Average train loss: 0.0092\n",
      "Step 45: Average train loss: 0.0092\n",
      "Step 50: Average train loss: 0.0092\n",
      "Step 55: Average train loss: 0.0091\n",
      "Step 60: Average train loss: 0.0091\n",
      "Step 65: Average train loss: 0.0091\n",
      "Step 70: Average train loss: 0.0091\n",
      "Step 75: Average train loss: 0.0090\n",
      "Step 80: Average train loss: 0.0090\n",
      "Step 85: Average train loss: 0.0090\n",
      "Step 90: Average train loss: 0.0090\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 48874.79296875\n",
      "Step 0: Average train loss: 0.0095\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0095\n",
      "Step 15: Average train loss: 0.0094\n",
      "Step 20: Average train loss: 0.0094\n",
      "Step 25: Average train loss: 0.0094\n",
      "Step 30: Average train loss: 0.0094\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0093\n",
      "Step 45: Average train loss: 0.0093\n",
      "Step 50: Average train loss: 0.0093\n",
      "Step 55: Average train loss: 0.0093\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0092\n",
      "Step 75: Average train loss: 0.0092\n",
      "Step 80: Average train loss: 0.0092\n",
      "Step 85: Average train loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092\n",
      "Step 95: Average train loss: 0.0091\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 32717.755859375\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0083\n",
      "Step 20: Average train loss: 0.0083\n",
      "Step 25: Average train loss: 0.0083\n",
      "Step 30: Average train loss: 0.0082\n",
      "Step 35: Average train loss: 0.0082\n",
      "Step 40: Average train loss: 0.0082\n",
      "Step 45: Average train loss: 0.0082\n",
      "Step 50: Average train loss: 0.0082\n",
      "Step 55: Average train loss: 0.0082\n",
      "Step 60: Average train loss: 0.0082\n",
      "Step 65: Average train loss: 0.0082\n",
      "Step 70: Average train loss: 0.0081\n",
      "Step 75: Average train loss: 0.0081\n",
      "Step 80: Average train loss: 0.0081\n",
      "Step 85: Average train loss: 0.0081\n",
      "Step 90: Average train loss: 0.0081\n",
      "Step 95: Average train loss: 0.0081\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 36975.94921875\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0079\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23023.990234375\n",
      "Step 0: Average train loss: 0.0074\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0073\n",
      "Step 20: Average train loss: 0.0073\n",
      "Step 25: Average train loss: 0.0073\n",
      "Step 30: Average train loss: 0.0073\n",
      "Step 35: Average train loss: 0.0073\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 12684.0400390625\n",
      "Step 0: Average train loss: 0.0063\n",
      "Step 5: Average train loss: 0.0063\n",
      "Step 10: Average train loss: 0.0063\n",
      "Step 15: Average train loss: 0.0063\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0063\n",
      "Step 55: Average train loss: 0.0063\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 10263.8603515625\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 12477.671875\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 16684.40234375\n",
      "Step 0: Average train loss: 0.0053\n",
      "Step 5: Average train loss: 0.0053\n",
      "Step 10: Average train loss: 0.0053\n",
      "Step 15: Average train loss: 0.0053\n",
      "Step 20: Average train loss: 0.0053\n",
      "Step 25: Average train loss: 0.0053\n",
      "Step 30: Average train loss: 0.0053\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0052\n",
      "Step 55: Average train loss: 0.0052\n",
      "Step 60: Average train loss: 0.0052\n",
      "Step 65: Average train loss: 0.0052\n",
      "Step 70: Average train loss: 0.0052\n",
      "Step 75: Average train loss: 0.0052\n",
      "Step 80: Average train loss: 0.0052\n",
      "Step 85: Average train loss: 0.0052\n",
      "Step 90: Average train loss: 0.0052\n",
      "Step 95: Average train loss: 0.0052\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 44879.12890625\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 37429.54296875\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 34441.1875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 7]) torch.Size([144, 24, 7]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0426 | Average test loss: 0.0314\n",
      "Step 5: Average train loss: 0.0079 | Average test loss: 0.0034\n",
      "Step 10: Average train loss: 0.0063 | Average test loss: 0.0018\n",
      "Step 15: Average train loss: 0.0056 | Average test loss: 0.0017\n",
      "Step 20: Average train loss: 0.0054 | Average test loss: 0.0017\n",
      "Step 25: Average train loss: 0.0053 | Average test loss: 0.0017\n",
      "Step 30: Average train loss: 0.0052 | Average test loss: 0.0018\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0019\n",
      "Step 40: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 50: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 55: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 60: Average train loss: 0.0049 | Average test loss: 0.0022\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 70: Average train loss: 0.0048 | Average test loss: 0.0023\n",
      "Step 75: Average train loss: 0.0048 | Average test loss: 0.0021\n",
      "Step 80: Average train loss: 0.0048 | Average test loss: 0.0025\n",
      "Step 85: Average train loss: 0.0047 | Average test loss: 0.0022\n",
      "Step 90: Average train loss: 0.0047 | Average test loss: 0.0026\n",
      "Step 95: Average train loss: 0.0047 | Average test loss: 0.0023\n",
      "Best Epoch: 15\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 304230.96875\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0161\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0161\n",
      "Step 30: Average train loss: 0.0161\n",
      "Step 35: Average train loss: 0.0160\n",
      "Step 40: Average train loss: 0.0160\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0160\n",
      "Step 90: Average train loss: 0.0160\n",
      "Step 95: Average train loss: 0.0160\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 300503.875\n",
      "Step 0: Average train loss: 0.0159\n",
      "Step 5: Average train loss: 0.0159\n",
      "Step 10: Average train loss: 0.0159\n",
      "Step 15: Average train loss: 0.0159\n",
      "Step 20: Average train loss: 0.0159\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0158\n",
      "Step 45: Average train loss: 0.0158\n",
      "Step 50: Average train loss: 0.0158\n",
      "Step 55: Average train loss: 0.0158\n",
      "Step 60: Average train loss: 0.0158\n",
      "Step 65: Average train loss: 0.0158\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0157\n",
      "Step 80: Average train loss: 0.0157\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 260581.46875\n",
      "Step 0: Average train loss: 0.0151\n",
      "Step 5: Average train loss: 0.0151\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0150\n",
      "Step 25: Average train loss: 0.0150\n",
      "Step 30: Average train loss: 0.0150\n",
      "Step 35: Average train loss: 0.0150\n",
      "Step 40: Average train loss: 0.0150\n",
      "Step 45: Average train loss: 0.0150\n",
      "Step 50: Average train loss: 0.0150\n",
      "Step 55: Average train loss: 0.0149\n",
      "Step 60: Average train loss: 0.0149\n",
      "Step 65: Average train loss: 0.0149\n",
      "Step 70: Average train loss: 0.0149\n",
      "Step 75: Average train loss: 0.0149\n",
      "Step 80: Average train loss: 0.0149\n",
      "Step 85: Average train loss: 0.0149\n",
      "Step 90: Average train loss: 0.0149\n",
      "Step 95: Average train loss: 0.0149\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 287579.1875\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0150\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0150\n",
      "Step 20: Average train loss: 0.0150\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0149\n",
      "Step 50: Average train loss: 0.0149\n",
      "Step 55: Average train loss: 0.0149\n",
      "Step 60: Average train loss: 0.0149\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0148\n",
      "Step 90: Average train loss: 0.0148\n",
      "Step 95: Average train loss: 0.0148\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 285062.6875\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 300325.0625\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0148\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0147\n",
      "Step 75: Average train loss: 0.0147\n",
      "Step 80: Average train loss: 0.0147\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 200287.890625\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0137\n",
      "Step 35: Average train loss: 0.0137\n",
      "Step 40: Average train loss: 0.0136\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 291307.28125\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 298809.03125\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 403849.6875\n",
      "Step 0: Average train loss: 0.0152\n",
      "Step 5: Average train loss: 0.0152\n",
      "Step 10: Average train loss: 0.0152\n",
      "Step 15: Average train loss: 0.0152\n",
      "Step 20: Average train loss: 0.0152\n",
      "Step 25: Average train loss: 0.0152\n",
      "Step 30: Average train loss: 0.0152\n",
      "Step 35: Average train loss: 0.0152\n",
      "Step 40: Average train loss: 0.0152\n",
      "Step 45: Average train loss: 0.0152\n",
      "Step 50: Average train loss: 0.0152\n",
      "Step 55: Average train loss: 0.0151\n",
      "Step 60: Average train loss: 0.0151\n",
      "Step 65: Average train loss: 0.0151\n",
      "Step 70: Average train loss: 0.0151\n",
      "Step 75: Average train loss: 0.0151\n",
      "Step 80: Average train loss: 0.0151\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 418352.3125\n",
      "Step 0: Average train loss: 0.0162\n",
      "Step 5: Average train loss: 0.0162\n",
      "Step 10: Average train loss: 0.0162\n",
      "Step 15: Average train loss: 0.0162\n",
      "Step 20: Average train loss: 0.0162\n",
      "Step 25: Average train loss: 0.0162\n",
      "Step 30: Average train loss: 0.0162\n",
      "Step 35: Average train loss: 0.0162\n",
      "Step 40: Average train loss: 0.0162\n",
      "Step 45: Average train loss: 0.0162\n",
      "Step 50: Average train loss: 0.0162\n",
      "Step 55: Average train loss: 0.0161\n",
      "Step 60: Average train loss: 0.0161\n",
      "Step 65: Average train loss: 0.0161\n",
      "Step 70: Average train loss: 0.0161\n",
      "Step 75: Average train loss: 0.0161\n",
      "Step 80: Average train loss: 0.0161\n",
      "Step 85: Average train loss: 0.0161\n",
      "Step 90: Average train loss: 0.0161\n",
      "Step 95: Average train loss: 0.0161\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 383605.0625\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0157\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0157\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0157\n",
      "Step 80: Average train loss: 0.0157\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 554841.4375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 7]) torch.Size([140, 24, 7]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0414 | Average test loss: 0.0250\n",
      "Step 5: Average train loss: 0.0181 | Average test loss: 0.0210\n",
      "Step 10: Average train loss: 0.0103 | Average test loss: 0.0095\n",
      "Step 15: Average train loss: 0.0103 | Average test loss: 0.0091\n",
      "Step 20: Average train loss: 0.0099 | Average test loss: 0.0087\n",
      "Step 25: Average train loss: 0.0096 | Average test loss: 0.0085\n",
      "Step 30: Average train loss: 0.0094 | Average test loss: 0.0082\n",
      "Step 35: Average train loss: 0.0093 | Average test loss: 0.0082\n",
      "Step 40: Average train loss: 0.0092 | Average test loss: 0.0081\n",
      "Step 45: Average train loss: 0.0091 | Average test loss: 0.0082\n",
      "Step 50: Average train loss: 0.0091 | Average test loss: 0.0080\n",
      "Step 55: Average train loss: 0.0089 | Average test loss: 0.0077\n",
      "Step 60: Average train loss: 0.0089 | Average test loss: 0.0079\n",
      "Step 65: Average train loss: 0.0088 | Average test loss: 0.0079\n",
      "Step 70: Average train loss: 0.0087 | Average test loss: 0.0080\n",
      "Step 75: Average train loss: 0.0106 | Average test loss: 0.0083\n",
      "Step 80: Average train loss: 0.0087 | Average test loss: 0.0075\n",
      "Step 85: Average train loss: 0.0086 | Average test loss: 0.0079\n",
      "Step 90: Average train loss: 0.0085 | Average test loss: 0.0078\n",
      "Step 95: Average train loss: 0.0084 | Average test loss: 0.0075\n",
      "Best Epoch: 96\n",
      "Shape of data:  torch.Size([30, 24, 7]) torch.Size([30, 24, 7]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 74612.375\n",
      "Step 0: Average train loss: 0.0197\n",
      "Step 5: Average train loss: 0.0197\n",
      "Step 10: Average train loss: 0.0197\n",
      "Step 15: Average train loss: 0.0197\n",
      "Step 20: Average train loss: 0.0196\n",
      "Step 25: Average train loss: 0.0196\n",
      "Step 30: Average train loss: 0.0196\n",
      "Step 35: Average train loss: 0.0195\n",
      "Step 40: Average train loss: 0.0195\n",
      "Step 45: Average train loss: 0.0195\n",
      "Step 50: Average train loss: 0.0195\n",
      "Step 55: Average train loss: 0.0194\n",
      "Step 60: Average train loss: 0.0194\n",
      "Step 65: Average train loss: 0.0194\n",
      "Step 70: Average train loss: 0.0194\n",
      "Step 75: Average train loss: 0.0193\n",
      "Step 80: Average train loss: 0.0193\n",
      "Step 85: Average train loss: 0.0193\n",
      "Step 90: Average train loss: 0.0193\n",
      "Step 95: Average train loss: 0.0192\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 78917.015625\n",
      "Step 0: Average train loss: 0.0193\n",
      "Step 5: Average train loss: 0.0193\n",
      "Step 10: Average train loss: 0.0193\n",
      "Step 15: Average train loss: 0.0192\n",
      "Step 20: Average train loss: 0.0192\n",
      "Step 25: Average train loss: 0.0191\n",
      "Step 30: Average train loss: 0.0191\n",
      "Step 35: Average train loss: 0.0190\n",
      "Step 40: Average train loss: 0.0190\n",
      "Step 45: Average train loss: 0.0189\n",
      "Step 50: Average train loss: 0.0189\n",
      "Step 55: Average train loss: 0.0189\n",
      "Step 60: Average train loss: 0.0188\n",
      "Step 65: Average train loss: 0.0188\n",
      "Step 70: Average train loss: 0.0187\n",
      "Step 75: Average train loss: 0.0187\n",
      "Step 80: Average train loss: 0.0186\n",
      "Step 85: Average train loss: 0.0186\n",
      "Step 90: Average train loss: 0.0185\n",
      "Step 95: Average train loss: 0.0185\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 62275.56640625\n",
      "Step 0: Average train loss: 0.0182\n",
      "Step 5: Average train loss: 0.0182\n",
      "Step 10: Average train loss: 0.0181\n",
      "Step 15: Average train loss: 0.0181\n",
      "Step 20: Average train loss: 0.0181\n",
      "Step 25: Average train loss: 0.0180\n",
      "Step 30: Average train loss: 0.0180\n",
      "Step 35: Average train loss: 0.0179\n",
      "Step 40: Average train loss: 0.0179\n",
      "Step 45: Average train loss: 0.0179\n",
      "Step 50: Average train loss: 0.0178\n",
      "Step 55: Average train loss: 0.0178\n",
      "Step 60: Average train loss: 0.0177\n",
      "Step 65: Average train loss: 0.0177\n",
      "Step 70: Average train loss: 0.0176\n",
      "Step 75: Average train loss: 0.0176\n",
      "Step 80: Average train loss: 0.0176\n",
      "Step 85: Average train loss: 0.0175\n",
      "Step 90: Average train loss: 0.0175\n",
      "Step 95: Average train loss: 0.0175\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 51255.41015625\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0160\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0159\n",
      "Step 20: Average train loss: 0.0159\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0156\n",
      "Step 50: Average train loss: 0.0156\n",
      "Step 55: Average train loss: 0.0155\n",
      "Step 60: Average train loss: 0.0155\n",
      "Step 65: Average train loss: 0.0154\n",
      "Step 70: Average train loss: 0.0154\n",
      "Step 75: Average train loss: 0.0153\n",
      "Step 80: Average train loss: 0.0153\n",
      "Step 85: Average train loss: 0.0152\n",
      "Step 90: Average train loss: 0.0152\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 31043.705078125\n",
      "Step 0: Average train loss: 0.0127\n",
      "Step 5: Average train loss: 0.0126\n",
      "Step 10: Average train loss: 0.0126\n",
      "Step 15: Average train loss: 0.0125\n",
      "Step 20: Average train loss: 0.0125\n",
      "Step 25: Average train loss: 0.0124\n",
      "Step 30: Average train loss: 0.0124\n",
      "Step 35: Average train loss: 0.0124\n",
      "Step 40: Average train loss: 0.0123\n",
      "Step 45: Average train loss: 0.0123\n",
      "Step 50: Average train loss: 0.0122\n",
      "Step 55: Average train loss: 0.0122\n",
      "Step 60: Average train loss: 0.0121\n",
      "Step 65: Average train loss: 0.0121\n",
      "Step 70: Average train loss: 0.0120\n",
      "Step 75: Average train loss: 0.0120\n",
      "Step 80: Average train loss: 0.0119\n",
      "Step 85: Average train loss: 0.0119\n",
      "Step 90: Average train loss: 0.0118\n",
      "Step 95: Average train loss: 0.0118\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 29497.03125\n",
      "Step 0: Average train loss: 0.0120\n",
      "Step 5: Average train loss: 0.0119\n",
      "Step 10: Average train loss: 0.0119\n",
      "Step 15: Average train loss: 0.0118\n",
      "Step 20: Average train loss: 0.0118\n",
      "Step 25: Average train loss: 0.0118\n",
      "Step 30: Average train loss: 0.0117\n",
      "Step 35: Average train loss: 0.0117\n",
      "Step 40: Average train loss: 0.0116\n",
      "Step 45: Average train loss: 0.0116\n",
      "Step 50: Average train loss: 0.0116\n",
      "Step 55: Average train loss: 0.0115\n",
      "Step 60: Average train loss: 0.0115\n",
      "Step 65: Average train loss: 0.0115\n",
      "Step 70: Average train loss: 0.0114\n",
      "Step 75: Average train loss: 0.0114\n",
      "Step 80: Average train loss: 0.0113\n",
      "Step 85: Average train loss: 0.0113\n",
      "Step 90: Average train loss: 0.0113\n",
      "Step 95: Average train loss: 0.0112\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 20493.267578125\n",
      "Step 0: Average train loss: 0.0100\n",
      "Step 5: Average train loss: 0.0100\n",
      "Step 10: Average train loss: 0.0100\n",
      "Step 15: Average train loss: 0.0099\n",
      "Step 20: Average train loss: 0.0099\n",
      "Step 25: Average train loss: 0.0099\n",
      "Step 30: Average train loss: 0.0099\n",
      "Step 35: Average train loss: 0.0098\n",
      "Step 40: Average train loss: 0.0098\n",
      "Step 45: Average train loss: 0.0098\n",
      "Step 50: Average train loss: 0.0097\n",
      "Step 55: Average train loss: 0.0097\n",
      "Step 60: Average train loss: 0.0097\n",
      "Step 65: Average train loss: 0.0097\n",
      "Step 70: Average train loss: 0.0096\n",
      "Step 75: Average train loss: 0.0096\n",
      "Step 80: Average train loss: 0.0096\n",
      "Step 85: Average train loss: 0.0096\n",
      "Step 90: Average train loss: 0.0095\n",
      "Step 95: Average train loss: 0.0095\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 12430.9765625\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0082\n",
      "Step 10: Average train loss: 0.0082\n",
      "Step 15: Average train loss: 0.0082\n",
      "Step 20: Average train loss: 0.0082\n",
      "Step 25: Average train loss: 0.0081\n",
      "Step 30: Average train loss: 0.0081\n",
      "Step 35: Average train loss: 0.0081\n",
      "Step 40: Average train loss: 0.0081\n",
      "Step 45: Average train loss: 0.0080\n",
      "Step 50: Average train loss: 0.0080\n",
      "Step 55: Average train loss: 0.0080\n",
      "Step 60: Average train loss: 0.0080\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0079\n",
      "Step 75: Average train loss: 0.0079\n",
      "Step 80: Average train loss: 0.0079\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 13680.546875\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0075\n",
      "Step 80: Average train loss: 0.0075\n",
      "Step 85: Average train loss: 0.0075\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 20730.59375\n",
      "Step 0: Average train loss: 0.0072\n",
      "Step 5: Average train loss: 0.0072\n",
      "Step 10: Average train loss: 0.0072\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0070\n",
      "Step 40: Average train loss: 0.0070\n",
      "Step 45: Average train loss: 0.0070\n",
      "Step 50: Average train loss: 0.0070\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0069\n",
      "Step 75: Average train loss: 0.0069\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 31799.6796875\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0069\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 30275.88671875\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', inv_limit=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('is_day')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "    rmse.loc[(3, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverter Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 8]) torch.Size([140, 24, 8]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0525 | Average test loss: 0.0359\n",
      "Step 5: Average train loss: 0.0145 | Average test loss: 0.0132\n",
      "Step 10: Average train loss: 0.0127 | Average test loss: 0.0122\n",
      "Step 15: Average train loss: 0.0112 | Average test loss: 0.0106\n",
      "Step 20: Average train loss: 0.0109 | Average test loss: 0.0108\n",
      "Step 25: Average train loss: 0.0107 | Average test loss: 0.0107\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0103\n",
      "Step 35: Average train loss: 0.0103 | Average test loss: 0.0101\n",
      "Step 40: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 45: Average train loss: 0.0102 | Average test loss: 0.0098\n",
      "Step 50: Average train loss: 0.0100 | Average test loss: 0.0095\n",
      "Step 55: Average train loss: 0.0098 | Average test loss: 0.0095\n",
      "Step 60: Average train loss: 0.0096 | Average test loss: 0.0089\n",
      "Step 65: Average train loss: 0.0096 | Average test loss: 0.0093\n",
      "Step 70: Average train loss: 0.0095 | Average test loss: 0.0090\n",
      "Step 75: Average train loss: 0.0094 | Average test loss: 0.0088\n",
      "Step 80: Average train loss: 0.0093 | Average test loss: 0.0090\n",
      "Step 85: Average train loss: 0.0093 | Average test loss: 0.0088\n",
      "Step 90: Average train loss: 0.0093 | Average test loss: 0.0088\n",
      "Step 95: Average train loss: 0.0092 | Average test loss: 0.0087\n",
      "Best Epoch: 95\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 70861.4609375\n",
      "Step 0: Average train loss: 0.0114\n",
      "Step 5: Average train loss: 0.0113\n",
      "Step 10: Average train loss: 0.0113\n",
      "Step 15: Average train loss: 0.0113\n",
      "Step 20: Average train loss: 0.0113\n",
      "Step 25: Average train loss: 0.0113\n",
      "Step 30: Average train loss: 0.0112\n",
      "Step 35: Average train loss: 0.0112\n",
      "Step 40: Average train loss: 0.0112\n",
      "Step 45: Average train loss: 0.0112\n",
      "Step 50: Average train loss: 0.0112\n",
      "Step 55: Average train loss: 0.0111\n",
      "Step 60: Average train loss: 0.0111\n",
      "Step 65: Average train loss: 0.0111\n",
      "Step 70: Average train loss: 0.0111\n",
      "Step 75: Average train loss: 0.0111\n",
      "Step 80: Average train loss: 0.0111\n",
      "Step 85: Average train loss: 0.0110\n",
      "Step 90: Average train loss: 0.0110\n",
      "Step 95: Average train loss: 0.0110\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 61197.14453125\n",
      "Step 0: Average train loss: 0.0104\n",
      "Step 5: Average train loss: 0.0104\n",
      "Step 10: Average train loss: 0.0104\n",
      "Step 15: Average train loss: 0.0104\n",
      "Step 20: Average train loss: 0.0103\n",
      "Step 25: Average train loss: 0.0103\n",
      "Step 30: Average train loss: 0.0103\n",
      "Step 35: Average train loss: 0.0103\n",
      "Step 40: Average train loss: 0.0103\n",
      "Step 45: Average train loss: 0.0102\n",
      "Step 50: Average train loss: 0.0102\n",
      "Step 55: Average train loss: 0.0102\n",
      "Step 60: Average train loss: 0.0102\n",
      "Step 65: Average train loss: 0.0102\n",
      "Step 70: Average train loss: 0.0102\n",
      "Step 75: Average train loss: 0.0101\n",
      "Step 80: Average train loss: 0.0101\n",
      "Step 85: Average train loss: 0.0101\n",
      "Step 90: Average train loss: 0.0101\n",
      "Step 95: Average train loss: 0.0101\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 46687.69921875\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0091\n",
      "Step 30: Average train loss: 0.0091\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0090\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 51618.31640625\n",
      "Step 0: Average train loss: 0.0086\n",
      "Step 5: Average train loss: 0.0086\n",
      "Step 10: Average train loss: 0.0086\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0085\n",
      "Step 40: Average train loss: 0.0085\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0085\n",
      "Step 70: Average train loss: 0.0085\n",
      "Step 75: Average train loss: 0.0085\n",
      "Step 80: Average train loss: 0.0084\n",
      "Step 85: Average train loss: 0.0084\n",
      "Step 90: Average train loss: 0.0084\n",
      "Step 95: Average train loss: 0.0084\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 47449.8125\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 40250.5234375\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 27140.666015625\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0070\n",
      "Step 35: Average train loss: 0.0070\n",
      "Step 40: Average train loss: 0.0070\n",
      "Step 45: Average train loss: 0.0070\n",
      "Step 50: Average train loss: 0.0070\n",
      "Step 55: Average train loss: 0.0070\n",
      "Step 60: Average train loss: 0.0070\n",
      "Step 65: Average train loss: 0.0070\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 10654.9326171875\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 15804.45703125\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 38232.8359375\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 56446.64453125\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 56848.921875\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0065\n",
      "Step 60: Average train loss: 0.0065\n",
      "Step 65: Average train loss: 0.0065\n",
      "Step 70: Average train loss: 0.0065\n",
      "Step 75: Average train loss: 0.0065\n",
      "Step 80: Average train loss: 0.0065\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 84908.7890625\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 8]) torch.Size([140, 24, 8]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0404 | Average test loss: 0.0263\n",
      "Step 5: Average train loss: 0.0145 | Average test loss: 0.0109\n",
      "Step 10: Average train loss: 0.0091 | Average test loss: 0.0071\n",
      "Step 15: Average train loss: 0.0095 | Average test loss: 0.0075\n",
      "Step 20: Average train loss: 0.0092 | Average test loss: 0.0070\n",
      "Step 25: Average train loss: 0.0091 | Average test loss: 0.0070\n",
      "Step 30: Average train loss: 0.0090 | Average test loss: 0.0070\n",
      "Step 35: Average train loss: 0.0089 | Average test loss: 0.0070\n",
      "Step 40: Average train loss: 0.0084 | Average test loss: 0.0064\n",
      "Step 45: Average train loss: 0.0094 | Average test loss: 0.0075\n",
      "Step 50: Average train loss: 0.0084 | Average test loss: 0.0064\n",
      "Step 55: Average train loss: 0.0084 | Average test loss: 0.0063\n",
      "Step 60: Average train loss: 0.0087 | Average test loss: 0.0074\n",
      "Step 65: Average train loss: 0.0079 | Average test loss: 0.0061\n",
      "Step 70: Average train loss: 0.0082 | Average test loss: 0.0064\n",
      "Step 75: Average train loss: 0.0085 | Average test loss: 0.0070\n",
      "Step 80: Average train loss: 0.0078 | Average test loss: 0.0061\n",
      "Step 85: Average train loss: 0.0085 | Average test loss: 0.0074\n",
      "Step 90: Average train loss: 0.0083 | Average test loss: 0.0065\n",
      "Step 95: Average train loss: 0.0084 | Average test loss: 0.0071\n",
      "Best Epoch: 65\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 45038.5546875\n",
      "Step 0: Average train loss: 0.0095\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0095\n",
      "Step 15: Average train loss: 0.0094\n",
      "Step 20: Average train loss: 0.0094\n",
      "Step 25: Average train loss: 0.0094\n",
      "Step 30: Average train loss: 0.0094\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0094\n",
      "Step 45: Average train loss: 0.0094\n",
      "Step 50: Average train loss: 0.0094\n",
      "Step 55: Average train loss: 0.0093\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0093\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0093\n",
      "Step 85: Average train loss: 0.0093\n",
      "Step 90: Average train loss: 0.0093\n",
      "Step 95: Average train loss: 0.0092\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 43611.0625\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0090\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0089\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0089\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0088\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0088\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 46538.25390625\n",
      "Step 0: Average train loss: 0.0092\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0091\n",
      "Step 30: Average train loss: 0.0091\n",
      "Step 35: Average train loss: 0.0091\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0090\n",
      "Step 70: Average train loss: 0.0090\n",
      "Step 75: Average train loss: 0.0090\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 35066.03515625\n",
      "Step 0: Average train loss: 0.0084\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0083\n",
      "Step 20: Average train loss: 0.0083\n",
      "Step 25: Average train loss: 0.0083\n",
      "Step 30: Average train loss: 0.0083\n",
      "Step 35: Average train loss: 0.0083\n",
      "Step 40: Average train loss: 0.0082\n",
      "Step 45: Average train loss: 0.0082\n",
      "Step 50: Average train loss: 0.0082\n",
      "Step 55: Average train loss: 0.0082\n",
      "Step 60: Average train loss: 0.0082\n",
      "Step 65: Average train loss: 0.0082\n",
      "Step 70: Average train loss: 0.0082\n",
      "Step 75: Average train loss: 0.0081\n",
      "Step 80: Average train loss: 0.0081\n",
      "Step 85: Average train loss: 0.0081\n",
      "Step 90: Average train loss: 0.0081\n",
      "Step 95: Average train loss: 0.0081\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 37628.5546875\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0080\n",
      "Step 10: Average train loss: 0.0080\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0080\n",
      "Step 25: Average train loss: 0.0080\n",
      "Step 30: Average train loss: 0.0080\n",
      "Step 35: Average train loss: 0.0080\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0079\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23663.099609375\n",
      "Step 0: Average train loss: 0.0074\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 14416.169921875\n",
      "Step 0: Average train loss: 0.0064\n",
      "Step 5: Average train loss: 0.0064\n",
      "Step 10: Average train loss: 0.0064\n",
      "Step 15: Average train loss: 0.0064\n",
      "Step 20: Average train loss: 0.0064\n",
      "Step 25: Average train loss: 0.0064\n",
      "Step 30: Average train loss: 0.0064\n",
      "Step 35: Average train loss: 0.0064\n",
      "Step 40: Average train loss: 0.0064\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9718.330078125\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 11782.8388671875\n",
      "Step 0: Average train loss: 0.0056\n",
      "Step 5: Average train loss: 0.0056\n",
      "Step 10: Average train loss: 0.0056\n",
      "Step 15: Average train loss: 0.0056\n",
      "Step 20: Average train loss: 0.0056\n",
      "Step 25: Average train loss: 0.0056\n",
      "Step 30: Average train loss: 0.0056\n",
      "Step 35: Average train loss: 0.0056\n",
      "Step 40: Average train loss: 0.0056\n",
      "Step 45: Average train loss: 0.0056\n",
      "Step 50: Average train loss: 0.0056\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 17339.416015625\n",
      "Step 0: Average train loss: 0.0053\n",
      "Step 5: Average train loss: 0.0053\n",
      "Step 10: Average train loss: 0.0053\n",
      "Step 15: Average train loss: 0.0053\n",
      "Step 20: Average train loss: 0.0053\n",
      "Step 25: Average train loss: 0.0053\n",
      "Step 30: Average train loss: 0.0053\n",
      "Step 35: Average train loss: 0.0053\n",
      "Step 40: Average train loss: 0.0053\n",
      "Step 45: Average train loss: 0.0053\n",
      "Step 50: Average train loss: 0.0053\n",
      "Step 55: Average train loss: 0.0053\n",
      "Step 60: Average train loss: 0.0053\n",
      "Step 65: Average train loss: 0.0053\n",
      "Step 70: Average train loss: 0.0053\n",
      "Step 75: Average train loss: 0.0053\n",
      "Step 80: Average train loss: 0.0053\n",
      "Step 85: Average train loss: 0.0053\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 46893.29296875\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0065\n",
      "Step 55: Average train loss: 0.0065\n",
      "Step 60: Average train loss: 0.0065\n",
      "Step 65: Average train loss: 0.0065\n",
      "Step 70: Average train loss: 0.0065\n",
      "Step 75: Average train loss: 0.0065\n",
      "Step 80: Average train loss: 0.0065\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 38712.19921875\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 34777.38671875\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 8]) torch.Size([144, 24, 8]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0434 | Average test loss: 0.0397\n",
      "Step 5: Average train loss: 0.0074 | Average test loss: 0.0032\n",
      "Step 10: Average train loss: 0.0060 | Average test loss: 0.0019\n",
      "Step 15: Average train loss: 0.0055 | Average test loss: 0.0016\n",
      "Step 20: Average train loss: 0.0053 | Average test loss: 0.0016\n",
      "Step 25: Average train loss: 0.0052 | Average test loss: 0.0017\n",
      "Step 30: Average train loss: 0.0051 | Average test loss: 0.0017\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 40: Average train loss: 0.0050 | Average test loss: 0.0018\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 55: Average train loss: 0.0049 | Average test loss: 0.0022\n",
      "Step 60: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 70: Average train loss: 0.0048 | Average test loss: 0.0023\n",
      "Step 75: Average train loss: 0.0048 | Average test loss: 0.0024\n",
      "Step 80: Average train loss: 0.0048 | Average test loss: 0.0024\n",
      "Step 85: Average train loss: 0.0047 | Average test loss: 0.0023\n",
      "Step 90: Average train loss: 0.0047 | Average test loss: 0.0022\n",
      "Step 95: Average train loss: 0.0047 | Average test loss: 0.0026\n",
      "Best Epoch: 18\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 301952.6875\n",
      "Step 0: Average train loss: 0.0160\n",
      "Step 5: Average train loss: 0.0160\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0159\n",
      "Step 25: Average train loss: 0.0159\n",
      "Step 30: Average train loss: 0.0159\n",
      "Step 35: Average train loss: 0.0159\n",
      "Step 40: Average train loss: 0.0159\n",
      "Step 45: Average train loss: 0.0159\n",
      "Step 50: Average train loss: 0.0159\n",
      "Step 55: Average train loss: 0.0159\n",
      "Step 60: Average train loss: 0.0159\n",
      "Step 65: Average train loss: 0.0159\n",
      "Step 70: Average train loss: 0.0159\n",
      "Step 75: Average train loss: 0.0159\n",
      "Step 80: Average train loss: 0.0159\n",
      "Step 85: Average train loss: 0.0159\n",
      "Step 90: Average train loss: 0.0158\n",
      "Step 95: Average train loss: 0.0158\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 294898.28125\n",
      "Step 0: Average train loss: 0.0156\n",
      "Step 5: Average train loss: 0.0156\n",
      "Step 10: Average train loss: 0.0155\n",
      "Step 15: Average train loss: 0.0155\n",
      "Step 20: Average train loss: 0.0155\n",
      "Step 25: Average train loss: 0.0155\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0155\n",
      "Step 45: Average train loss: 0.0155\n",
      "Step 50: Average train loss: 0.0155\n",
      "Step 55: Average train loss: 0.0154\n",
      "Step 60: Average train loss: 0.0154\n",
      "Step 65: Average train loss: 0.0154\n",
      "Step 70: Average train loss: 0.0154\n",
      "Step 75: Average train loss: 0.0154\n",
      "Step 80: Average train loss: 0.0154\n",
      "Step 85: Average train loss: 0.0154\n",
      "Step 90: Average train loss: 0.0154\n",
      "Step 95: Average train loss: 0.0153\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 250668.828125\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 283509.59375\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 287911.8125\n",
      "Step 0: Average train loss: 0.0146\n",
      "Step 5: Average train loss: 0.0146\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0145\n",
      "Step 45: Average train loss: 0.0145\n",
      "Step 50: Average train loss: 0.0145\n",
      "Step 55: Average train loss: 0.0145\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 307782.875\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 203411.15625\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0137\n",
      "Step 35: Average train loss: 0.0137\n",
      "Step 40: Average train loss: 0.0137\n",
      "Step 45: Average train loss: 0.0137\n",
      "Step 50: Average train loss: 0.0137\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 291231.28125\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0141\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 303281.0625\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0142\n",
      "Step 35: Average train loss: 0.0142\n",
      "Step 40: Average train loss: 0.0142\n",
      "Step 45: Average train loss: 0.0142\n",
      "Step 50: Average train loss: 0.0142\n",
      "Step 55: Average train loss: 0.0142\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0141\n",
      "Step 85: Average train loss: 0.0141\n",
      "Step 90: Average train loss: 0.0141\n",
      "Step 95: Average train loss: 0.0141\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 410102.75\n",
      "Step 0: Average train loss: 0.0154\n",
      "Step 5: Average train loss: 0.0154\n",
      "Step 10: Average train loss: 0.0154\n",
      "Step 15: Average train loss: 0.0153\n",
      "Step 20: Average train loss: 0.0153\n",
      "Step 25: Average train loss: 0.0153\n",
      "Step 30: Average train loss: 0.0153\n",
      "Step 35: Average train loss: 0.0153\n",
      "Step 40: Average train loss: 0.0153\n",
      "Step 45: Average train loss: 0.0153\n",
      "Step 50: Average train loss: 0.0153\n",
      "Step 55: Average train loss: 0.0153\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0153\n",
      "Step 75: Average train loss: 0.0153\n",
      "Step 80: Average train loss: 0.0153\n",
      "Step 85: Average train loss: 0.0153\n",
      "Step 90: Average train loss: 0.0152\n",
      "Step 95: Average train loss: 0.0152\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 419981.46875\n",
      "Step 0: Average train loss: 0.0163\n",
      "Step 5: Average train loss: 0.0163\n",
      "Step 10: Average train loss: 0.0163\n",
      "Step 15: Average train loss: 0.0163\n",
      "Step 20: Average train loss: 0.0163\n",
      "Step 25: Average train loss: 0.0163\n",
      "Step 30: Average train loss: 0.0163\n",
      "Step 35: Average train loss: 0.0163\n",
      "Step 40: Average train loss: 0.0163\n",
      "Step 45: Average train loss: 0.0163\n",
      "Step 50: Average train loss: 0.0163\n",
      "Step 55: Average train loss: 0.0163\n",
      "Step 60: Average train loss: 0.0162\n",
      "Step 65: Average train loss: 0.0162\n",
      "Step 70: Average train loss: 0.0162\n",
      "Step 75: Average train loss: 0.0162\n",
      "Step 80: Average train loss: 0.0162\n",
      "Step 85: Average train loss: 0.0162\n",
      "Step 90: Average train loss: 0.0162\n",
      "Step 95: Average train loss: 0.0162\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 386856.875\n",
      "Step 0: Average train loss: 0.0159\n",
      "Step 5: Average train loss: 0.0159\n",
      "Step 10: Average train loss: 0.0159\n",
      "Step 15: Average train loss: 0.0159\n",
      "Step 20: Average train loss: 0.0158\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0158\n",
      "Step 45: Average train loss: 0.0158\n",
      "Step 50: Average train loss: 0.0158\n",
      "Step 55: Average train loss: 0.0158\n",
      "Step 60: Average train loss: 0.0158\n",
      "Step 65: Average train loss: 0.0158\n",
      "Step 70: Average train loss: 0.0158\n",
      "Step 75: Average train loss: 0.0158\n",
      "Step 80: Average train loss: 0.0158\n",
      "Step 85: Average train loss: 0.0158\n",
      "Step 90: Average train loss: 0.0158\n",
      "Step 95: Average train loss: 0.0158\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 576552.0625\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 8]) torch.Size([140, 24, 8]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0403 | Average test loss: 0.0240\n",
      "Step 5: Average train loss: 0.0246 | Average test loss: 0.0181\n",
      "Step 10: Average train loss: 0.0105 | Average test loss: 0.0108\n",
      "Step 15: Average train loss: 0.0097 | Average test loss: 0.0092\n",
      "Step 20: Average train loss: 0.0119 | Average test loss: 0.0109\n",
      "Step 25: Average train loss: 0.0099 | Average test loss: 0.0084\n",
      "Step 30: Average train loss: 0.0095 | Average test loss: 0.0082\n",
      "Step 35: Average train loss: 0.0100 | Average test loss: 0.0085\n",
      "Step 40: Average train loss: 0.0095 | Average test loss: 0.0086\n",
      "Step 45: Average train loss: 0.0093 | Average test loss: 0.0081\n",
      "Step 50: Average train loss: 0.0090 | Average test loss: 0.0079\n",
      "Step 55: Average train loss: 0.0088 | Average test loss: 0.0079\n",
      "Step 60: Average train loss: 0.0093 | Average test loss: 0.0086\n",
      "Step 65: Average train loss: 0.0092 | Average test loss: 0.0085\n",
      "Step 70: Average train loss: 0.0088 | Average test loss: 0.0082\n",
      "Step 75: Average train loss: 0.0092 | Average test loss: 0.0079\n",
      "Step 80: Average train loss: 0.0086 | Average test loss: 0.0079\n",
      "Step 85: Average train loss: 0.0087 | Average test loss: 0.0080\n",
      "Step 90: Average train loss: 0.0085 | Average test loss: 0.0081\n",
      "Step 95: Average train loss: 0.0090 | Average test loss: 0.0078\n",
      "Best Epoch: 96\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 85691.484375\n",
      "Step 0: Average train loss: 0.0227\n",
      "Step 5: Average train loss: 0.0227\n",
      "Step 10: Average train loss: 0.0226\n",
      "Step 15: Average train loss: 0.0226\n",
      "Step 20: Average train loss: 0.0226\n",
      "Step 25: Average train loss: 0.0225\n",
      "Step 30: Average train loss: 0.0225\n",
      "Step 35: Average train loss: 0.0225\n",
      "Step 40: Average train loss: 0.0225\n",
      "Step 45: Average train loss: 0.0224\n",
      "Step 50: Average train loss: 0.0224\n",
      "Step 55: Average train loss: 0.0224\n",
      "Step 60: Average train loss: 0.0223\n",
      "Step 65: Average train loss: 0.0223\n",
      "Step 70: Average train loss: 0.0223\n",
      "Step 75: Average train loss: 0.0223\n",
      "Step 80: Average train loss: 0.0222\n",
      "Step 85: Average train loss: 0.0222\n",
      "Step 90: Average train loss: 0.0222\n",
      "Step 95: Average train loss: 0.0221\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 87475.296875\n",
      "Step 0: Average train loss: 0.0217\n",
      "Step 5: Average train loss: 0.0217\n",
      "Step 10: Average train loss: 0.0216\n",
      "Step 15: Average train loss: 0.0216\n",
      "Step 20: Average train loss: 0.0215\n",
      "Step 25: Average train loss: 0.0215\n",
      "Step 30: Average train loss: 0.0214\n",
      "Step 35: Average train loss: 0.0214\n",
      "Step 40: Average train loss: 0.0213\n",
      "Step 45: Average train loss: 0.0213\n",
      "Step 50: Average train loss: 0.0212\n",
      "Step 55: Average train loss: 0.0212\n",
      "Step 60: Average train loss: 0.0211\n",
      "Step 65: Average train loss: 0.0211\n",
      "Step 70: Average train loss: 0.0210\n",
      "Step 75: Average train loss: 0.0210\n",
      "Step 80: Average train loss: 0.0209\n",
      "Step 85: Average train loss: 0.0209\n",
      "Step 90: Average train loss: 0.0208\n",
      "Step 95: Average train loss: 0.0208\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 66362.453125\n",
      "Step 0: Average train loss: 0.0202\n",
      "Step 5: Average train loss: 0.0201\n",
      "Step 10: Average train loss: 0.0201\n",
      "Step 15: Average train loss: 0.0200\n",
      "Step 20: Average train loss: 0.0200\n",
      "Step 25: Average train loss: 0.0199\n",
      "Step 30: Average train loss: 0.0199\n",
      "Step 35: Average train loss: 0.0198\n",
      "Step 40: Average train loss: 0.0198\n",
      "Step 45: Average train loss: 0.0197\n",
      "Step 50: Average train loss: 0.0197\n",
      "Step 55: Average train loss: 0.0196\n",
      "Step 60: Average train loss: 0.0196\n",
      "Step 65: Average train loss: 0.0196\n",
      "Step 70: Average train loss: 0.0195\n",
      "Step 75: Average train loss: 0.0195\n",
      "Step 80: Average train loss: 0.0194\n",
      "Step 85: Average train loss: 0.0194\n",
      "Step 90: Average train loss: 0.0193\n",
      "Step 95: Average train loss: 0.0193\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 60487.34375\n",
      "Step 0: Average train loss: 0.0181\n",
      "Step 5: Average train loss: 0.0181\n",
      "Step 10: Average train loss: 0.0180\n",
      "Step 15: Average train loss: 0.0179\n",
      "Step 20: Average train loss: 0.0179\n",
      "Step 25: Average train loss: 0.0178\n",
      "Step 30: Average train loss: 0.0177\n",
      "Step 35: Average train loss: 0.0177\n",
      "Step 40: Average train loss: 0.0176\n",
      "Step 45: Average train loss: 0.0175\n",
      "Step 50: Average train loss: 0.0175\n",
      "Step 55: Average train loss: 0.0174\n",
      "Step 60: Average train loss: 0.0174\n",
      "Step 65: Average train loss: 0.0173\n",
      "Step 70: Average train loss: 0.0172\n",
      "Step 75: Average train loss: 0.0172\n",
      "Step 80: Average train loss: 0.0171\n",
      "Step 85: Average train loss: 0.0170\n",
      "Step 90: Average train loss: 0.0170\n",
      "Step 95: Average train loss: 0.0169\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 37950.6796875\n",
      "Step 0: Average train loss: 0.0145\n",
      "Step 5: Average train loss: 0.0145\n",
      "Step 10: Average train loss: 0.0144\n",
      "Step 15: Average train loss: 0.0143\n",
      "Step 20: Average train loss: 0.0143\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0141\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0140\n",
      "Step 45: Average train loss: 0.0139\n",
      "Step 50: Average train loss: 0.0139\n",
      "Step 55: Average train loss: 0.0138\n",
      "Step 60: Average train loss: 0.0137\n",
      "Step 65: Average train loss: 0.0137\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0135\n",
      "Step 85: Average train loss: 0.0134\n",
      "Step 90: Average train loss: 0.0134\n",
      "Step 95: Average train loss: 0.0133\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 35213.62109375\n",
      "Step 0: Average train loss: 0.0135\n",
      "Step 5: Average train loss: 0.0134\n",
      "Step 10: Average train loss: 0.0133\n",
      "Step 15: Average train loss: 0.0133\n",
      "Step 20: Average train loss: 0.0132\n",
      "Step 25: Average train loss: 0.0132\n",
      "Step 30: Average train loss: 0.0131\n",
      "Step 35: Average train loss: 0.0131\n",
      "Step 40: Average train loss: 0.0130\n",
      "Step 45: Average train loss: 0.0130\n",
      "Step 50: Average train loss: 0.0129\n",
      "Step 55: Average train loss: 0.0129\n",
      "Step 60: Average train loss: 0.0128\n",
      "Step 65: Average train loss: 0.0128\n",
      "Step 70: Average train loss: 0.0127\n",
      "Step 75: Average train loss: 0.0126\n",
      "Step 80: Average train loss: 0.0126\n",
      "Step 85: Average train loss: 0.0125\n",
      "Step 90: Average train loss: 0.0125\n",
      "Step 95: Average train loss: 0.0125\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 19307.36328125\n",
      "Step 0: Average train loss: 0.0109\n",
      "Step 5: Average train loss: 0.0109\n",
      "Step 10: Average train loss: 0.0108\n",
      "Step 15: Average train loss: 0.0108\n",
      "Step 20: Average train loss: 0.0107\n",
      "Step 25: Average train loss: 0.0107\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0106\n",
      "Step 40: Average train loss: 0.0106\n",
      "Step 45: Average train loss: 0.0105\n",
      "Step 50: Average train loss: 0.0105\n",
      "Step 55: Average train loss: 0.0105\n",
      "Step 60: Average train loss: 0.0104\n",
      "Step 65: Average train loss: 0.0104\n",
      "Step 70: Average train loss: 0.0103\n",
      "Step 75: Average train loss: 0.0103\n",
      "Step 80: Average train loss: 0.0103\n",
      "Step 85: Average train loss: 0.0102\n",
      "Step 90: Average train loss: 0.0102\n",
      "Step 95: Average train loss: 0.0102\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 11012.7919921875\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0087\n",
      "Step 10: Average train loss: 0.0086\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0085\n",
      "Step 30: Average train loss: 0.0085\n",
      "Step 35: Average train loss: 0.0085\n",
      "Step 40: Average train loss: 0.0084\n",
      "Step 45: Average train loss: 0.0084\n",
      "Step 50: Average train loss: 0.0084\n",
      "Step 55: Average train loss: 0.0084\n",
      "Step 60: Average train loss: 0.0083\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0082\n",
      "Step 80: Average train loss: 0.0082\n",
      "Step 85: Average train loss: 0.0082\n",
      "Step 90: Average train loss: 0.0082\n",
      "Step 95: Average train loss: 0.0081\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 12566.908203125\n",
      "Step 0: Average train loss: 0.0082\n",
      "Step 5: Average train loss: 0.0082\n",
      "Step 10: Average train loss: 0.0081\n",
      "Step 15: Average train loss: 0.0081\n",
      "Step 20: Average train loss: 0.0081\n",
      "Step 25: Average train loss: 0.0081\n",
      "Step 30: Average train loss: 0.0080\n",
      "Step 35: Average train loss: 0.0080\n",
      "Step 40: Average train loss: 0.0080\n",
      "Step 45: Average train loss: 0.0080\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 19782.56640625\n",
      "Step 0: Average train loss: 0.0074\n",
      "Step 5: Average train loss: 0.0073\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0073\n",
      "Step 20: Average train loss: 0.0073\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0072\n",
      "Step 40: Average train loss: 0.0072\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0069\n",
      "Step 95: Average train loss: 0.0069\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 32579.197265625\n",
      "Step 0: Average train loss: 0.0072\n",
      "Step 5: Average train loss: 0.0072\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0070\n",
      "Step 35: Average train loss: 0.0070\n",
      "Step 40: Average train loss: 0.0070\n",
      "Step 45: Average train loss: 0.0070\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 34274.8984375\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', inv_limit=False);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "    rmse.loc[(4, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 5]) torch.Size([140, 24, 5]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0562 | Average test loss: 0.0354\n",
      "Step 5: Average train loss: 0.0153 | Average test loss: 0.0137\n",
      "Step 10: Average train loss: 0.0125 | Average test loss: 0.0130\n",
      "Step 15: Average train loss: 0.0114 | Average test loss: 0.0112\n",
      "Step 20: Average train loss: 0.0109 | Average test loss: 0.0108\n",
      "Step 25: Average train loss: 0.0108 | Average test loss: 0.0108\n",
      "Step 30: Average train loss: 0.0105 | Average test loss: 0.0104\n",
      "Step 35: Average train loss: 0.0105 | Average test loss: 0.0104\n",
      "Step 40: Average train loss: 0.0104 | Average test loss: 0.0103\n",
      "Step 45: Average train loss: 0.0104 | Average test loss: 0.0103\n",
      "Step 50: Average train loss: 0.0103 | Average test loss: 0.0102\n",
      "Step 55: Average train loss: 0.0103 | Average test loss: 0.0102\n",
      "Step 60: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 65: Average train loss: 0.0100 | Average test loss: 0.0094\n",
      "Step 70: Average train loss: 0.0099 | Average test loss: 0.0100\n",
      "Step 75: Average train loss: 0.0095 | Average test loss: 0.0088\n",
      "Step 80: Average train loss: 0.0097 | Average test loss: 0.0088\n",
      "Step 85: Average train loss: 0.0096 | Average test loss: 0.0092\n",
      "Step 90: Average train loss: 0.0098 | Average test loss: 0.0091\n",
      "Step 95: Average train loss: 0.0095 | Average test loss: 0.0087\n",
      "Best Epoch: 74\n",
      "Shape of data:  torch.Size([30, 24, 5]) torch.Size([30, 24, 5]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 70521.2578125\n",
      "Step 0: Average train loss: 0.0113\n",
      "Step 5: Average train loss: 0.0113\n",
      "Step 10: Average train loss: 0.0113\n",
      "Step 15: Average train loss: 0.0112\n",
      "Step 20: Average train loss: 0.0112\n",
      "Step 25: Average train loss: 0.0112\n",
      "Step 30: Average train loss: 0.0112\n",
      "Step 35: Average train loss: 0.0112\n",
      "Step 40: Average train loss: 0.0111\n",
      "Step 45: Average train loss: 0.0111\n",
      "Step 50: Average train loss: 0.0111\n",
      "Step 55: Average train loss: 0.0111\n",
      "Step 60: Average train loss: 0.0111\n",
      "Step 65: Average train loss: 0.0111\n",
      "Step 70: Average train loss: 0.0110\n",
      "Step 75: Average train loss: 0.0110\n",
      "Step 80: Average train loss: 0.0110\n",
      "Step 85: Average train loss: 0.0110\n",
      "Step 90: Average train loss: 0.0110\n",
      "Step 95: Average train loss: 0.0110\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 64551.53515625\n",
      "Step 0: Average train loss: 0.0108\n",
      "Step 5: Average train loss: 0.0108\n",
      "Step 10: Average train loss: 0.0108\n",
      "Step 15: Average train loss: 0.0108\n",
      "Step 20: Average train loss: 0.0107\n",
      "Step 25: Average train loss: 0.0107\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0107\n",
      "Step 40: Average train loss: 0.0107\n",
      "Step 45: Average train loss: 0.0106\n",
      "Step 50: Average train loss: 0.0106\n",
      "Step 55: Average train loss: 0.0106\n",
      "Step 60: Average train loss: 0.0106\n",
      "Step 65: Average train loss: 0.0106\n",
      "Step 70: Average train loss: 0.0106\n",
      "Step 75: Average train loss: 0.0105\n",
      "Step 80: Average train loss: 0.0105\n",
      "Step 85: Average train loss: 0.0105\n",
      "Step 90: Average train loss: 0.0105\n",
      "Step 95: Average train loss: 0.0105\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 49883.18359375\n",
      "Step 0: Average train loss: 0.0095\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0094\n",
      "Step 15: Average train loss: 0.0094\n",
      "Step 20: Average train loss: 0.0094\n",
      "Step 25: Average train loss: 0.0094\n",
      "Step 30: Average train loss: 0.0094\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0094\n",
      "Step 45: Average train loss: 0.0093\n",
      "Step 50: Average train loss: 0.0093\n",
      "Step 55: Average train loss: 0.0093\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0093\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0092\n",
      "Step 85: Average train loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092\n",
      "Step 95: Average train loss: 0.0092\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 53552.51171875\n",
      "Step 0: Average train loss: 0.0089\n",
      "Step 5: Average train loss: 0.0089\n",
      "Step 10: Average train loss: 0.0089\n",
      "Step 15: Average train loss: 0.0089\n",
      "Step 20: Average train loss: 0.0089\n",
      "Step 25: Average train loss: 0.0088\n",
      "Step 30: Average train loss: 0.0088\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0088\n",
      "Step 50: Average train loss: 0.0088\n",
      "Step 55: Average train loss: 0.0088\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0087\n",
      "Step 80: Average train loss: 0.0087\n",
      "Step 85: Average train loss: 0.0087\n",
      "Step 90: Average train loss: 0.0087\n",
      "Step 95: Average train loss: 0.0086\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 47888.7109375\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 40980.41015625\n",
      "Step 0: Average train loss: 0.0080\n",
      "Step 5: Average train loss: 0.0080\n",
      "Step 10: Average train loss: 0.0080\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0079\n",
      "Step 35: Average train loss: 0.0079\n",
      "Step 40: Average train loss: 0.0079\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0079\n",
      "Step 65: Average train loss: 0.0079\n",
      "Step 70: Average train loss: 0.0079\n",
      "Step 75: Average train loss: 0.0079\n",
      "Step 80: Average train loss: 0.0079\n",
      "Step 85: Average train loss: 0.0079\n",
      "Step 90: Average train loss: 0.0079\n",
      "Step 95: Average train loss: 0.0079\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 27213.01171875\n",
      "Step 0: Average train loss: 0.0072\n",
      "Step 5: Average train loss: 0.0072\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 10430.9833984375\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 15663.7197265625\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 41455.71484375\n",
      "Step 0: Average train loss: 0.0063\n",
      "Step 5: Average train loss: 0.0063\n",
      "Step 10: Average train loss: 0.0063\n",
      "Step 15: Average train loss: 0.0063\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0062\n",
      "Step 70: Average train loss: 0.0062\n",
      "Step 75: Average train loss: 0.0062\n",
      "Step 80: Average train loss: 0.0062\n",
      "Step 85: Average train loss: 0.0062\n",
      "Step 90: Average train loss: 0.0062\n",
      "Step 95: Average train loss: 0.0062\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 58108.0234375\n",
      "Step 0: Average train loss: 0.0068\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 58015.56640625\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n",
      "Step 60: Average train loss: 0.0067\n",
      "Step 65: Average train loss: 0.0067\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 74503.4609375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 5]) torch.Size([140, 24, 5]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0459 | Average test loss: 0.0266\n",
      "Step 5: Average train loss: 0.0222 | Average test loss: 0.0153\n",
      "Step 10: Average train loss: 0.0093 | Average test loss: 0.0075\n",
      "Step 15: Average train loss: 0.0096 | Average test loss: 0.0075\n",
      "Step 20: Average train loss: 0.0094 | Average test loss: 0.0071\n",
      "Step 25: Average train loss: 0.0094 | Average test loss: 0.0070\n",
      "Step 30: Average train loss: 0.0089 | Average test loss: 0.0071\n",
      "Step 35: Average train loss: 0.0091 | Average test loss: 0.0070\n",
      "Step 40: Average train loss: 0.0089 | Average test loss: 0.0072\n",
      "Step 45: Average train loss: 0.0089 | Average test loss: 0.0069\n",
      "Step 50: Average train loss: 0.0088 | Average test loss: 0.0072\n",
      "Step 55: Average train loss: 0.0088 | Average test loss: 0.0068\n",
      "Step 60: Average train loss: 0.0088 | Average test loss: 0.0070\n",
      "Step 65: Average train loss: 0.0088 | Average test loss: 0.0068\n",
      "Step 70: Average train loss: 0.0087 | Average test loss: 0.0068\n",
      "Step 75: Average train loss: 0.0087 | Average test loss: 0.0069\n",
      "Step 80: Average train loss: 0.0086 | Average test loss: 0.0066\n",
      "Step 85: Average train loss: 0.0086 | Average test loss: 0.0066\n",
      "Step 90: Average train loss: 0.0087 | Average test loss: 0.0069\n",
      "Step 95: Average train loss: 0.0085 | Average test loss: 0.0064\n",
      "Best Epoch: 93\n",
      "Shape of data:  torch.Size([30, 24, 5]) torch.Size([30, 24, 5]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 41935.390625\n",
      "Step 0: Average train loss: 0.0088\n",
      "Step 5: Average train loss: 0.0088\n",
      "Step 10: Average train loss: 0.0088\n",
      "Step 15: Average train loss: 0.0088\n",
      "Step 20: Average train loss: 0.0088\n",
      "Step 25: Average train loss: 0.0087\n",
      "Step 30: Average train loss: 0.0087\n",
      "Step 35: Average train loss: 0.0087\n",
      "Step 40: Average train loss: 0.0087\n",
      "Step 45: Average train loss: 0.0087\n",
      "Step 50: Average train loss: 0.0087\n",
      "Step 55: Average train loss: 0.0087\n",
      "Step 60: Average train loss: 0.0087\n",
      "Step 65: Average train loss: 0.0087\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0086\n",
      "Step 80: Average train loss: 0.0086\n",
      "Step 85: Average train loss: 0.0086\n",
      "Step 90: Average train loss: 0.0086\n",
      "Step 95: Average train loss: 0.0086\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 45100.74609375\n",
      "Step 0: Average train loss: 0.0091\n",
      "Step 5: Average train loss: 0.0091\n",
      "Step 10: Average train loss: 0.0091\n",
      "Step 15: Average train loss: 0.0091\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0091\n",
      "Step 30: Average train loss: 0.0090\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0090\n",
      "Step 45: Average train loss: 0.0090\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0090\n",
      "Step 60: Average train loss: 0.0090\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0089\n",
      "Step 75: Average train loss: 0.0089\n",
      "Step 80: Average train loss: 0.0089\n",
      "Step 85: Average train loss: 0.0089\n",
      "Step 90: Average train loss: 0.0089\n",
      "Step 95: Average train loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 52291.34375\n",
      "Step 0: Average train loss: 0.0095\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0095\n",
      "Step 15: Average train loss: 0.0094\n",
      "Step 20: Average train loss: 0.0094\n",
      "Step 25: Average train loss: 0.0094\n",
      "Step 30: Average train loss: 0.0094\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0094\n",
      "Step 45: Average train loss: 0.0094\n",
      "Step 50: Average train loss: 0.0093\n",
      "Step 55: Average train loss: 0.0093\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0093\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0093\n",
      "Step 85: Average train loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092\n",
      "Step 95: Average train loss: 0.0092\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 36504.0703125\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0086\n",
      "Step 10: Average train loss: 0.0086\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0085\n",
      "Step 40: Average train loss: 0.0085\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0084\n",
      "Step 75: Average train loss: 0.0084\n",
      "Step 80: Average train loss: 0.0084\n",
      "Step 85: Average train loss: 0.0084\n",
      "Step 90: Average train loss: 0.0084\n",
      "Step 95: Average train loss: 0.0084\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 38479.140625\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0083\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0082\n",
      "Step 20: Average train loss: 0.0082\n",
      "Step 25: Average train loss: 0.0082\n",
      "Step 30: Average train loss: 0.0082\n",
      "Step 35: Average train loss: 0.0082\n",
      "Step 40: Average train loss: 0.0081\n",
      "Step 45: Average train loss: 0.0081\n",
      "Step 50: Average train loss: 0.0081\n",
      "Step 55: Average train loss: 0.0081\n",
      "Step 60: Average train loss: 0.0081\n",
      "Step 65: Average train loss: 0.0081\n",
      "Step 70: Average train loss: 0.0080\n",
      "Step 75: Average train loss: 0.0080\n",
      "Step 80: Average train loss: 0.0080\n",
      "Step 85: Average train loss: 0.0080\n",
      "Step 90: Average train loss: 0.0080\n",
      "Step 95: Average train loss: 0.0080\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 24408.955078125\n",
      "Step 0: Average train loss: 0.0076\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0075\n",
      "Step 15: Average train loss: 0.0075\n",
      "Step 20: Average train loss: 0.0075\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0075\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0075\n",
      "Step 50: Average train loss: 0.0075\n",
      "Step 55: Average train loss: 0.0075\n",
      "Step 60: Average train loss: 0.0075\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 14959.5068359375\n",
      "Step 0: Average train loss: 0.0065\n",
      "Step 5: Average train loss: 0.0065\n",
      "Step 10: Average train loss: 0.0065\n",
      "Step 15: Average train loss: 0.0065\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0065\n",
      "Step 30: Average train loss: 0.0065\n",
      "Step 35: Average train loss: 0.0065\n",
      "Step 40: Average train loss: 0.0065\n",
      "Step 45: Average train loss: 0.0065\n",
      "Step 50: Average train loss: 0.0065\n",
      "Step 55: Average train loss: 0.0065\n",
      "Step 60: Average train loss: 0.0065\n",
      "Step 65: Average train loss: 0.0065\n",
      "Step 70: Average train loss: 0.0065\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9596.66796875\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 13585.2998046875\n",
      "Step 0: Average train loss: 0.0057\n",
      "Step 5: Average train loss: 0.0057\n",
      "Step 10: Average train loss: 0.0057\n",
      "Step 15: Average train loss: 0.0057\n",
      "Step 20: Average train loss: 0.0057\n",
      "Step 25: Average train loss: 0.0057\n",
      "Step 30: Average train loss: 0.0057\n",
      "Step 35: Average train loss: 0.0057\n",
      "Step 40: Average train loss: 0.0057\n",
      "Step 45: Average train loss: 0.0057\n",
      "Step 50: Average train loss: 0.0057\n",
      "Step 55: Average train loss: 0.0057\n",
      "Step 60: Average train loss: 0.0057\n",
      "Step 65: Average train loss: 0.0057\n",
      "Step 70: Average train loss: 0.0057\n",
      "Step 75: Average train loss: 0.0057\n",
      "Step 80: Average train loss: 0.0057\n",
      "Step 85: Average train loss: 0.0057\n",
      "Step 90: Average train loss: 0.0057\n",
      "Step 95: Average train loss: 0.0057\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 17583.921875\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 45986.24609375\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n",
      "Step 60: Average train loss: 0.0067\n",
      "Step 65: Average train loss: 0.0067\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0067\n",
      "Step 95: Average train loss: 0.0067\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 38944.453125\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 33616.71484375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 5]) torch.Size([144, 24, 5]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0450 | Average test loss: 0.0388\n",
      "Step 5: Average train loss: 0.0080 | Average test loss: 0.0034\n",
      "Step 10: Average train loss: 0.0061 | Average test loss: 0.0018\n",
      "Step 15: Average train loss: 0.0054 | Average test loss: 0.0018\n",
      "Step 20: Average train loss: 0.0053 | Average test loss: 0.0018\n",
      "Step 25: Average train loss: 0.0052 | Average test loss: 0.0018\n",
      "Step 30: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0019\n",
      "Step 40: Average train loss: 0.0051 | Average test loss: 0.0019\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 55: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 60: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 70: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 75: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 80: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 85: Average train loss: 0.0049 | Average test loss: 0.0021\n",
      "Step 90: Average train loss: 0.0049 | Average test loss: 0.0020\n",
      "Step 95: Average train loss: 0.0049 | Average test loss: 0.0018\n",
      "Best Epoch: 89\n",
      "Shape of data:  torch.Size([30, 24, 5]) torch.Size([30, 24, 5]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 302178.53125\n",
      "Step 0: Average train loss: 0.0160\n",
      "Step 5: Average train loss: 0.0160\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0160\n",
      "Step 30: Average train loss: 0.0159\n",
      "Step 35: Average train loss: 0.0159\n",
      "Step 40: Average train loss: 0.0159\n",
      "Step 45: Average train loss: 0.0159\n",
      "Step 50: Average train loss: 0.0159\n",
      "Step 55: Average train loss: 0.0159\n",
      "Step 60: Average train loss: 0.0159\n",
      "Step 65: Average train loss: 0.0159\n",
      "Step 70: Average train loss: 0.0159\n",
      "Step 75: Average train loss: 0.0159\n",
      "Step 80: Average train loss: 0.0159\n",
      "Step 85: Average train loss: 0.0159\n",
      "Step 90: Average train loss: 0.0159\n",
      "Step 95: Average train loss: 0.0159\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 296543.21875\n",
      "Step 0: Average train loss: 0.0156\n",
      "Step 5: Average train loss: 0.0156\n",
      "Step 10: Average train loss: 0.0156\n",
      "Step 15: Average train loss: 0.0156\n",
      "Step 20: Average train loss: 0.0156\n",
      "Step 25: Average train loss: 0.0156\n",
      "Step 30: Average train loss: 0.0156\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0155\n",
      "Step 45: Average train loss: 0.0155\n",
      "Step 50: Average train loss: 0.0155\n",
      "Step 55: Average train loss: 0.0155\n",
      "Step 60: Average train loss: 0.0155\n",
      "Step 65: Average train loss: 0.0155\n",
      "Step 70: Average train loss: 0.0155\n",
      "Step 75: Average train loss: 0.0155\n",
      "Step 80: Average train loss: 0.0154\n",
      "Step 85: Average train loss: 0.0154\n",
      "Step 90: Average train loss: 0.0154\n",
      "Step 95: Average train loss: 0.0154\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 248961.421875\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 286245.375\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 286085.125\n",
      "Step 0: Average train loss: 0.0146\n",
      "Step 5: Average train loss: 0.0146\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0145\n",
      "Step 50: Average train loss: 0.0145\n",
      "Step 55: Average train loss: 0.0145\n",
      "Step 60: Average train loss: 0.0145\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0144\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 300518.46875\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0146\n",
      "Step 15: Average train loss: 0.0146\n",
      "Step 20: Average train loss: 0.0146\n",
      "Step 25: Average train loss: 0.0146\n",
      "Step 30: Average train loss: 0.0146\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0145\n",
      "Step 70: Average train loss: 0.0145\n",
      "Step 75: Average train loss: 0.0145\n",
      "Step 80: Average train loss: 0.0145\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 203694.9375\n",
      "Step 0: Average train loss: 0.0136\n",
      "Step 5: Average train loss: 0.0136\n",
      "Step 10: Average train loss: 0.0136\n",
      "Step 15: Average train loss: 0.0136\n",
      "Step 20: Average train loss: 0.0136\n",
      "Step 25: Average train loss: 0.0136\n",
      "Step 30: Average train loss: 0.0136\n",
      "Step 35: Average train loss: 0.0136\n",
      "Step 40: Average train loss: 0.0136\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0135\n",
      "Step 75: Average train loss: 0.0135\n",
      "Step 80: Average train loss: 0.0135\n",
      "Step 85: Average train loss: 0.0135\n",
      "Step 90: Average train loss: 0.0135\n",
      "Step 95: Average train loss: 0.0135\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 289047.25\n",
      "Step 0: Average train loss: 0.0140\n",
      "Step 5: Average train loss: 0.0140\n",
      "Step 10: Average train loss: 0.0140\n",
      "Step 15: Average train loss: 0.0140\n",
      "Step 20: Average train loss: 0.0140\n",
      "Step 25: Average train loss: 0.0139\n",
      "Step 30: Average train loss: 0.0139\n",
      "Step 35: Average train loss: 0.0139\n",
      "Step 40: Average train loss: 0.0139\n",
      "Step 45: Average train loss: 0.0139\n",
      "Step 50: Average train loss: 0.0139\n",
      "Step 55: Average train loss: 0.0139\n",
      "Step 60: Average train loss: 0.0139\n",
      "Step 65: Average train loss: 0.0139\n",
      "Step 70: Average train loss: 0.0139\n",
      "Step 75: Average train loss: 0.0139\n",
      "Step 80: Average train loss: 0.0138\n",
      "Step 85: Average train loss: 0.0138\n",
      "Step 90: Average train loss: 0.0138\n",
      "Step 95: Average train loss: 0.0138\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 298016.65625\n",
      "Step 0: Average train loss: 0.0141\n",
      "Step 5: Average train loss: 0.0141\n",
      "Step 10: Average train loss: 0.0141\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0140\n",
      "Step 30: Average train loss: 0.0140\n",
      "Step 35: Average train loss: 0.0140\n",
      "Step 40: Average train loss: 0.0140\n",
      "Step 45: Average train loss: 0.0140\n",
      "Step 50: Average train loss: 0.0140\n",
      "Step 55: Average train loss: 0.0140\n",
      "Step 60: Average train loss: 0.0140\n",
      "Step 65: Average train loss: 0.0140\n",
      "Step 70: Average train loss: 0.0140\n",
      "Step 75: Average train loss: 0.0140\n",
      "Step 80: Average train loss: 0.0140\n",
      "Step 85: Average train loss: 0.0140\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 394914.0\n",
      "Step 0: Average train loss: 0.0151\n",
      "Step 5: Average train loss: 0.0151\n",
      "Step 10: Average train loss: 0.0151\n",
      "Step 15: Average train loss: 0.0151\n",
      "Step 20: Average train loss: 0.0151\n",
      "Step 25: Average train loss: 0.0151\n",
      "Step 30: Average train loss: 0.0151\n",
      "Step 35: Average train loss: 0.0151\n",
      "Step 40: Average train loss: 0.0151\n",
      "Step 45: Average train loss: 0.0151\n",
      "Step 50: Average train loss: 0.0151\n",
      "Step 55: Average train loss: 0.0150\n",
      "Step 60: Average train loss: 0.0150\n",
      "Step 65: Average train loss: 0.0150\n",
      "Step 70: Average train loss: 0.0150\n",
      "Step 75: Average train loss: 0.0150\n",
      "Step 80: Average train loss: 0.0150\n",
      "Step 85: Average train loss: 0.0150\n",
      "Step 90: Average train loss: 0.0150\n",
      "Step 95: Average train loss: 0.0150\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 414459.28125\n",
      "Step 0: Average train loss: 0.0160\n",
      "Step 5: Average train loss: 0.0160\n",
      "Step 10: Average train loss: 0.0160\n",
      "Step 15: Average train loss: 0.0160\n",
      "Step 20: Average train loss: 0.0160\n",
      "Step 25: Average train loss: 0.0160\n",
      "Step 30: Average train loss: 0.0160\n",
      "Step 35: Average train loss: 0.0160\n",
      "Step 40: Average train loss: 0.0160\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0160\n",
      "Step 90: Average train loss: 0.0160\n",
      "Step 95: Average train loss: 0.0160\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 388363.65625\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0157\n",
      "Step 20: Average train loss: 0.0157\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0156\n",
      "Step 70: Average train loss: 0.0156\n",
      "Step 75: Average train loss: 0.0156\n",
      "Step 80: Average train loss: 0.0156\n",
      "Step 85: Average train loss: 0.0156\n",
      "Step 90: Average train loss: 0.0156\n",
      "Step 95: Average train loss: 0.0156\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 610730.9375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 5]) torch.Size([140, 24, 5]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0437 | Average test loss: 0.0257\n",
      "Step 5: Average train loss: 0.0162 | Average test loss: 0.0120\n",
      "Step 10: Average train loss: 0.0144 | Average test loss: 0.0124\n",
      "Step 15: Average train loss: 0.0099 | Average test loss: 0.0089\n",
      "Step 20: Average train loss: 0.0101 | Average test loss: 0.0088\n",
      "Step 25: Average train loss: 0.0098 | Average test loss: 0.0086\n",
      "Step 30: Average train loss: 0.0095 | Average test loss: 0.0084\n",
      "Step 35: Average train loss: 0.0094 | Average test loss: 0.0083\n",
      "Step 40: Average train loss: 0.0094 | Average test loss: 0.0082\n",
      "Step 45: Average train loss: 0.0093 | Average test loss: 0.0082\n",
      "Step 50: Average train loss: 0.0094 | Average test loss: 0.0084\n",
      "Step 55: Average train loss: 0.0092 | Average test loss: 0.0082\n",
      "Step 60: Average train loss: 0.0101 | Average test loss: 0.0092\n",
      "Step 65: Average train loss: 0.0092 | Average test loss: 0.0082\n",
      "Step 70: Average train loss: 0.0096 | Average test loss: 0.0084\n",
      "Step 75: Average train loss: 0.0094 | Average test loss: 0.0088\n",
      "Step 80: Average train loss: 0.0092 | Average test loss: 0.0084\n",
      "Step 85: Average train loss: 0.0089 | Average test loss: 0.0079\n",
      "Step 90: Average train loss: 0.0091 | Average test loss: 0.0085\n",
      "Step 95: Average train loss: 0.0097 | Average test loss: 0.0083\n",
      "Best Epoch: 85\n",
      "Shape of data:  torch.Size([30, 24, 5]) torch.Size([30, 24, 5]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 63649.16015625\n",
      "Step 0: Average train loss: 0.0168\n",
      "Step 5: Average train loss: 0.0167\n",
      "Step 10: Average train loss: 0.0167\n",
      "Step 15: Average train loss: 0.0167\n",
      "Step 20: Average train loss: 0.0167\n",
      "Step 25: Average train loss: 0.0167\n",
      "Step 30: Average train loss: 0.0166\n",
      "Step 35: Average train loss: 0.0166\n",
      "Step 40: Average train loss: 0.0166\n",
      "Step 45: Average train loss: 0.0166\n",
      "Step 50: Average train loss: 0.0165\n",
      "Step 55: Average train loss: 0.0165\n",
      "Step 60: Average train loss: 0.0165\n",
      "Step 65: Average train loss: 0.0165\n",
      "Step 70: Average train loss: 0.0164\n",
      "Step 75: Average train loss: 0.0164\n",
      "Step 80: Average train loss: 0.0164\n",
      "Step 85: Average train loss: 0.0164\n",
      "Step 90: Average train loss: 0.0163\n",
      "Step 95: Average train loss: 0.0163\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 70596.6484375\n",
      "Step 0: Average train loss: 0.0169\n",
      "Step 5: Average train loss: 0.0168\n",
      "Step 10: Average train loss: 0.0168\n",
      "Step 15: Average train loss: 0.0167\n",
      "Step 20: Average train loss: 0.0167\n",
      "Step 25: Average train loss: 0.0167\n",
      "Step 30: Average train loss: 0.0166\n",
      "Step 35: Average train loss: 0.0166\n",
      "Step 40: Average train loss: 0.0165\n",
      "Step 45: Average train loss: 0.0165\n",
      "Step 50: Average train loss: 0.0164\n",
      "Step 55: Average train loss: 0.0164\n",
      "Step 60: Average train loss: 0.0164\n",
      "Step 65: Average train loss: 0.0163\n",
      "Step 70: Average train loss: 0.0163\n",
      "Step 75: Average train loss: 0.0162\n",
      "Step 80: Average train loss: 0.0162\n",
      "Step 85: Average train loss: 0.0162\n",
      "Step 90: Average train loss: 0.0161\n",
      "Step 95: Average train loss: 0.0161\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 53494.171875\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0156\n",
      "Step 20: Average train loss: 0.0156\n",
      "Step 25: Average train loss: 0.0155\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0154\n",
      "Step 45: Average train loss: 0.0154\n",
      "Step 50: Average train loss: 0.0154\n",
      "Step 55: Average train loss: 0.0153\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0152\n",
      "Step 75: Average train loss: 0.0152\n",
      "Step 80: Average train loss: 0.0151\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0150\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 43828.33984375\n",
      "Step 0: Average train loss: 0.0139\n",
      "Step 5: Average train loss: 0.0138\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0136\n",
      "Step 25: Average train loss: 0.0136\n",
      "Step 30: Average train loss: 0.0136\n",
      "Step 35: Average train loss: 0.0135\n",
      "Step 40: Average train loss: 0.0135\n",
      "Step 45: Average train loss: 0.0134\n",
      "Step 50: Average train loss: 0.0134\n",
      "Step 55: Average train loss: 0.0133\n",
      "Step 60: Average train loss: 0.0133\n",
      "Step 65: Average train loss: 0.0132\n",
      "Step 70: Average train loss: 0.0132\n",
      "Step 75: Average train loss: 0.0131\n",
      "Step 80: Average train loss: 0.0131\n",
      "Step 85: Average train loss: 0.0130\n",
      "Step 90: Average train loss: 0.0130\n",
      "Step 95: Average train loss: 0.0130\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 27635.33984375\n",
      "Step 0: Average train loss: 0.0110\n",
      "Step 5: Average train loss: 0.0110\n",
      "Step 10: Average train loss: 0.0109\n",
      "Step 15: Average train loss: 0.0109\n",
      "Step 20: Average train loss: 0.0108\n",
      "Step 25: Average train loss: 0.0108\n",
      "Step 30: Average train loss: 0.0107\n",
      "Step 35: Average train loss: 0.0107\n",
      "Step 40: Average train loss: 0.0107\n",
      "Step 45: Average train loss: 0.0106\n",
      "Step 50: Average train loss: 0.0106\n",
      "Step 55: Average train loss: 0.0105\n",
      "Step 60: Average train loss: 0.0105\n",
      "Step 65: Average train loss: 0.0104\n",
      "Step 70: Average train loss: 0.0104\n",
      "Step 75: Average train loss: 0.0104\n",
      "Step 80: Average train loss: 0.0103\n",
      "Step 85: Average train loss: 0.0103\n",
      "Step 90: Average train loss: 0.0103\n",
      "Step 95: Average train loss: 0.0102\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 26217.27734375\n",
      "Step 0: Average train loss: 0.0103\n",
      "Step 5: Average train loss: 0.0103\n",
      "Step 10: Average train loss: 0.0103\n",
      "Step 15: Average train loss: 0.0102\n",
      "Step 20: Average train loss: 0.0102\n",
      "Step 25: Average train loss: 0.0101\n",
      "Step 30: Average train loss: 0.0101\n",
      "Step 35: Average train loss: 0.0101\n",
      "Step 40: Average train loss: 0.0100\n",
      "Step 45: Average train loss: 0.0100\n",
      "Step 50: Average train loss: 0.0100\n",
      "Step 55: Average train loss: 0.0099\n",
      "Step 60: Average train loss: 0.0099\n",
      "Step 65: Average train loss: 0.0099\n",
      "Step 70: Average train loss: 0.0099\n",
      "Step 75: Average train loss: 0.0098\n",
      "Step 80: Average train loss: 0.0098\n",
      "Step 85: Average train loss: 0.0098\n",
      "Step 90: Average train loss: 0.0097\n",
      "Step 95: Average train loss: 0.0097\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 18388.974609375\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0087\n",
      "Step 10: Average train loss: 0.0087\n",
      "Step 15: Average train loss: 0.0086\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0085\n",
      "Step 40: Average train loss: 0.0085\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0084\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0084\n",
      "Step 75: Average train loss: 0.0084\n",
      "Step 80: Average train loss: 0.0084\n",
      "Step 85: Average train loss: 0.0083\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 11899.84765625\n",
      "Step 0: Average train loss: 0.0073\n",
      "Step 5: Average train loss: 0.0072\n",
      "Step 10: Average train loss: 0.0072\n",
      "Step 15: Average train loss: 0.0072\n",
      "Step 20: Average train loss: 0.0072\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0071\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 13107.2529296875\n",
      "Step 0: Average train loss: 0.0070\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 19670.935546875\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0065\n",
      "Step 30: Average train loss: 0.0065\n",
      "Step 35: Average train loss: 0.0065\n",
      "Step 40: Average train loss: 0.0065\n",
      "Step 45: Average train loss: 0.0065\n",
      "Step 50: Average train loss: 0.0065\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 33007.8984375\n",
      "Step 0: Average train loss: 0.0067\n",
      "Step 5: Average train loss: 0.0067\n",
      "Step 10: Average train loss: 0.0067\n",
      "Step 15: Average train loss: 0.0067\n",
      "Step 20: Average train loss: 0.0067\n",
      "Step 25: Average train loss: 0.0067\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0065\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 26984.712890625\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', inv_limit=True);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    features.remove('is_day')\n",
    "    features.remove('PoA')\n",
    "    features.remove('T_PV')\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "    rmse.loc[(5, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 8]) torch.Size([140, 24, 8]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0549 | Average test loss: 0.0359\n",
      "Step 5: Average train loss: 0.0318 | Average test loss: 0.0241\n",
      "Step 10: Average train loss: 0.0121 | Average test loss: 0.0103\n",
      "Step 15: Average train loss: 0.0110 | Average test loss: 0.0101\n",
      "Step 20: Average train loss: 0.0107 | Average test loss: 0.0104\n",
      "Step 25: Average train loss: 0.0105 | Average test loss: 0.0105\n",
      "Step 30: Average train loss: 0.0103 | Average test loss: 0.0103\n",
      "Step 35: Average train loss: 0.0102 | Average test loss: 0.0100\n",
      "Step 40: Average train loss: 0.0100 | Average test loss: 0.0097\n",
      "Step 45: Average train loss: 0.0096 | Average test loss: 0.0094\n",
      "Step 50: Average train loss: 0.0096 | Average test loss: 0.0093\n",
      "Step 55: Average train loss: 0.0096 | Average test loss: 0.0092\n",
      "Step 60: Average train loss: 0.0096 | Average test loss: 0.0099\n",
      "Step 65: Average train loss: 0.0095 | Average test loss: 0.0095\n",
      "Step 70: Average train loss: 0.0093 | Average test loss: 0.0091\n",
      "Step 75: Average train loss: 0.0093 | Average test loss: 0.0092\n",
      "Step 80: Average train loss: 0.0093 | Average test loss: 0.0093\n",
      "Step 85: Average train loss: 0.0092 | Average test loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092 | Average test loss: 0.0090\n",
      "Step 95: Average train loss: 0.0091 | Average test loss: 0.0089\n",
      "Best Epoch: 99\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 66327.8359375\n",
      "Step 0: Average train loss: 0.0106\n",
      "Step 5: Average train loss: 0.0106\n",
      "Step 10: Average train loss: 0.0106\n",
      "Step 15: Average train loss: 0.0106\n",
      "Step 20: Average train loss: 0.0105\n",
      "Step 25: Average train loss: 0.0105\n",
      "Step 30: Average train loss: 0.0105\n",
      "Step 35: Average train loss: 0.0105\n",
      "Step 40: Average train loss: 0.0105\n",
      "Step 45: Average train loss: 0.0105\n",
      "Step 50: Average train loss: 0.0104\n",
      "Step 55: Average train loss: 0.0104\n",
      "Step 60: Average train loss: 0.0104\n",
      "Step 65: Average train loss: 0.0104\n",
      "Step 70: Average train loss: 0.0104\n",
      "Step 75: Average train loss: 0.0104\n",
      "Step 80: Average train loss: 0.0103\n",
      "Step 85: Average train loss: 0.0103\n",
      "Step 90: Average train loss: 0.0103\n",
      "Step 95: Average train loss: 0.0103\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 63321.83203125\n",
      "Step 0: Average train loss: 0.0105\n",
      "Step 5: Average train loss: 0.0105\n",
      "Step 10: Average train loss: 0.0105\n",
      "Step 15: Average train loss: 0.0105\n",
      "Step 20: Average train loss: 0.0104\n",
      "Step 25: Average train loss: 0.0104\n",
      "Step 30: Average train loss: 0.0104\n",
      "Step 35: Average train loss: 0.0104\n",
      "Step 40: Average train loss: 0.0104\n",
      "Step 45: Average train loss: 0.0104\n",
      "Step 50: Average train loss: 0.0103\n",
      "Step 55: Average train loss: 0.0103\n",
      "Step 60: Average train loss: 0.0103\n",
      "Step 65: Average train loss: 0.0103\n",
      "Step 70: Average train loss: 0.0103\n",
      "Step 75: Average train loss: 0.0103\n",
      "Step 80: Average train loss: 0.0102\n",
      "Step 85: Average train loss: 0.0102\n",
      "Step 90: Average train loss: 0.0102\n",
      "Step 95: Average train loss: 0.0102\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 46253.45703125\n",
      "Step 0: Average train loss: 0.0090\n",
      "Step 5: Average train loss: 0.0090\n",
      "Step 10: Average train loss: 0.0090\n",
      "Step 15: Average train loss: 0.0090\n",
      "Step 20: Average train loss: 0.0090\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0089\n",
      "Step 35: Average train loss: 0.0089\n",
      "Step 40: Average train loss: 0.0089\n",
      "Step 45: Average train loss: 0.0089\n",
      "Step 50: Average train loss: 0.0089\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0089\n",
      "Step 65: Average train loss: 0.0089\n",
      "Step 70: Average train loss: 0.0088\n",
      "Step 75: Average train loss: 0.0088\n",
      "Step 80: Average train loss: 0.0088\n",
      "Step 85: Average train loss: 0.0088\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0088\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50039.1875\n",
      "Step 0: Average train loss: 0.0085\n",
      "Step 5: Average train loss: 0.0085\n",
      "Step 10: Average train loss: 0.0084\n",
      "Step 15: Average train loss: 0.0084\n",
      "Step 20: Average train loss: 0.0084\n",
      "Step 25: Average train loss: 0.0084\n",
      "Step 30: Average train loss: 0.0084\n",
      "Step 35: Average train loss: 0.0084\n",
      "Step 40: Average train loss: 0.0084\n",
      "Step 45: Average train loss: 0.0084\n",
      "Step 50: Average train loss: 0.0084\n",
      "Step 55: Average train loss: 0.0084\n",
      "Step 60: Average train loss: 0.0083\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0083\n",
      "Step 80: Average train loss: 0.0083\n",
      "Step 85: Average train loss: 0.0083\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 48101.2734375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0077\n",
      "Step 10: Average train loss: 0.0077\n",
      "Step 15: Average train loss: 0.0077\n",
      "Step 20: Average train loss: 0.0077\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0077\n",
      "Step 40: Average train loss: 0.0077\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0076\n",
      "Step 60: Average train loss: 0.0076\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0076\n",
      "Step 95: Average train loss: 0.0076\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 39744.11328125\n",
      "Step 0: Average train loss: 0.0078\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0078\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0078\n",
      "Step 85: Average train loss: 0.0078\n",
      "Step 90: Average train loss: 0.0078\n",
      "Step 95: Average train loss: 0.0078\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 27006.57421875\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0071\n",
      "Step 15: Average train loss: 0.0071\n",
      "Step 20: Average train loss: 0.0071\n",
      "Step 25: Average train loss: 0.0071\n",
      "Step 30: Average train loss: 0.0071\n",
      "Step 35: Average train loss: 0.0071\n",
      "Step 40: Average train loss: 0.0071\n",
      "Step 45: Average train loss: 0.0070\n",
      "Step 50: Average train loss: 0.0070\n",
      "Step 55: Average train loss: 0.0070\n",
      "Step 60: Average train loss: 0.0070\n",
      "Step 65: Average train loss: 0.0070\n",
      "Step 70: Average train loss: 0.0070\n",
      "Step 75: Average train loss: 0.0070\n",
      "Step 80: Average train loss: 0.0070\n",
      "Step 85: Average train loss: 0.0070\n",
      "Step 90: Average train loss: 0.0070\n",
      "Step 95: Average train loss: 0.0070\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 13015.3349609375\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0060\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0060\n",
      "Step 55: Average train loss: 0.0060\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 20818.412109375\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0061\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0061\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 36896.140625\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0062\n",
      "Step 20: Average train loss: 0.0062\n",
      "Step 25: Average train loss: 0.0062\n",
      "Step 30: Average train loss: 0.0062\n",
      "Step 35: Average train loss: 0.0062\n",
      "Step 40: Average train loss: 0.0062\n",
      "Step 45: Average train loss: 0.0062\n",
      "Step 50: Average train loss: 0.0062\n",
      "Step 55: Average train loss: 0.0062\n",
      "Step 60: Average train loss: 0.0062\n",
      "Step 65: Average train loss: 0.0061\n",
      "Step 70: Average train loss: 0.0061\n",
      "Step 75: Average train loss: 0.0061\n",
      "Step 80: Average train loss: 0.0061\n",
      "Step 85: Average train loss: 0.0061\n",
      "Step 90: Average train loss: 0.0061\n",
      "Step 95: Average train loss: 0.0061\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 54980.58984375\n",
      "Step 0: Average train loss: 0.0069\n",
      "Step 5: Average train loss: 0.0069\n",
      "Step 10: Average train loss: 0.0069\n",
      "Step 15: Average train loss: 0.0069\n",
      "Step 20: Average train loss: 0.0069\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0068\n",
      "Step 40: Average train loss: 0.0068\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0068\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 57795.7734375\n",
      "Step 0: Average train loss: 0.0066\n",
      "Step 5: Average train loss: 0.0066\n",
      "Step 10: Average train loss: 0.0066\n",
      "Step 15: Average train loss: 0.0066\n",
      "Step 20: Average train loss: 0.0066\n",
      "Step 25: Average train loss: 0.0066\n",
      "Step 30: Average train loss: 0.0066\n",
      "Step 35: Average train loss: 0.0066\n",
      "Step 40: Average train loss: 0.0066\n",
      "Step 45: Average train loss: 0.0066\n",
      "Step 50: Average train loss: 0.0066\n",
      "Step 55: Average train loss: 0.0066\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 80970.578125\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([558, 24, 8]) torch.Size([140, 24, 8]) torch.Size([558, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0466 | Average test loss: 0.0260\n",
      "Step 5: Average train loss: 0.0194 | Average test loss: 0.0202\n",
      "Step 10: Average train loss: 0.0094 | Average test loss: 0.0081\n",
      "Step 15: Average train loss: 0.0091 | Average test loss: 0.0077\n",
      "Step 20: Average train loss: 0.0087 | Average test loss: 0.0074\n",
      "Step 25: Average train loss: 0.0085 | Average test loss: 0.0075\n",
      "Step 30: Average train loss: 0.0085 | Average test loss: 0.0076\n",
      "Step 35: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 40: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 45: Average train loss: 0.0083 | Average test loss: 0.0071\n",
      "Step 50: Average train loss: 0.0082 | Average test loss: 0.0070\n",
      "Step 55: Average train loss: 0.0081 | Average test loss: 0.0069\n",
      "Step 60: Average train loss: 0.0080 | Average test loss: 0.0067\n",
      "Step 65: Average train loss: 0.0078 | Average test loss: 0.0065\n",
      "Step 70: Average train loss: 0.0078 | Average test loss: 0.0066\n",
      "Step 75: Average train loss: 0.0078 | Average test loss: 0.0063\n",
      "Step 80: Average train loss: 0.0077 | Average test loss: 0.0065\n",
      "Step 85: Average train loss: 0.0078 | Average test loss: 0.0066\n",
      "Step 90: Average train loss: 0.0078 | Average test loss: 0.0066\n",
      "Step 95: Average train loss: 0.0076 | Average test loss: 0.0060\n",
      "Best Epoch: 94\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 56829.3671875\n",
      "Step 0: Average train loss: 0.0119\n",
      "Step 5: Average train loss: 0.0119\n",
      "Step 10: Average train loss: 0.0119\n",
      "Step 15: Average train loss: 0.0119\n",
      "Step 20: Average train loss: 0.0118\n",
      "Step 25: Average train loss: 0.0118\n",
      "Step 30: Average train loss: 0.0118\n",
      "Step 35: Average train loss: 0.0118\n",
      "Step 40: Average train loss: 0.0117\n",
      "Step 45: Average train loss: 0.0117\n",
      "Step 50: Average train loss: 0.0117\n",
      "Step 55: Average train loss: 0.0117\n",
      "Step 60: Average train loss: 0.0116\n",
      "Step 65: Average train loss: 0.0116\n",
      "Step 70: Average train loss: 0.0116\n",
      "Step 75: Average train loss: 0.0116\n",
      "Step 80: Average train loss: 0.0115\n",
      "Step 85: Average train loss: 0.0115\n",
      "Step 90: Average train loss: 0.0115\n",
      "Step 95: Average train loss: 0.0115\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 44497.58984375\n",
      "Step 0: Average train loss: 0.0100\n",
      "Step 5: Average train loss: 0.0100\n",
      "Step 10: Average train loss: 0.0099\n",
      "Step 15: Average train loss: 0.0099\n",
      "Step 20: Average train loss: 0.0099\n",
      "Step 25: Average train loss: 0.0098\n",
      "Step 30: Average train loss: 0.0098\n",
      "Step 35: Average train loss: 0.0098\n",
      "Step 40: Average train loss: 0.0097\n",
      "Step 45: Average train loss: 0.0097\n",
      "Step 50: Average train loss: 0.0097\n",
      "Step 55: Average train loss: 0.0096\n",
      "Step 60: Average train loss: 0.0096\n",
      "Step 65: Average train loss: 0.0096\n",
      "Step 70: Average train loss: 0.0095\n",
      "Step 75: Average train loss: 0.0095\n",
      "Step 80: Average train loss: 0.0095\n",
      "Step 85: Average train loss: 0.0095\n",
      "Step 90: Average train loss: 0.0094\n",
      "Step 95: Average train loss: 0.0094\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 52221.8984375\n",
      "Step 0: Average train loss: 0.0101\n",
      "Step 5: Average train loss: 0.0101\n",
      "Step 10: Average train loss: 0.0101\n",
      "Step 15: Average train loss: 0.0101\n",
      "Step 20: Average train loss: 0.0100\n",
      "Step 25: Average train loss: 0.0100\n",
      "Step 30: Average train loss: 0.0100\n",
      "Step 35: Average train loss: 0.0100\n",
      "Step 40: Average train loss: 0.0099\n",
      "Step 45: Average train loss: 0.0099\n",
      "Step 50: Average train loss: 0.0099\n",
      "Step 55: Average train loss: 0.0098\n",
      "Step 60: Average train loss: 0.0098\n",
      "Step 65: Average train loss: 0.0098\n",
      "Step 70: Average train loss: 0.0098\n",
      "Step 75: Average train loss: 0.0098\n",
      "Step 80: Average train loss: 0.0097\n",
      "Step 85: Average train loss: 0.0097\n",
      "Step 90: Average train loss: 0.0097\n",
      "Step 95: Average train loss: 0.0097\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 33641.23828125\n",
      "Step 0: Average train loss: 0.0087\n",
      "Step 5: Average train loss: 0.0087\n",
      "Step 10: Average train loss: 0.0087\n",
      "Step 15: Average train loss: 0.0087\n",
      "Step 20: Average train loss: 0.0086\n",
      "Step 25: Average train loss: 0.0086\n",
      "Step 30: Average train loss: 0.0086\n",
      "Step 35: Average train loss: 0.0086\n",
      "Step 40: Average train loss: 0.0085\n",
      "Step 45: Average train loss: 0.0085\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0084\n",
      "Step 75: Average train loss: 0.0084\n",
      "Step 80: Average train loss: 0.0084\n",
      "Step 85: Average train loss: 0.0084\n",
      "Step 90: Average train loss: 0.0083\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 35668.40625\n",
      "Step 0: Average train loss: 0.0080\n",
      "Step 5: Average train loss: 0.0079\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0079\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0079\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0078\n",
      "Step 55: Average train loss: 0.0078\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0077\n",
      "Step 75: Average train loss: 0.0077\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 23976.400390625\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0074\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 12949.861328125\n",
      "Step 0: Average train loss: 0.0063\n",
      "Step 5: Average train loss: 0.0063\n",
      "Step 10: Average train loss: 0.0063\n",
      "Step 15: Average train loss: 0.0063\n",
      "Step 20: Average train loss: 0.0063\n",
      "Step 25: Average train loss: 0.0063\n",
      "Step 30: Average train loss: 0.0063\n",
      "Step 35: Average train loss: 0.0063\n",
      "Step 40: Average train loss: 0.0063\n",
      "Step 45: Average train loss: 0.0063\n",
      "Step 50: Average train loss: 0.0063\n",
      "Step 55: Average train loss: 0.0063\n",
      "Step 60: Average train loss: 0.0063\n",
      "Step 65: Average train loss: 0.0063\n",
      "Step 70: Average train loss: 0.0063\n",
      "Step 75: Average train loss: 0.0063\n",
      "Step 80: Average train loss: 0.0063\n",
      "Step 85: Average train loss: 0.0063\n",
      "Step 90: Average train loss: 0.0063\n",
      "Step 95: Average train loss: 0.0063\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 8432.2763671875\n",
      "Step 0: Average train loss: 0.0053\n",
      "Step 5: Average train loss: 0.0053\n",
      "Step 10: Average train loss: 0.0053\n",
      "Step 15: Average train loss: 0.0053\n",
      "Step 20: Average train loss: 0.0053\n",
      "Step 25: Average train loss: 0.0053\n",
      "Step 30: Average train loss: 0.0053\n",
      "Step 35: Average train loss: 0.0053\n",
      "Step 40: Average train loss: 0.0053\n",
      "Step 45: Average train loss: 0.0053\n",
      "Step 50: Average train loss: 0.0053\n",
      "Step 55: Average train loss: 0.0053\n",
      "Step 60: Average train loss: 0.0053\n",
      "Step 65: Average train loss: 0.0053\n",
      "Step 70: Average train loss: 0.0053\n",
      "Step 75: Average train loss: 0.0053\n",
      "Step 80: Average train loss: 0.0053\n",
      "Step 85: Average train loss: 0.0053\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 11559.484375\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 14565.5927734375\n",
      "Step 0: Average train loss: 0.0052\n",
      "Step 5: Average train loss: 0.0052\n",
      "Step 10: Average train loss: 0.0052\n",
      "Step 15: Average train loss: 0.0052\n",
      "Step 20: Average train loss: 0.0052\n",
      "Step 25: Average train loss: 0.0052\n",
      "Step 30: Average train loss: 0.0052\n",
      "Step 35: Average train loss: 0.0052\n",
      "Step 40: Average train loss: 0.0052\n",
      "Step 45: Average train loss: 0.0052\n",
      "Step 50: Average train loss: 0.0051\n",
      "Step 55: Average train loss: 0.0051\n",
      "Step 60: Average train loss: 0.0051\n",
      "Step 65: Average train loss: 0.0051\n",
      "Step 70: Average train loss: 0.0051\n",
      "Step 75: Average train loss: 0.0051\n",
      "Step 80: Average train loss: 0.0051\n",
      "Step 85: Average train loss: 0.0051\n",
      "Step 90: Average train loss: 0.0051\n",
      "Step 95: Average train loss: 0.0051\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 45715.2265625\n",
      "Step 0: Average train loss: 0.0065\n",
      "Step 5: Average train loss: 0.0065\n",
      "Step 10: Average train loss: 0.0065\n",
      "Step 15: Average train loss: 0.0065\n",
      "Step 20: Average train loss: 0.0065\n",
      "Step 25: Average train loss: 0.0065\n",
      "Step 30: Average train loss: 0.0065\n",
      "Step 35: Average train loss: 0.0065\n",
      "Step 40: Average train loss: 0.0065\n",
      "Step 45: Average train loss: 0.0064\n",
      "Step 50: Average train loss: 0.0064\n",
      "Step 55: Average train loss: 0.0064\n",
      "Step 60: Average train loss: 0.0064\n",
      "Step 65: Average train loss: 0.0064\n",
      "Step 70: Average train loss: 0.0064\n",
      "Step 75: Average train loss: 0.0064\n",
      "Step 80: Average train loss: 0.0064\n",
      "Step 85: Average train loss: 0.0064\n",
      "Step 90: Average train loss: 0.0064\n",
      "Step 95: Average train loss: 0.0064\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 38997.33203125\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0059\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 33348.30859375\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([574, 24, 8]) torch.Size([144, 24, 8]) torch.Size([574, 24, 1]) torch.Size([144, 24, 1])\n",
      "Step 0: Average train loss: 0.0426 | Average test loss: 0.0335\n",
      "Step 5: Average train loss: 0.0075 | Average test loss: 0.0029\n",
      "Step 10: Average train loss: 0.0061 | Average test loss: 0.0018\n",
      "Step 15: Average train loss: 0.0056 | Average test loss: 0.0017\n",
      "Step 20: Average train loss: 0.0054 | Average test loss: 0.0017\n",
      "Step 25: Average train loss: 0.0053 | Average test loss: 0.0017\n",
      "Step 30: Average train loss: 0.0052 | Average test loss: 0.0018\n",
      "Step 35: Average train loss: 0.0051 | Average test loss: 0.0018\n",
      "Step 40: Average train loss: 0.0050 | Average test loss: 0.0019\n",
      "Step 45: Average train loss: 0.0050 | Average test loss: 0.0020\n",
      "Step 50: Average train loss: 0.0050 | Average test loss: 0.0021\n",
      "Step 55: Average train loss: 0.0049 | Average test loss: 0.0022\n",
      "Step 60: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 65: Average train loss: 0.0049 | Average test loss: 0.0023\n",
      "Step 70: Average train loss: 0.0048 | Average test loss: 0.0023\n",
      "Step 75: Average train loss: 0.0048 | Average test loss: 0.0023\n",
      "Step 80: Average train loss: 0.0048 | Average test loss: 0.0024\n",
      "Step 85: Average train loss: 0.0047 | Average test loss: 0.0024\n",
      "Step 90: Average train loss: 0.0047 | Average test loss: 0.0025\n",
      "Step 95: Average train loss: 0.0047 | Average test loss: 0.0026\n",
      "Best Epoch: 17\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 304459.75\n",
      "Step 0: Average train loss: 0.0161\n",
      "Step 5: Average train loss: 0.0161\n",
      "Step 10: Average train loss: 0.0161\n",
      "Step 15: Average train loss: 0.0161\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0161\n",
      "Step 30: Average train loss: 0.0161\n",
      "Step 35: Average train loss: 0.0161\n",
      "Step 40: Average train loss: 0.0161\n",
      "Step 45: Average train loss: 0.0160\n",
      "Step 50: Average train loss: 0.0160\n",
      "Step 55: Average train loss: 0.0160\n",
      "Step 60: Average train loss: 0.0160\n",
      "Step 65: Average train loss: 0.0160\n",
      "Step 70: Average train loss: 0.0160\n",
      "Step 75: Average train loss: 0.0160\n",
      "Step 80: Average train loss: 0.0160\n",
      "Step 85: Average train loss: 0.0160\n",
      "Step 90: Average train loss: 0.0160\n",
      "Step 95: Average train loss: 0.0160\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 299822.75\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0158\n",
      "Step 20: Average train loss: 0.0158\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0157\n",
      "Step 35: Average train loss: 0.0157\n",
      "Step 40: Average train loss: 0.0157\n",
      "Step 45: Average train loss: 0.0157\n",
      "Step 50: Average train loss: 0.0157\n",
      "Step 55: Average train loss: 0.0157\n",
      "Step 60: Average train loss: 0.0157\n",
      "Step 65: Average train loss: 0.0157\n",
      "Step 70: Average train loss: 0.0157\n",
      "Step 75: Average train loss: 0.0156\n",
      "Step 80: Average train loss: 0.0156\n",
      "Step 85: Average train loss: 0.0156\n",
      "Step 90: Average train loss: 0.0156\n",
      "Step 95: Average train loss: 0.0156\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 256214.9375\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0150\n",
      "Step 10: Average train loss: 0.0150\n",
      "Step 15: Average train loss: 0.0149\n",
      "Step 20: Average train loss: 0.0149\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0149\n",
      "Step 50: Average train loss: 0.0149\n",
      "Step 55: Average train loss: 0.0149\n",
      "Step 60: Average train loss: 0.0148\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0148\n",
      "Step 90: Average train loss: 0.0148\n",
      "Step 95: Average train loss: 0.0148\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 287599.5\n",
      "Step 0: Average train loss: 0.0150\n",
      "Step 5: Average train loss: 0.0149\n",
      "Step 10: Average train loss: 0.0149\n",
      "Step 15: Average train loss: 0.0149\n",
      "Step 20: Average train loss: 0.0149\n",
      "Step 25: Average train loss: 0.0149\n",
      "Step 30: Average train loss: 0.0149\n",
      "Step 35: Average train loss: 0.0149\n",
      "Step 40: Average train loss: 0.0149\n",
      "Step 45: Average train loss: 0.0148\n",
      "Step 50: Average train loss: 0.0148\n",
      "Step 55: Average train loss: 0.0148\n",
      "Step 60: Average train loss: 0.0148\n",
      "Step 65: Average train loss: 0.0148\n",
      "Step 70: Average train loss: 0.0148\n",
      "Step 75: Average train loss: 0.0148\n",
      "Step 80: Average train loss: 0.0148\n",
      "Step 85: Average train loss: 0.0147\n",
      "Step 90: Average train loss: 0.0147\n",
      "Step 95: Average train loss: 0.0147\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 284289.1875\n",
      "Step 0: Average train loss: 0.0147\n",
      "Step 5: Average train loss: 0.0147\n",
      "Step 10: Average train loss: 0.0147\n",
      "Step 15: Average train loss: 0.0147\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0146\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0146\n",
      "Step 50: Average train loss: 0.0146\n",
      "Step 55: Average train loss: 0.0146\n",
      "Step 60: Average train loss: 0.0146\n",
      "Step 65: Average train loss: 0.0146\n",
      "Step 70: Average train loss: 0.0146\n",
      "Step 75: Average train loss: 0.0146\n",
      "Step 80: Average train loss: 0.0146\n",
      "Step 85: Average train loss: 0.0145\n",
      "Step 90: Average train loss: 0.0145\n",
      "Step 95: Average train loss: 0.0145\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 303375.59375\n",
      "Step 0: Average train loss: 0.0148\n",
      "Step 5: Average train loss: 0.0148\n",
      "Step 10: Average train loss: 0.0148\n",
      "Step 15: Average train loss: 0.0148\n",
      "Step 20: Average train loss: 0.0147\n",
      "Step 25: Average train loss: 0.0147\n",
      "Step 30: Average train loss: 0.0147\n",
      "Step 35: Average train loss: 0.0147\n",
      "Step 40: Average train loss: 0.0147\n",
      "Step 45: Average train loss: 0.0147\n",
      "Step 50: Average train loss: 0.0147\n",
      "Step 55: Average train loss: 0.0147\n",
      "Step 60: Average train loss: 0.0147\n",
      "Step 65: Average train loss: 0.0147\n",
      "Step 70: Average train loss: 0.0147\n",
      "Step 75: Average train loss: 0.0147\n",
      "Step 80: Average train loss: 0.0147\n",
      "Step 85: Average train loss: 0.0146\n",
      "Step 90: Average train loss: 0.0146\n",
      "Step 95: Average train loss: 0.0146\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 200664.578125\n",
      "Step 0: Average train loss: 0.0137\n",
      "Step 5: Average train loss: 0.0137\n",
      "Step 10: Average train loss: 0.0137\n",
      "Step 15: Average train loss: 0.0137\n",
      "Step 20: Average train loss: 0.0137\n",
      "Step 25: Average train loss: 0.0137\n",
      "Step 30: Average train loss: 0.0137\n",
      "Step 35: Average train loss: 0.0137\n",
      "Step 40: Average train loss: 0.0137\n",
      "Step 45: Average train loss: 0.0136\n",
      "Step 50: Average train loss: 0.0136\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0136\n",
      "Step 65: Average train loss: 0.0136\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0136\n",
      "Step 85: Average train loss: 0.0136\n",
      "Step 90: Average train loss: 0.0136\n",
      "Step 95: Average train loss: 0.0136\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 293126.96875\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0142\n",
      "Step 35: Average train loss: 0.0141\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0141\n",
      "Step 85: Average train loss: 0.0141\n",
      "Step 90: Average train loss: 0.0140\n",
      "Step 95: Average train loss: 0.0140\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 304233.96875\n",
      "Step 0: Average train loss: 0.0142\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0142\n",
      "Step 20: Average train loss: 0.0142\n",
      "Step 25: Average train loss: 0.0142\n",
      "Step 30: Average train loss: 0.0142\n",
      "Step 35: Average train loss: 0.0142\n",
      "Step 40: Average train loss: 0.0141\n",
      "Step 45: Average train loss: 0.0141\n",
      "Step 50: Average train loss: 0.0141\n",
      "Step 55: Average train loss: 0.0141\n",
      "Step 60: Average train loss: 0.0141\n",
      "Step 65: Average train loss: 0.0141\n",
      "Step 70: Average train loss: 0.0141\n",
      "Step 75: Average train loss: 0.0141\n",
      "Step 80: Average train loss: 0.0141\n",
      "Step 85: Average train loss: 0.0141\n",
      "Step 90: Average train loss: 0.0141\n",
      "Step 95: Average train loss: 0.0141\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 412949.78125\n",
      "Step 0: Average train loss: 0.0154\n",
      "Step 5: Average train loss: 0.0153\n",
      "Step 10: Average train loss: 0.0153\n",
      "Step 15: Average train loss: 0.0153\n",
      "Step 20: Average train loss: 0.0153\n",
      "Step 25: Average train loss: 0.0153\n",
      "Step 30: Average train loss: 0.0153\n",
      "Step 35: Average train loss: 0.0153\n",
      "Step 40: Average train loss: 0.0153\n",
      "Step 45: Average train loss: 0.0153\n",
      "Step 50: Average train loss: 0.0153\n",
      "Step 55: Average train loss: 0.0153\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0152\n",
      "Step 75: Average train loss: 0.0152\n",
      "Step 80: Average train loss: 0.0152\n",
      "Step 85: Average train loss: 0.0152\n",
      "Step 90: Average train loss: 0.0152\n",
      "Step 95: Average train loss: 0.0152\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 422137.4375\n",
      "Step 0: Average train loss: 0.0163\n",
      "Step 5: Average train loss: 0.0163\n",
      "Step 10: Average train loss: 0.0163\n",
      "Step 15: Average train loss: 0.0163\n",
      "Step 20: Average train loss: 0.0163\n",
      "Step 25: Average train loss: 0.0163\n",
      "Step 30: Average train loss: 0.0163\n",
      "Step 35: Average train loss: 0.0163\n",
      "Step 40: Average train loss: 0.0163\n",
      "Step 45: Average train loss: 0.0162\n",
      "Step 50: Average train loss: 0.0162\n",
      "Step 55: Average train loss: 0.0162\n",
      "Step 60: Average train loss: 0.0162\n",
      "Step 65: Average train loss: 0.0162\n",
      "Step 70: Average train loss: 0.0162\n",
      "Step 75: Average train loss: 0.0162\n",
      "Step 80: Average train loss: 0.0162\n",
      "Step 85: Average train loss: 0.0162\n",
      "Step 90: Average train loss: 0.0162\n",
      "Step 95: Average train loss: 0.0162\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 384938.21875\n",
      "Step 0: Average train loss: 0.0158\n",
      "Step 5: Average train loss: 0.0158\n",
      "Step 10: Average train loss: 0.0158\n",
      "Step 15: Average train loss: 0.0158\n",
      "Step 20: Average train loss: 0.0158\n",
      "Step 25: Average train loss: 0.0158\n",
      "Step 30: Average train loss: 0.0158\n",
      "Step 35: Average train loss: 0.0158\n",
      "Step 40: Average train loss: 0.0158\n",
      "Step 45: Average train loss: 0.0158\n",
      "Step 50: Average train loss: 0.0158\n",
      "Step 55: Average train loss: 0.0158\n",
      "Step 60: Average train loss: 0.0158\n",
      "Step 65: Average train loss: 0.0158\n",
      "Step 70: Average train loss: 0.0158\n",
      "Step 75: Average train loss: 0.0158\n",
      "Step 80: Average train loss: 0.0158\n",
      "Step 85: Average train loss: 0.0157\n",
      "Step 90: Average train loss: 0.0157\n",
      "Step 95: Average train loss: 0.0157\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 560901.3125\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([562, 24, 8]) torch.Size([140, 24, 8]) torch.Size([562, 24, 1]) torch.Size([140, 24, 1])\n",
      "Step 0: Average train loss: 0.0394 | Average test loss: 0.0230\n",
      "Step 5: Average train loss: 0.0137 | Average test loss: 0.0177\n",
      "Step 10: Average train loss: 0.0095 | Average test loss: 0.0087\n",
      "Step 15: Average train loss: 0.0098 | Average test loss: 0.0095\n",
      "Step 20: Average train loss: 0.0095 | Average test loss: 0.0083\n",
      "Step 25: Average train loss: 0.0094 | Average test loss: 0.0086\n",
      "Step 30: Average train loss: 0.0094 | Average test loss: 0.0084\n",
      "Step 35: Average train loss: 0.0094 | Average test loss: 0.0089\n",
      "Step 40: Average train loss: 0.0090 | Average test loss: 0.0080\n",
      "Step 45: Average train loss: 0.0093 | Average test loss: 0.0083\n",
      "Step 50: Average train loss: 0.0087 | Average test loss: 0.0077\n",
      "Step 55: Average train loss: 0.0096 | Average test loss: 0.0094\n",
      "Step 60: Average train loss: 0.0088 | Average test loss: 0.0077\n",
      "Step 65: Average train loss: 0.0085 | Average test loss: 0.0074\n",
      "Step 70: Average train loss: 0.0087 | Average test loss: 0.0079\n",
      "Step 75: Average train loss: 0.0084 | Average test loss: 0.0078\n",
      "Step 80: Average train loss: 0.0085 | Average test loss: 0.0075\n",
      "Step 85: Average train loss: 0.0085 | Average test loss: 0.0075\n",
      "Step 90: Average train loss: 0.0081 | Average test loss: 0.0073\n",
      "Step 95: Average train loss: 0.0081 | Average test loss: 0.0073\n",
      "Best Epoch: 93\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 69264.28125\n",
      "Step 0: Average train loss: 0.0182\n",
      "Step 5: Average train loss: 0.0182\n",
      "Step 10: Average train loss: 0.0182\n",
      "Step 15: Average train loss: 0.0182\n",
      "Step 20: Average train loss: 0.0181\n",
      "Step 25: Average train loss: 0.0181\n",
      "Step 30: Average train loss: 0.0181\n",
      "Step 35: Average train loss: 0.0181\n",
      "Step 40: Average train loss: 0.0180\n",
      "Step 45: Average train loss: 0.0180\n",
      "Step 50: Average train loss: 0.0180\n",
      "Step 55: Average train loss: 0.0180\n",
      "Step 60: Average train loss: 0.0179\n",
      "Step 65: Average train loss: 0.0179\n",
      "Step 70: Average train loss: 0.0179\n",
      "Step 75: Average train loss: 0.0179\n",
      "Step 80: Average train loss: 0.0178\n",
      "Step 85: Average train loss: 0.0178\n",
      "Step 90: Average train loss: 0.0178\n",
      "Step 95: Average train loss: 0.0178\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 66671.953125\n",
      "Step 0: Average train loss: 0.0170\n",
      "Step 5: Average train loss: 0.0170\n",
      "Step 10: Average train loss: 0.0169\n",
      "Step 15: Average train loss: 0.0169\n",
      "Step 20: Average train loss: 0.0169\n",
      "Step 25: Average train loss: 0.0168\n",
      "Step 30: Average train loss: 0.0168\n",
      "Step 35: Average train loss: 0.0167\n",
      "Step 40: Average train loss: 0.0167\n",
      "Step 45: Average train loss: 0.0167\n",
      "Step 50: Average train loss: 0.0166\n",
      "Step 55: Average train loss: 0.0166\n",
      "Step 60: Average train loss: 0.0165\n",
      "Step 65: Average train loss: 0.0165\n",
      "Step 70: Average train loss: 0.0165\n",
      "Step 75: Average train loss: 0.0164\n",
      "Step 80: Average train loss: 0.0164\n",
      "Step 85: Average train loss: 0.0164\n",
      "Step 90: Average train loss: 0.0163\n",
      "Step 95: Average train loss: 0.0163\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 51524.5390625\n",
      "Step 0: Average train loss: 0.0157\n",
      "Step 5: Average train loss: 0.0157\n",
      "Step 10: Average train loss: 0.0157\n",
      "Step 15: Average train loss: 0.0156\n",
      "Step 20: Average train loss: 0.0156\n",
      "Step 25: Average train loss: 0.0156\n",
      "Step 30: Average train loss: 0.0155\n",
      "Step 35: Average train loss: 0.0155\n",
      "Step 40: Average train loss: 0.0154\n",
      "Step 45: Average train loss: 0.0154\n",
      "Step 50: Average train loss: 0.0154\n",
      "Step 55: Average train loss: 0.0153\n",
      "Step 60: Average train loss: 0.0153\n",
      "Step 65: Average train loss: 0.0153\n",
      "Step 70: Average train loss: 0.0152\n",
      "Step 75: Average train loss: 0.0152\n",
      "Step 80: Average train loss: 0.0152\n",
      "Step 85: Average train loss: 0.0151\n",
      "Step 90: Average train loss: 0.0151\n",
      "Step 95: Average train loss: 0.0151\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 48192.4765625\n",
      "Step 0: Average train loss: 0.0143\n",
      "Step 5: Average train loss: 0.0142\n",
      "Step 10: Average train loss: 0.0142\n",
      "Step 15: Average train loss: 0.0141\n",
      "Step 20: Average train loss: 0.0141\n",
      "Step 25: Average train loss: 0.0140\n",
      "Step 30: Average train loss: 0.0140\n",
      "Step 35: Average train loss: 0.0139\n",
      "Step 40: Average train loss: 0.0139\n",
      "Step 45: Average train loss: 0.0139\n",
      "Step 50: Average train loss: 0.0138\n",
      "Step 55: Average train loss: 0.0138\n",
      "Step 60: Average train loss: 0.0137\n",
      "Step 65: Average train loss: 0.0137\n",
      "Step 70: Average train loss: 0.0136\n",
      "Step 75: Average train loss: 0.0136\n",
      "Step 80: Average train loss: 0.0135\n",
      "Step 85: Average train loss: 0.0135\n",
      "Step 90: Average train loss: 0.0135\n",
      "Step 95: Average train loss: 0.0134\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 32585.72265625\n",
      "Step 0: Average train loss: 0.0118\n",
      "Step 5: Average train loss: 0.0117\n",
      "Step 10: Average train loss: 0.0117\n",
      "Step 15: Average train loss: 0.0116\n",
      "Step 20: Average train loss: 0.0116\n",
      "Step 25: Average train loss: 0.0115\n",
      "Step 30: Average train loss: 0.0115\n",
      "Step 35: Average train loss: 0.0114\n",
      "Step 40: Average train loss: 0.0114\n",
      "Step 45: Average train loss: 0.0113\n",
      "Step 50: Average train loss: 0.0113\n",
      "Step 55: Average train loss: 0.0112\n",
      "Step 60: Average train loss: 0.0112\n",
      "Step 65: Average train loss: 0.0111\n",
      "Step 70: Average train loss: 0.0111\n",
      "Step 75: Average train loss: 0.0110\n",
      "Step 80: Average train loss: 0.0110\n",
      "Step 85: Average train loss: 0.0110\n",
      "Step 90: Average train loss: 0.0109\n",
      "Step 95: Average train loss: 0.0109\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 34694.19140625\n",
      "Step 0: Average train loss: 0.0112\n",
      "Step 5: Average train loss: 0.0111\n",
      "Step 10: Average train loss: 0.0111\n",
      "Step 15: Average train loss: 0.0110\n",
      "Step 20: Average train loss: 0.0110\n",
      "Step 25: Average train loss: 0.0110\n",
      "Step 30: Average train loss: 0.0109\n",
      "Step 35: Average train loss: 0.0109\n",
      "Step 40: Average train loss: 0.0108\n",
      "Step 45: Average train loss: 0.0108\n",
      "Step 50: Average train loss: 0.0108\n",
      "Step 55: Average train loss: 0.0107\n",
      "Step 60: Average train loss: 0.0107\n",
      "Step 65: Average train loss: 0.0107\n",
      "Step 70: Average train loss: 0.0106\n",
      "Step 75: Average train loss: 0.0106\n",
      "Step 80: Average train loss: 0.0105\n",
      "Step 85: Average train loss: 0.0105\n",
      "Step 90: Average train loss: 0.0105\n",
      "Step 95: Average train loss: 0.0104\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 25985.560546875\n",
      "Step 0: Average train loss: 0.0097\n",
      "Step 5: Average train loss: 0.0097\n",
      "Step 10: Average train loss: 0.0096\n",
      "Step 15: Average train loss: 0.0096\n",
      "Step 20: Average train loss: 0.0096\n",
      "Step 25: Average train loss: 0.0096\n",
      "Step 30: Average train loss: 0.0095\n",
      "Step 35: Average train loss: 0.0095\n",
      "Step 40: Average train loss: 0.0095\n",
      "Step 45: Average train loss: 0.0094\n",
      "Step 50: Average train loss: 0.0094\n",
      "Step 55: Average train loss: 0.0094\n",
      "Step 60: Average train loss: 0.0093\n",
      "Step 65: Average train loss: 0.0093\n",
      "Step 70: Average train loss: 0.0093\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0092\n",
      "Step 85: Average train loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092\n",
      "Step 95: Average train loss: 0.0092\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 14674.171875\n",
      "Step 0: Average train loss: 0.0080\n",
      "Step 5: Average train loss: 0.0080\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0079\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0078\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0078\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0077\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0076\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 17193.77734375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0076\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0075\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0074\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0073\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0072\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 22006.974609375\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0068\n",
      "Step 50: Average train loss: 0.0068\n",
      "Step 55: Average train loss: 0.0068\n",
      "Step 60: Average train loss: 0.0068\n",
      "Step 65: Average train loss: 0.0067\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0067\n",
      "Step 80: Average train loss: 0.0067\n",
      "Step 85: Average train loss: 0.0067\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 31828.986328125\n",
      "Step 0: Average train loss: 0.0069\n",
      "Step 5: Average train loss: 0.0069\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0068\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n",
      "Step 60: Average train loss: 0.0066\n",
      "Step 65: Average train loss: 0.0066\n",
      "Step 70: Average train loss: 0.0066\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0065\n",
      "Step 90: Average train loss: 0.0065\n",
      "Step 95: Average train loss: 0.0065\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 28419.140625\n"
     ]
    }
   ],
   "source": [
    "warnings. filterwarnings('ignore') \n",
    "for site in sites:\n",
    "    dataset_name = \"nwp\"\n",
    "    phys=True\n",
    "    source_data, _, eval_data = data_handeler(site, 'nwp', 'nwp', 'nwp', decomp=True);\n",
    "    ftr_file='features/ft_phys.pkl'\n",
    "\n",
    "\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        features = pickle.load(f)\n",
    "    scale = Scale()\n",
    "    scale.load(site, dataset_name, phys)\n",
    "\n",
    "    hp = hyperparameters_source()\n",
    "    hp.load(model)\n",
    "\n",
    "\n",
    "    accuracy, state_dict, timer = source(source_data, features, hp, scale);\n",
    "\n",
    "    hp = hyperparameters_target()\n",
    "    hp.load(model)\n",
    "    hp.source_state_dict = state_dict\n",
    "    accur, timer, forecasts = target(eval_data, features, hp, scale, WFE = True);\n",
    "    rmse.loc[(6, slice(len(accur)-1)),site] = accur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208.705463</td>\n",
       "      <td>174.537122</td>\n",
       "      <td>558.925574</td>\n",
       "      <td>193.606811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>210.809443</td>\n",
       "      <td>177.056246</td>\n",
       "      <td>558.312261</td>\n",
       "      <td>196.365235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>209.488528</td>\n",
       "      <td>172.579986</td>\n",
       "      <td>559.99105</td>\n",
       "      <td>186.733048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211.101287</td>\n",
       "      <td>175.709857</td>\n",
       "      <td>559.065218</td>\n",
       "      <td>195.548412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209.350613</td>\n",
       "      <td>175.752439</td>\n",
       "      <td>559.697938</td>\n",
       "      <td>205.044143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>212.177251</td>\n",
       "      <td>177.836177</td>\n",
       "      <td>557.451531</td>\n",
       "      <td>184.878216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209.517709</td>\n",
       "      <td>177.757179</td>\n",
       "      <td>560.52506</td>\n",
       "      <td>192.584326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3\n",
       "0  208.705463  174.537122  558.925574  193.606811\n",
       "1  210.809443  177.056246  558.312261  196.365235\n",
       "2  209.488528  172.579986   559.99105  186.733048\n",
       "3  211.101287  175.709857  559.065218  195.548412\n",
       "4  209.350613  175.752439  559.697938  205.044143\n",
       "5  212.177251  177.836177  557.451531  184.878216\n",
       "6  209.517709  177.757179   560.52506  192.584326"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-physics-informed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the Random Forest to determine importances of all features and then put the; in this order of importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (12582, 13)\n",
      "Training Labels Shape: (12582,)\n",
      "Testing Features Shape: (4194, 13)\n",
      "Testing Labels Shape: (4194,)\n",
      "238.62298480319606 W\n",
      "Variable: downward_surface_SW_flux Importance: 0.81\n",
      "Variable: P_24h_shift          Importance: 0.03\n",
      "Variable: direct_surface_SW_flux Importance: 0.03\n",
      "Variable: hour_cos             Importance: 0.03\n",
      "Variable: diffuse_surface_SW_flux Importance: 0.02\n",
      "Variable: relative_humidity_1_5m Importance: 0.02\n",
      "Variable: temperature_1_5m     Importance: 0.02\n",
      "Variable: wind_speed_10m       Importance: 0.02\n",
      "Variable: pressure_MSL         Importance: 0.02\n",
      "Variable: hour_sin             Importance: 0.01\n",
      "Variable: month_cos            Importance: 0.01\n",
      "Variable: total_cloud_amount   Importance: 0.01\n",
      "Variable: month_sin            Importance: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "installation_int = 0\n",
    "source_data,_,_ = data_handeler(installation_int, \"nwp\", \"nwp\", \"nwp\")\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(source_data['P'])\n",
    "# Remove the labels from the source_data\n",
    "# axis 1 refers to the columns\n",
    "source_data= source_data.drop('P', axis = 1)\n",
    "# Saving feature names for later use\n",
    "ftr_file = \"features/ft_no_phys_sa.pkl\"\n",
    "if os.path.isfile(ftr_file):\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        feature_list = pickle.load(f)\n",
    "# Convert to numpy array\n",
    "source_data = source_data[feature_list]\n",
    "source_data = np.array(source_data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(source_data, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "#Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = np.sqrt(np.mean(np.square(predictions - test_labels)))\n",
    "# Print out rmse\n",
    "print(errors, 'W')\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_np = pd.read_pickle(\"sensitivity_analysis/nb_features/rmse_no_physics.pkl\")\n",
    "zs_rmse_np = rmse_np.loc[(slice(None), 0),:]\n",
    "zs_rmse_np = zs_rmse_np.droplevel(1)\n",
    "for site in range(4):\n",
    "    plt.figure()\n",
    "    plt.plot(zs_rmse_np[site])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics-informed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Training Features Shape: (12582, 16)\n",
      "Training Labels Shape: (12582,)\n",
      "Testing Features Shape: (4194, 16)\n",
      "Testing Labels Shape: (4194,)\n",
      "241.21926501974775 W\n",
      "Variable: PoA                  Importance: 0.81\n",
      "Variable: P_24h_shift          Importance: 0.03\n",
      "Variable: downward_surface_SW_flux Importance: 0.03\n",
      "Variable: diffuse_surface_SW_flux Importance: 0.02\n",
      "Variable: T_PV                 Importance: 0.02\n",
      "Variable: wind_speed_10m       Importance: 0.02\n",
      "Variable: relative_humidity_1_5m Importance: 0.01\n",
      "Variable: direct_surface_SW_flux Importance: 0.01\n",
      "Variable: month_sin            Importance: 0.01\n",
      "Variable: hour_sin             Importance: 0.01\n",
      "Variable: temperature_1_5m     Importance: 0.01\n",
      "Variable: pressure_MSL         Importance: 0.01\n",
      "Variable: is_day               Importance: 0.0\n",
      "Variable: month_cos            Importance: 0.0\n",
      "Variable: hour_cos             Importance: 0.0\n",
      "Variable: total_cloud_amount   Importance: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "installation_int = 0\n",
    "source_data,_,_ = data_handeler(installation_int, \"nwp\", \"nwp\", \"nwp\")\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(source_data['P'])\n",
    "# Remove the labels from the source_data\n",
    "# axis 1 refers to the columns\n",
    "source_data= source_data.drop('P', axis = 1)\n",
    "# Saving feature names for later use\n",
    "ftr_file = \"features/ft_phys_sa.pkl\"\n",
    "if os.path.isfile(ftr_file):\n",
    "    with open(ftr_file, 'rb') as f:\n",
    "        feature_list = pickle.load(f)\n",
    "# Convert to numpy array\n",
    "source_data = source_data[feature_list]\n",
    "source_data = np.array(source_data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(source_data, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)\n",
    "\n",
    "#Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels)\n",
    "\n",
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "# Calculate the absolute errors\n",
    "errors = np.sqrt(np.mean(np.square(predictions - test_labels)))\n",
    "# Print out rmse\n",
    "print(errors, 'W')\n",
    "# Get numerical feature importances\n",
    "importances = list(rf.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(feature_list, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances \n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATIAAADlCAYAAADQinvmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAk6UlEQVR4nO3deVwTd/4/8Fe4LzFEuUUwXqDiEcEb6oHXWqltg93Yte12K3Vrf7XdWtPWXtuLQu297RZp99uuW1HAVrFVLNHWW4sERKkKJYoY8AwRFZRrfn/YpAQSCOSYmfB+Ph59FDKTz7wZwsuZz3w+MwKGYRgQQgiPObFdACGEWIqCjBDCexRkhBDeoyAjhPCeC5sbHzlyJAYPHgy1Wo3Q0NAu1zdnPWqL2qK2HL+tiooKlJaW/rGQYdHChQsN/m/u+pauQ21RW9QWv9tqvz4nTi1lMpnd2zJnPWu2ZS5710X7vntt0b7v/nrWaqvTdcyKSxsxN617uj6X8Ll2huF3/XyunWH4Xb+taufkEZm5rPkvgL3xuXaA3/XzuXaA3/Xbq3YBw7A3sj8xMRG5ublsbZ4QwlPts4NXR2SEEGIMBRkhhPd6ZZC9m3sCWQfPsl0GIcRKel2QNTQ2Y21uKf6df5rtUgghVsJqkKnVaiQmJiIzM9Nu29x38hLqG1tQdEaD6w1NdtsuIcRymZmZSExMhFqtNnid1SALDQ1Fbm6uXS8v5xWr4evpipZWBofLL9ttu4QQy8lkMuTm5naYztSrTi0ZhkFesRqyqYMQ2NcD+05eYrskQogVsDpp3N5+PX8NVVfrMX9cKK7euI19py6yXRIhxAp61RHZjmI1vN1dMC0yAHGRAdRPRoiD6FVBllesxsxRQXB3dUZcVCD1kxHiIHpNkF25fgu//HYFc8fe6SQcEtQHQUJP6icjxAH0miBTlNSAYYC5Y0IAAAKBAHGRAdRPRogD6DVBlleshmSQCEFCT/1r06ICqZ+MEAfQK4KsqbkViuM1mDfWcOxJXGQA9ZMR4gB6xcj+w+WXca2+qUOQ6frJ9p6k00tC+MDUyH5Wx5HpRvbb2o5iNYKEnhgT7mfwuq6fbD91+BPCCzKZDDKZDImJiQav94pTy7ziaswdEwInJ0GHZdOiAlF0VoM66icjhLccPsh+u1CH8pq6DqeVOvp+sjLqJyOErxw+yHYWV8Pd1QnTRwYaXa4fT0bDMAjhLYcPsrxiNeKjAuHj4Wp0OfWTEcJ/Dh1kdQ1N2H/6ksnTSp046icjhNccOsh2H69BcwujH81vSlwU9ZMRwmcOHWQ7itUYMaAvwv19Ol1vcGAfBPtRPxkhfOWwQdbayuDHY9WYO6bz00qA+skI4TuHHdlfeOYqrly/jXljOz+t1JkWSf1khHBdr7tnf16RGn7ebpgwpL9Z61M/GSHc1+vu2Z9XXI05Y0Lg4mzej6jrJ6N5l4Twj0MGmVpTj5JztWafVgJt+smow58Q3nHIINtZrIazkwCzos0PMuD3frIztdRPRgjPOGSQ7ShWY/Iwf/h5u3XrfXFRAWhlGBwqo6uXhPCJwwVZ/e1m/Fx6scvR/Mbox5PRMAxCeMXhgmzvyYu41dTSrf4xHYFAgPioQOonI4RnHC7I8orVEAf4YFiwb4/ePy0ygPrJCOEZhwoyhmGQV1yNeWNDIRB0vImiOeKiAqmfjBCecaiR/SeqtFBr6nvUP6YjDvBBCPWTEcJJveKe/XnFavh4uGBqpH+P2xAIBIijfjJCOKlX3LN/R5Eas6KD4ebibFE71E9GCL84TJBdrruFo6qrXd57zBzUT0YIvzhMkOWXVINhYJUgo34yQvjFYYIsr7gaMeJ+COjraXFbun6yfTSBnBBeMNnZr1QqoVAoAAAFBQXIyMiAUCg0WL5s2TIUFhYavE+lUiEnJwdisRgqlQrJyckG77OFxuYW7Dpeg6fmR1qtzWmRAcg+VIlr9Y3o69W9qU6EEPsyGWQKhQKrV68GAKSlpWHWrFn60NIFlVKp7PC+pKQk/XoqlQrLli1Ddna2LWrXO1R2GXUNTRYNu2jvj36yy1ZtlxBifUZPLZVKJVJSUvTfS6VSKJVKqFQq/fcSiaTD+3TLdcRisf6ozpZ2FKkR7OeJ0eF+VmuT+skI4Q+jQSaRSJCRkaH/XqvVAgBEIlGnjSkUig7riEQio0du1mTpaH5jaN4lIfxhsrNfKpXqv960aRMSEhK67OvSBV57Go2mR8WZo7ymDhUXr/doknhXpkUFovhsLa7VN1q9bUKI9XQ5sl+r1SInJ6dDp353mAo43RQlHd2o3e7IK1bDw9UZ00cE9bg+U+IiA6ifjBAOyMzMNJjK2O0pSnK5HPn5+WZdeRQKhR2OvjQajcn3WmOKUl5xNeJHBMLL3fqzrQYF+CBU5IV9J7t+WjkhxHbaH+R0a4pSWloa5HI5xGIxtFqtySMrnYSEBKOvx8TEmFlu92hvNuJg2SXMt1HI0H38CeEHk0GWk5MDiUSiD7GsrCyjR1Ztw00sFhssU6lUiImJsdk4st0natDcwlhlNL8p1E9GCPcZPR9TqVRISkoyeE0oFCI5ORnAnauT+fn5AICUlBTExsbqLw5kZ2dDLpcjNjYWBQUFNh1DllesxqgwIcL6e9tsG9RPRgj3CRiGYdjaeGJiYo/7yFpaWyF+8js8OmMIXk0aY+XK/sAwDKKe2Yr7J4bjLdk4m22HEGK+9tnB27mWRyuuQnPjNubaYNhFW7p+Mpp3SQh38TbI8oqrIfJxR+zgfjbf1rSoQByrrIX2JvWTEcJFPA4yNeaOCYazk+1/hLb9ZIQQ7uFlkFVduYkTVVq7db4PCvDBAJEX9tEwDEI4iZcPH9l5rBouzgLMHBVso8oM3bk/WQD20wRyQlhl6uEjrAaZbmR/d6cl7ShWY8qwAAi97XefsGmR1E9GCNtkMhlyc3MRGmp4Nsa7U8ubt5ux59cLNpkk3pm29ycjhHAL74Jsz68XcLup1e6DUyP8vamfjBCO4l2Q5RVXY3BgHwwN9rXrdqmfjBDu4lWQMQyDvGK13U8rdaifjBBu4lWQlVTWoqa2AfPHsTPnkfrJCOEmXgVZXrEavp6umDzMn5XtUz8ZIdzEsyCrxqzoYLi5OLOyfV0/Gc27JIRbeBNkl6414Kjqqk3vPWYO6icjhHt4M7L/x5IaCATAHJaDLH5EIBgGOFhGVy8JsTfej+zPK1YjRtwP/r4edqjMtPD+3gjr50XPuySEBaZG9lv/iR02cldUIHy9XNkuAwKBANMi6XmXhHAJb4JsWcIwtkvQi4sKwMaDZ6C92WjX+Z6EEON409nPJXFR1E9GCJdQkPUA9ZMRwi0UZD1A/WSEcAsFWQ/FRQXQeDJCOIKCrIeon4wQ7qAg6yHqJyOEO3gzsp9rdP1kNO+SEPvh/ch+LoqLCkDJuVrUUj8ZIXbhMPfs55J4XT/ZaTq9JIRNFGQWCPf3QXh/b2QoynC7qYXtcgjptSjILPT+w7E4cPoyFn+wBzdvN7NdDiG9EgWZheaMCcG3q6bjl9+u4J603TSujBAWUJBZQVxUILbJZ6Ksug4LUnbhct0ttksipFehILOSmMH9sePFBFy41oB5bymg1tSzXRIhvQYFmRWNDBNi55oENDQ2Y+6b+VBdvM52SVbxc+kFXNQ2sF0GISZRkFnZkCBf7FwzGy7OTpj7lgInz2vZLskiJ87V4p60n/D65hK2SyHEJBrZbwNh/b3x40sJ6N/HHfPe3oWiMxq2S+oRhmGwan0hWhkGuQXnaIgJYR2N7LezgL6e2P5iAsSBPliQosABHg6a3XykEgdOX0LKEgm09U1QHK9huyTSy9HIfhb4ebshd/VMjBvUD/e++xPyS6rZLslsN241YU1mERaOH4An50ViZJgQOYcr2S6LEKMoyGysj6crNj87HXeNCMQDH+zF1oJzbJdklndzS6G50YiUJRIAgHRSOLYrz9OgX8JJFGR24OHmjA1PxeOe2DA89K8D+Gafiu2SOlVeU4dPdpzCP+4egXB/HwB3gqy+sQXbledZro6QjijI7MTVxQlfLJ+MpfFiLM84jPT802yXZBTDMHj+m0KE+Hni6QVR+tcj/H0QO7gfsun0knCQycfBKZVKKBQKAEBBQQEyMjIgFAoBACqVCjk5ORCLxVCpVEhOTjZrWW/n7OSETx6dgD6erli1vhDXbzVj1cKRbJdlYEexGj+W1GDDyjh4uhl+PJImR2BNZhE0N25D5OPOUoWEGMGYkJqaavC1RCLRf9/264qKCkYqlZq1rL2FCxeaXObIWltbmZTvShifpd8wL28sYlpbW9kuiWEYhmm43cxEP7uVuSd1l9GaLtTWM74PbWD+s7ucheoI+UP77DB6aqlUKpGSkqL/XiqVQqlUQqVSQaUy7N8Ri8X6I7fOlpE/CAQCPL8oGilLJPjgh1/xj6+PorWVYbssfLzjJM5frUfa0hgIBIIOywOFnoiPCqCrl4RzjAaZRCJBRkaG/nutVgsAEIlEUCgUEIlEBuuLRCL9qaipZaSjJ+dF4pNHJ+DLn8qxPOMQmltaWaul6spNrN1WiifmDsewYF+T6yVNjsC+UxdRU0tzSQl3mOzsl0ql+q83bdqEhIQECIVCfai1p9FoOl1GjHtk+hD839+nIvtwJR76137WRs+/mKlEXy83yO8Z1el6iTFhcHV2wrdH+DGMhPQOJjv7dbRaLXJyclBYWNjlet1dppuipCOTyRxylH9X7p8UDm8PF/zlk31Y8vE+ZK6Mg5uLs922/3PpBWwpqMIXyyejj6drp+sKvd0we3QIcg5XYsW8SDtVSHq7zMxMg6mM7acodRlkcrkc+fn5+iuPQqGwwxGWRqOBUCjsdJkxuilKBJg3NhSbnr4Liz/Yg0f/fRBfPTEVLs62Hx3T1NyKVeuPYvIwfyyeHGHWe5ImheORzw5AdfE6xIF9bFsgIeh4kNP2AAjoYhxZWloa5HI5xGIxtFottFotEhISjK4bExPT6TLStVnRwVj//6bhB+V5LM84jJZW2/eZpSvKUF5zHWtNdPAbM39cKLzdXajTn3CGySDLycmBRCLRh1hWVhaEQiHEYrHBeiqVCjExMV0uI+b507gB+HL5FGQfqsTK/ysAw9juauZFbQPe/rYEf5s5BKPD/cx+n5e7CxZIQpF9uNKm9RFiLqOnliqVCklJSQavCYVCJCcnAwCys7Mhl8sRGxuLgoICZGdn69frbBkxz30Tw3GrqQWPrzsML3dnpD443uyjpe54JasYri7OeOn+0d1+b9LkCGQd2oPSKi1GDTQ/BAmxBaNBJhaLO/2XViwWIzU1FYDh1c2ulhHzLZkmxq3GFqz8qgAeri745+IxVg2zI+WXsWH/GXz01wk9GqU/c1QQ/LzdkH24koKMsI7mWnLYozOH4p3fB82mbT1htXZbWu908I+N8MPDd4m7foMRbi7OWDRhIDbT6SXhAAoyjlsxLxKvSMfgzW+P46PtJ63S5td7VCg+W4u1S2Pg7NTzj0DSpHBUXrmJX367YpW6COmpLodfEPY9lzgSDY3NeGljEbzcnLEsYViP29LcuI1/Zh/DkmmDMHGov0V1TRnuj2A/T2QfqrS4LUIsQUdkPPHy/aOxYu5w/OO/R7F+b0WP23lzcwmaW1rx+uKxFtfk7OSE+yYMxLe/nGN1ehUh9PARnhAIBEhZIsHfZg7Bii+PIPvQ2W63UVJZiy93/4YX7o1GoNDTKnUlTY7A5bpb2HvyolXaI6Qzph4+wuqpJY3s7x6BQID3H4pFQ2MLlqUfgrurMxJjwsx6L8MwWLX+KIaF+OJxC05N25MMEmFwoA+yD1Vi5qhgq7VLiDG6Ef7dGtlPuMfJSYDPHpuIRbFheOTTA2Y/0CTr0FkcKruMtUvHw9XFer92gUAA6aQIbCusosfFEdZQkPGQs5MTMh6fgjljQrDko33Y+2vnp3XXG5rw0sZiLIoNw10jgqxej3RSOK7VN+FHHj0lijgWCjKecnVxwtcrpmLqcH8s/mAPDpdfNrlu6tYTuFbfiLdlEpvUEhnaF9EDhcg5RHMvCTsoyHjM3dUZG1bGY9wgEe5f+7PRJ5qfrr6GT3eewqqFIxHW39tmtUgnRWB7kRrXG5pstg1CTKEg4zkvdxdkPXMXhof44p603Sit0uqXMQyD1f8rRFg/bzw1P8p0I1YgnXRnfugP9Lg4wgIKMgfQx9MV366agYH9vbEwdTfKauoAANsKz2P3iQt450EJPNxse6PGgf29MXFof3pcHGEFBZmDEHq7YcvqGejfxx0L39mFk+e1eGGDEnPGhGD+2FC71LB4cgR2n6jB1eu37bI9QnQoyBxI/z4e2CafCU83F0x7JQ8XtA1IfVBik1sAGXPvhIFgGGBrAd3Pn9gXjex3MIFCT3z//EwMCvDB84tGYUiQ6SciWZu/rwemjwik00tiM6ZG9gsYFu/BkpiYSCP7bYRhGLsdibX1v30qPPHFYZz8YBFCRV523z7pHdpnB51aOig2QgwAFo4fADcXJ2w+QkdlxH4oyIhV9fVyw5zRITQ4ltgVBRmxusWTI1B0VoPfLtSxXQrpJSjIiNXNHRuCPh70uDhiPxRkxOo83Vxw9/gByDpE9/Mn9kFBRmxCOikC5TV1KKmsZbsU0gtQkBGbmDEyCCIfdxpTRuyCgozYhKuLE+6dEIbNhyvR2kqnl8S2aGQ/sRnppAic19R3eq80QrrD1Mh+VoNMd89+mUzGZhnERqYM80eoyIuuXhKrkclkyM3NRWio4Y0Q6NSS2IyTkwD3TwzHd/S4OGJjFGTEppImh+PK9dv4ufQC26UQB0ZBRmxqTLgfhgT1QRZNWSI2REFGbEogECBpUji+L6xCQ2Mz2+UQB0VBRmxOOjkC128148dj9Lg4YhsUZMTmhgX7YmyEHw2OJTZDQUbsQjopAnnFatTR4+KIDVCQEbu4f+JA3G5qxfeFVWyXQhwQjewndjGgnzemDPdHNl29JBagkf2EdUmTIvBT6QVcrrvFdimEp2hkP2HdoglhEAiA5RmH9Q8RJsQaKMiI3fTv44Evl0/Br1VaTHjhBzz55RGoNfVsl0UcAAUZsav7JoajKG0h3vzzOGwrPI+xz23DSxuLoLlBTycnPUdBRuzOw80ZT86LxPH3EvH0gih8sasco1fl4t3cUty8TaP/SfeZDDKlUonx48d3eF2lUkEul2PdunWQy+XQarUGy9LS0pCTk4O0tDSDZYS05+vpijX3jcbx9xKxZNogpHx3HKNX5SJDUYbG5ha2yyN8whiRnZ3NFBYWMsYWi8Vipra2lmEYhiksLGSSk5P1yyQSif7riooKRiqVGmteb+HChZ0uJ73L2UvXmWWfH2T6PPQNE/3sVmbTgTNMS0sr22URDmqfHUaPyKRSKSQSSYfXFQoFAEAoFAIAJBIJ1q1bB+DO0VhbYrFYvz4h5gj398G6xyfj8Ft/QlRoX/zt84OY+vIO7DympqcxkU51q4/M1KmiUqmEQqGASCQyeF0kEkGpVPa4ONI7jRggxKZn7kL+y7Ph6+UK6Xt7MO9tBQ6V0S2ziXHdCjKJRGJw5KULKY1GYzLkNBpNz6sjvdqkof7IezEBm5+djusNTZjzZj4Wf7AHpVVatkvjpYvaBoc9snXpzspisRipqalYt24dFi9erA+19kdibXXW4a+boqQjk8lolD8xIBAIMGdMCBKig7H5SCXe2FyCyS9txwOTI7Dm/tGI8Pdhu0ReOFJ+GXPeVOCe2DD8e9kkeLt360+fdZmZmQZTGdtPURIwnUS0QCAwmuAqlQparRZisRh+fn6ora1FVlYW0tPTUVhYqF/Pz88P2dnZSEhIMNp+YmIicnNzu/1Dkd6rsbkF/92jwjtbjkNzoxFjIvwwLNgXw4J9MfT3/4sDfeDm4sx2qZzR3NKK+FfzUH+7GTW1DRga7IvMlfEI6+/Ndmk91j47uh3LKpUKYrEYwJ1TS4lEAqFQiISEBKSnp3dYPyYmxoJyCTHk5uKMx2YNhWzaIKzfUwHlGQ3Kaurwg/I8rtXfuUWQs5MAEf4+GBZiGHDDgn3Rr487yz+B/WXsKseJKi1+fnUuXF2c8OcP9+Ku13bim6fiMHmYP9vlWUWXQabVavVXKQFg/PjxOHPmDIRCIdLT05GamgoA+nDTUalUiImJMXgvIdbi7e6C5XOG679nGAaXrt1C+YU6lFXXoaymDuU1ddhacA6VV25Cd2Ih8nG/E2ohvhga1EcfdhH+PnBxdrzx4Re0DXhzcwkenTEEEnE/AMDPr83F0k/2Y0HKLnz4SCweumswy1VazmiQKRQK5OfnAwBSUlIQGxsLqVQKAEhNTYVCoYBGo0FSUpLBaWN2djbkcjliY2NRUFCA7OxsO/wIhNzpBgkUeiJQ6IlpkYEGyxoam6G6eANlNXUoq76G8gvXcbyyFpsPV+pnEni4OuOrFVOxQDKAjfJt5qWNRXB1ccIr0jH61/x9PZArn4Hn1hdixZdHUFqlxVuycbwO8k77yGyN+sgImxiGQU1tA8pq6rB2WynOXrqBwtS74e7qGP1r+05exJ9SduGzxyZiabzxo64vdpVj1fqjiI8KxFcrpkLkw49T7/bZwd8IJsRCAoEAISIvTB8ZhLVLY1B1tR5f7CpnuyyraGpuxT/+exQTh/bHg9PEJtd7bNZQ5K6eieKzGsx4bSdOqa/ZsUrroSAjBEBkaF88PH0wUreegPZmI9vlWOzTnadQVl2HDx6OhZOToNN140cEYs8/58HDzRkz/7kTO4rUna7PRRRkhPzuxXujcbupBR/88CvbpVhEranHO1tOYPnsYYge6GfWewYF+EDx8hzERQXigQ/34P3vf+XV4FkKMkJ+FyT0xJPzIvHZztO8vuHj898UwsfDBS/eF92t9/XxdEXmynisWjgSr2YV47HPD/Lmocr08BFC2li5YAR8PFzw5uYStkvpkV3Ha7CloApvyyTo6+XW7fc7OQnwinQMvnpiKrYVnse8txSo5lCom3r4CF21JKSd9PzTWP0/JQ69NR8jBgjZLsdstxpbMGnNDwgVeeP752dCIOi8b6wrRWc0kH20Fy2tDDasjEPs4P5WqtRydNWSkC78dcYQRPh745VNxWyX0i0fbf8VlVdu4r2HYiwOMQAYN0iEPa/NRbi/N+a/rUDmgTNWqNI2KMgIacfNxRmvLR6Lnceqse/kRbbLMcvZyzewdtuveHJeJCJD+1qt3UChJ354fhaSJkUgOf0QXtpYhJbWVqu1by0UZIQYsSg2DDHifnh5UxEvrt49t/4o+vVxh/yeUVZv293VGZ89NhGpD0rwyY5TWPz+Hs4NUaEgI8QIgUCAN/48FoUqDb775Rzb5XTqB+V55BVXI/VBCXw8XG2yDYFAgCfmRuLbVdPxy29XMPP1Hzl1EYCCjBATpkUGYu6YELyWfYyzD0Opv92M1f8rREJ0MBJjwmy+vVnRwfjptblouN2MBz/eh1uN3NgvFGSEdOL1B8ai8vJN/Gf3b2yXYtTabaW4oG3Au0vHW6WD3xxDgnyxYWU8TlRp8fTXBZw49aYgI6QTIwYI8WDcILyz9QTqGprYLsdAeU0dPtp+Es8sGIEhQb523fa4QSJ8/OgEfLNPhXWKMrtu2xgKMkK6sOa+0bh5qxkfcmjqEsMwWLX+KEL8PPHswhGs1CCbOggr5g6H/Bsl61d3aWQ/IV0IFXlhxbzh+FfeKdTUcqODe0tBFXafuIC0v8TA0429+++/+edxmBYZgKX/2o+qKzdtvj1TI/tZDbLQ0FDk5ubSA0cI5z2zYAQ83Vzw9nfH2S4F1xua8Pw3hVggGYD540JZrcXF2QlfrZgKH3cXLPl4r83nZspkMuTm5iI01PDnplNLQszQ18sNqxNH4r97VKzfs+udLSdQe7MRaX8Zz2odOv37eCDz6Xicrq7DU//5hZXOfwoyQsz02KyhGNjfC69mFbNWw8nzWnz24yk8lzgKAzn0FKTogX747LGJ2HjwLD7dedru26cgI8RM7q7OeEU6BtuL1Dhw+pLdt88wDJ75+igi/H3w1PxIu2+/K9JJEXh6QRTWZBbhpxMX7LptCjJCuuH+ieEYFyHCyxvtP3Vp08GzOHD6Et5/KJazzxV4LWkMZowMxMOf7sfZyzfstl0KMkK6wcnpztSlgoqryD1aZbftam82Ys3GItw3YSBmjAqy23a7y9nJCf95YiqE3m5Y8tFe/VOqbI2CjJBuumtEEGaPDsarWcfQ1GyfO0G89W0J6m83I2WJxC7bs4TIxx2ZK+OhungDK744bJcjVwoyQnrg9cVjobp0HV/9bPupS8fOarBOUY4X7o1GiMjL5tuzhpFhQqQnT8LmI+fw4faTNt8eBRkhPTBqoB9kUwchZcsJXLfh1KXWVgbPfF2A4SG++Pvs4V2/gUPuiR2I5xLv3P9fUVJt023RyH5Ceuil+0ajrqERn+yw3RHH+n0qFFRcxfsPx8LVhX/HHWvui8bs0SH462cHUHHxusXt0ch+QqwsrL83ls8ejo93nMJFbYNV2750rQHv5pZiTaYSsqkRmBYZYNX27cXZyQlfLp+Cfn08IPtwL27csuzolUb2E2IDzy4cCTcXJ6RssXzqEsMw2H/qIh75dD8in96Kd3NPIDEmDO88yI0R/D0l9HbDxqfjcf7qTTy+zjad/xRkhFjAz9sNqxJH4qufK1BWU9ejNq7VN+LzH09jwovbMf/tXSg5p8UbD4zF6Y/uxWePTYLIx93KVdtfZGhfrHt8CnKPVmHttlKrt8/etHlCHETyrGH4/MfTeC2rGBtWxpv9vmNnNfhidzmyDp5FY0sr7pYMwNql4xEfFWi3myTa093jB+CFRaPwxuYSRA/0w7yx1pvwTkFGiIU83JzxsnQMktMP4XD5ZUwa6m9y3YbGZnx75By+2F2OoxVXESrywj/uHoGHpw9BkNDTjlWz4/lF0ThWWYu//fsgfnptLoYFW+eGkHRqSYgVPDA5AtEDhXh5Y7HRPqDfLtThhQ1KDF+5BcszDkPo5YbMlfE48V4i5Iuie0WIAXdmRmQsn4IgoSdkH+612l13KcgIsQInJwHeeGAcDpdfxg/KO0MDmltakXu0Cvek7ca41d9jw/4zWBo/GMXvLsR3z83A3eMHwMW59/0J+nq6YuPT8bigbcCyzw+itdXyzn86tSTESmZFB2PGyCC8klWM4+dq8dXPv6G6tgEThvTHuscn497YgfBw4+Zkb3sbGuyLL/8+BYs/2IN3thzHi/eNtqg9CjJCrOiNB8Yi7tU8fLT9JB6YEoHHZg1F9EA/tsvipHljQ/Hy/aPxek4J4qICERcV2OO2BAyLz3IaP348QkNDIZPJaFAscRgnztVioL8PfD1t87BcR8IwDNbvVUE2dZBZMxcyMzORmZkJtVqNwsJC/eusBlliYiJyc3PZ2jwhhKfaZ0fv62kkhDgcCjJCCO9RkBFCeI9XQcbn2/3wuXaA3/XzuXaA3/Xbq3YKMjvhc+0Av+vnc+0Av+vvVUFmzR/W3LbMWc+abZnL3nXRvu9eW7Tvu7+etdrqbB0KMju1ZS76Y7J+W+aifW/9tsxlaV2sjiMbOXIkBg8eDLVa3eGOj8aYsx61RW1RW47fVkVFBUpL/7ivGatBRggh1sCJU0tCCLEEBRkhhPcoyAghvMep2/ioVCrk5ORALBZDpVIhOTkZQqHQ4nXtRalUQqFQAAAKCgqQkZFhsialUgkAkEgkUKlU0Gq1kEgk9irVonq4tu9zcnKQkJAAAF3WwYX9rlQqsWzZMoO7NwD8+fybqp/Vzz/DIRKJRP91RUUFI5VKrbKuvaSmphp83bbG9pKTkxkADAAmISGBqa2ttUOFpnWnHq7te13dbf9r+7toi+39np2dzRQWFjLG/vT48PnvrH42P/+cCbKKiooOP7hQKLR4XXspLCw0qKGiooIBwFRUVBhdPz09namtrWU9wHTMrYdr+762tpbJzs42eM1UiDEMd/Z7+yDg2+e/ff1sf/4500emUCggEokMXhOJRPpD0J6uay8SiQQZGRn677VaLQB0qLMtoVDI+ulwW+bUw8V9L5VK9V/n5OQYfG8M1/Y7QJ9/S3Gmj0z3g7en0WgsWtee2v4Bbdq0CQkJCSZ/UVqtFjk5OQDu9Cc8/vjjEIvF9ijTonq4tu/b7l+tVguNRtPpfuTaftehz79lvwfOBJkppn5plq5rS7pfUvvO0Lbads6KxWLMnj0bFRUVdqrQ+vVwYd/L5XKkpqZ2ug7X9ntX6PNvHs6cWgqFwg7/omg0GqOJ3p112SCXy5Gfn99pPSqVSv+17spT29fszdx6uLrvtVotFApFl3Vwbb/r0Offst8DZ4JMd/m8vZiYGIvWtbe0tDTI5XKIxWJotVqj/0oqlUrMmjWrw+ud9SfYUnfq4eq+P3r0qFlDL7i039uiz79lvwfOBFn782OVSoWYmBj9h1OpVOoTu6t12ZKTkwOJRKL/JWZlZZmsv+0pkEKhgFQqZa3+rurhw75XKpVG/xC4vN/b/pHz8fPfPqTY/PxzatK4SqVCeno6YmNjUVBQgBdeeEH/wyUlJSE2NharV6/ucl22ah88eLDBa0KhELW1tQA61q8bPCgUClFRUdFl346tdVYP1/c9cOdIoKKiAunp6Qavc22/KxQK5OfnIy0tDatXr0ZsbKy+k5wPn39T9bP9+edUkBFCSE9w5tSSEEJ6ioKMEMJ7FGSEEN6jICOE8B4FGSGE9yjICCG89/8BzDJoSYALck8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 350x262.5 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rmse_p = pd.read_pickle(\"sensitivity_analysis/nb_features/rmse_physics.pkl\")\n",
    "zs_rmse_p = rmse_p.loc[(slice(None), 0),:]\n",
    "zs_rmse_p = zs_rmse_p.droplevel(1)\n",
    "for site in range(4):\n",
    "    plt.figure()\n",
    "    plt.plot(zs_rmse_p[site])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other ML models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVM\n",
    "- RF\n",
    "- biLSTM\n",
    "- seq2seq LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "                           temperature_1_5m  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00        285.791138               49.130329   \n",
      "2017-05-01 01:00:00+00:00        285.791138               49.130329   \n",
      "2017-05-01 02:00:00+00:00        284.749817               53.405571   \n",
      "2017-05-01 03:00:00+00:00        284.716705               56.041130   \n",
      "2017-05-01 04:00:00+00:00        284.208313               76.047226   \n",
      "...                                     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00        284.337646               81.713089   \n",
      "2019-04-30 20:00:00+00:00        284.214355               81.506241   \n",
      "2019-04-30 21:00:00+00:00        283.925049               82.345413   \n",
      "2019-04-30 22:00:00+00:00        283.625977               83.327530   \n",
      "2019-04-30 23:00:00+00:00        283.157715               87.310318   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 01:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 02:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 03:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 04:00:00+00:00                      0.0                    -0.0   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 20:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 21:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 22:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 23:00:00+00:00                      0.0                    -0.0   \n",
      "\n",
      "                           downward_surface_SW_flux  P_24h_shift  \\\n",
      "2017-05-01 00:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 01:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 02:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 03:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 04:00:00+00:00                       0.0         0.13   \n",
      "...                                             ...          ...   \n",
      "2019-04-30 19:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 20:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 21:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 22:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 23:00:00+00:00                       0.0         0.00   \n",
      "\n",
      "                           wind_speed_10m  \n",
      "2017-05-01 00:00:00+00:00        5.770765  \n",
      "2017-05-01 01:00:00+00:00        5.770765  \n",
      "2017-05-01 02:00:00+00:00        5.493945  \n",
      "2017-05-01 03:00:00+00:00        4.754774  \n",
      "2017-05-01 04:00:00+00:00        5.078067  \n",
      "...                                   ...  \n",
      "2019-04-30 19:00:00+00:00        3.381322  \n",
      "2019-04-30 20:00:00+00:00        2.891367  \n",
      "2019-04-30 21:00:00+00:00        2.126535  \n",
      "2019-04-30 22:00:00+00:00        2.048604  \n",
      "2019-04-30 23:00:00+00:00        2.481968  \n",
      "\n",
      "[16776 rows x 7 columns]\n",
      "Training Features Shape: (12582, 7)\n",
      "Training Labels Shape: (12582,)\n",
      "Testing Features Shape: (4194, 7)\n",
      "Testing Labels Shape: (4194,)\n",
      "Test Error:  255.5898199277538 W\n",
      "Zero-shot RMSE:  250.97395776380202 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                           PoA  P_24h_shift  is_day  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00  0.0         0.13     0.0               49.130329   \n",
      "2017-05-01 01:00:00+00:00  0.0         0.13     0.0               49.130329   \n",
      "2017-05-01 02:00:00+00:00  0.0         0.13     0.0               53.405571   \n",
      "2017-05-01 03:00:00+00:00  0.0         0.13     0.0               56.041130   \n",
      "2017-05-01 04:00:00+00:00  0.0         0.13     0.0               76.047226   \n",
      "...                        ...          ...     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00  0.0         0.00     1.0               81.713089   \n",
      "2019-04-30 20:00:00+00:00  0.0         0.00     0.0               81.506241   \n",
      "2019-04-30 21:00:00+00:00  0.0         0.00     0.0               82.345413   \n",
      "2019-04-30 22:00:00+00:00  0.0         0.00     0.0               83.327530   \n",
      "2019-04-30 23:00:00+00:00  0.0         0.00     0.0               87.310318   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 01:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 02:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 03:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 04:00:00+00:00                      0.0                    -0.0   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 20:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 21:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 22:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 23:00:00+00:00                      0.0                    -0.0   \n",
      "\n",
      "                           downward_surface_SW_flux      T_PV  \n",
      "2017-05-01 00:00:00+00:00                       0.0  9.118710  \n",
      "2017-05-01 01:00:00+00:00                       0.0  9.118710  \n",
      "2017-05-01 02:00:00+00:00                       0.0  8.015085  \n",
      "2017-05-01 03:00:00+00:00                       0.0  7.826575  \n",
      "2017-05-01 04:00:00+00:00                       0.0  7.383883  \n",
      "...                                             ...       ...  \n",
      "2019-04-30 19:00:00+00:00                       0.0  7.245319  \n",
      "2019-04-30 20:00:00+00:00                       0.0  6.848996  \n",
      "2019-04-30 21:00:00+00:00                       0.0  6.293461  \n",
      "2019-04-30 22:00:00+00:00                       0.0  5.954376  \n",
      "2019-04-30 23:00:00+00:00                       0.0  5.642422  \n",
      "\n",
      "[16776 rows x 8 columns]\n",
      "Training Features Shape: (12582, 8)\n",
      "Training Labels Shape: (12582,)\n",
      "Testing Features Shape: (4194, 8)\n",
      "Testing Labels Shape: (4194,)\n",
      "Test Error:  254.08967751321126 W\n",
      "Zero-shot RMSE:  238.8491504992903 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                           temperature_1_5m  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00        285.380493               54.158875   \n",
      "2017-05-01 01:00:00+00:00        285.080505               54.849888   \n",
      "2017-05-01 02:00:00+00:00        284.730499               56.330013   \n",
      "2017-05-01 03:00:00+00:00        284.180481               61.157490   \n",
      "2017-05-01 04:00:00+00:00        283.680481               69.723862   \n",
      "...                                     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00        283.780487               78.688652   \n",
      "2019-04-30 20:00:00+00:00        283.330505               80.256760   \n",
      "2019-04-30 21:00:00+00:00        282.880493               82.145218   \n",
      "2019-04-30 22:00:00+00:00        282.430481               84.956696   \n",
      "2019-04-30 23:00:00+00:00        282.180481               86.103416   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 01:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 02:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 03:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 04:00:00+00:00                      6.0                     0.0   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 20:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 21:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 22:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 23:00:00+00:00                      0.0                     0.0   \n",
      "\n",
      "                           downward_surface_SW_flux  P_24h_shift  \\\n",
      "2017-05-01 00:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 01:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 02:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 03:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 04:00:00+00:00                       6.0         0.13   \n",
      "...                                             ...          ...   \n",
      "2019-04-30 19:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 20:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 21:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 22:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 23:00:00+00:00                       0.0         0.00   \n",
      "\n",
      "                           wind_speed_10m  \n",
      "2017-05-01 00:00:00+00:00        6.135145  \n",
      "2017-05-01 01:00:00+00:00        5.700877  \n",
      "2017-05-01 02:00:00+00:00        5.323533  \n",
      "2017-05-01 03:00:00+00:00        4.750789  \n",
      "2017-05-01 04:00:00+00:00        4.248529  \n",
      "...                                   ...  \n",
      "2019-04-30 19:00:00+00:00        2.906888  \n",
      "2019-04-30 20:00:00+00:00        2.716616  \n",
      "2019-04-30 21:00:00+00:00        2.319483  \n",
      "2019-04-30 22:00:00+00:00        2.202272  \n",
      "2019-04-30 23:00:00+00:00        2.300000  \n",
      "\n",
      "[16704 rows x 7 columns]\n",
      "Training Features Shape: (12528, 7)\n",
      "Training Labels Shape: (12528,)\n",
      "Testing Features Shape: (4176, 7)\n",
      "Testing Labels Shape: (4176,)\n",
      "Test Error:  241.7128323229194 W\n",
      "Zero-shot RMSE:  304.38263427248074 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                                PoA  P_24h_shift  is_day  \\\n",
      "2017-05-01 00:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 01:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 02:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 03:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 04:00:00+00:00  0.120997         0.13     0.0   \n",
      "...                             ...          ...     ...   \n",
      "2019-04-30 19:00:00+00:00  0.000000         0.00     1.0   \n",
      "2019-04-30 20:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 21:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 22:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 23:00:00+00:00  0.000000         0.00     0.0   \n",
      "\n",
      "                           relative_humidity_1_5m  diffuse_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00               54.158875                      0.0   \n",
      "2017-05-01 01:00:00+00:00               54.849888                      0.0   \n",
      "2017-05-01 02:00:00+00:00               56.330013                      0.0   \n",
      "2017-05-01 03:00:00+00:00               61.157490                      0.0   \n",
      "2017-05-01 04:00:00+00:00               69.723862                      6.0   \n",
      "...                                           ...                      ...   \n",
      "2019-04-30 19:00:00+00:00               78.688652                      0.0   \n",
      "2019-04-30 20:00:00+00:00               80.256760                      0.0   \n",
      "2019-04-30 21:00:00+00:00               82.145218                      0.0   \n",
      "2019-04-30 22:00:00+00:00               84.956696                      0.0   \n",
      "2019-04-30 23:00:00+00:00               86.103416                      0.0   \n",
      "\n",
      "                           direct_surface_SW_flux  downward_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 01:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 02:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 03:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 04:00:00+00:00                     0.0                       6.0   \n",
      "...                                           ...                       ...   \n",
      "2019-04-30 19:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 20:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 21:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 22:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 23:00:00+00:00                     0.0                       0.0   \n",
      "\n",
      "                               T_PV  \n",
      "2017-05-01 00:00:00+00:00  8.763814  \n",
      "2017-05-01 01:00:00+00:00  8.387480  \n",
      "2017-05-01 02:00:00+00:00  7.962651  \n",
      "2017-05-01 03:00:00+00:00  7.282539  \n",
      "2017-05-01 04:00:00+00:00  6.647836  \n",
      "...                             ...  \n",
      "2019-04-30 19:00:00+00:00  6.573006  \n",
      "2019-04-30 20:00:00+00:00  5.895502  \n",
      "2019-04-30 21:00:00+00:00  5.301056  \n",
      "2019-04-30 22:00:00+00:00  4.795839  \n",
      "2019-04-30 23:00:00+00:00  4.578567  \n",
      "\n",
      "[16704 rows x 8 columns]\n",
      "Training Features Shape: (12528, 8)\n",
      "Training Labels Shape: (12528,)\n",
      "Testing Features Shape: (4176, 8)\n",
      "Testing Labels Shape: (4176,)\n",
      "Test Error:  233.04683951935544 W\n",
      "Zero-shot RMSE:  267.7826381738062 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                           temperature_1_5m  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00        283.041138               58.130329   \n",
      "2017-05-01 01:00:00+00:00        283.041138               58.130329   \n",
      "2017-05-01 02:00:00+00:00        282.624817               60.405571   \n",
      "2017-05-01 03:00:00+00:00        282.341705               62.041130   \n",
      "2017-05-01 04:00:00+00:00        281.958313               66.047226   \n",
      "...                                     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00        282.212646               92.713089   \n",
      "2019-04-30 20:00:00+00:00        281.839355               94.506241   \n",
      "2019-04-30 21:00:00+00:00        281.800049               93.345413   \n",
      "2019-04-30 22:00:00+00:00        281.625977               93.327530   \n",
      "2019-04-30 23:00:00+00:00        281.532715               95.310318   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 01:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 02:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 03:00:00+00:00                      0.0                    -0.0   \n",
      "2017-05-01 04:00:00+00:00                      0.0                    -0.0   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 20:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 21:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 22:00:00+00:00                      0.0                    -0.0   \n",
      "2019-04-30 23:00:00+00:00                      0.0                    -0.0   \n",
      "\n",
      "                           downward_surface_SW_flux  P_24h_shift  \\\n",
      "2017-05-01 00:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 01:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 02:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 03:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 04:00:00+00:00                       3.0         0.13   \n",
      "...                                             ...          ...   \n",
      "2019-04-30 19:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 20:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 21:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 22:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 23:00:00+00:00                       0.0         0.00   \n",
      "\n",
      "                           wind_speed_10m  \n",
      "2017-05-01 00:00:00+00:00        7.458175  \n",
      "2017-05-01 01:00:00+00:00        7.458175  \n",
      "2017-05-01 02:00:00+00:00        7.825811  \n",
      "2017-05-01 03:00:00+00:00        8.142806  \n",
      "2017-05-01 04:00:00+00:00        7.761098  \n",
      "...                                   ...  \n",
      "2019-04-30 19:00:00+00:00        3.166226  \n",
      "2019-04-30 20:00:00+00:00        2.844692  \n",
      "2019-04-30 21:00:00+00:00        2.317633  \n",
      "2019-04-30 22:00:00+00:00        1.880459  \n",
      "2019-04-30 23:00:00+00:00        1.980348  \n",
      "\n",
      "[16776 rows x 7 columns]\n",
      "Training Features Shape: (12582, 7)\n",
      "Training Labels Shape: (12582,)\n",
      "Testing Features Shape: (4194, 7)\n",
      "Testing Labels Shape: (4194,)\n",
      "Test Error:  210.3246800879905 W\n",
      "Zero-shot RMSE:  239.1664205371097 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                                PoA  P_24h_shift  is_day  \\\n",
      "2017-05-01 00:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 01:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 02:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 03:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 04:00:00+00:00  0.060499         0.13     0.0   \n",
      "...                             ...          ...     ...   \n",
      "2019-04-30 19:00:00+00:00  0.000000         0.00     1.0   \n",
      "2019-04-30 20:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 21:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 22:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 23:00:00+00:00  0.000000         0.00     0.0   \n",
      "\n",
      "                           relative_humidity_1_5m  diffuse_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00               58.130329                      0.0   \n",
      "2017-05-01 01:00:00+00:00               58.130329                      0.0   \n",
      "2017-05-01 02:00:00+00:00               60.405571                      0.0   \n",
      "2017-05-01 03:00:00+00:00               62.041130                      0.0   \n",
      "2017-05-01 04:00:00+00:00               66.047226                      0.0   \n",
      "...                                           ...                      ...   \n",
      "2019-04-30 19:00:00+00:00               92.713089                      0.0   \n",
      "2019-04-30 20:00:00+00:00               94.506241                      0.0   \n",
      "2019-04-30 21:00:00+00:00               93.345413                      0.0   \n",
      "2019-04-30 22:00:00+00:00               93.327530                      0.0   \n",
      "2019-04-30 23:00:00+00:00               95.310318                      0.0   \n",
      "\n",
      "                           direct_surface_SW_flux  downward_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                    -0.0                       0.0   \n",
      "2017-05-01 01:00:00+00:00                    -0.0                       0.0   \n",
      "2017-05-01 02:00:00+00:00                    -0.0                       0.0   \n",
      "2017-05-01 03:00:00+00:00                    -0.0                       0.0   \n",
      "2017-05-01 04:00:00+00:00                    -0.0                       3.0   \n",
      "...                                           ...                       ...   \n",
      "2019-04-30 19:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 20:00:00+00:00                    -0.0                       0.0   \n",
      "2019-04-30 21:00:00+00:00                    -0.0                       0.0   \n",
      "2019-04-30 22:00:00+00:00                    -0.0                       0.0   \n",
      "2019-04-30 23:00:00+00:00                    -0.0                       0.0   \n",
      "\n",
      "                               T_PV  \n",
      "2017-05-01 00:00:00+00:00  6.585371  \n",
      "2017-05-01 01:00:00+00:00  6.585371  \n",
      "2017-05-01 02:00:00+00:00  6.208568  \n",
      "2017-05-01 03:00:00+00:00  5.957901  \n",
      "2017-05-01 04:00:00+00:00  5.530112  \n",
      "...                             ...  \n",
      "2019-04-30 19:00:00+00:00  5.649064  \n",
      "2019-04-30 20:00:00+00:00  4.416673  \n",
      "2019-04-30 21:00:00+00:00  4.197011  \n",
      "2019-04-30 22:00:00+00:00  3.831342  \n",
      "2019-04-30 23:00:00+00:00  3.782976  \n",
      "\n",
      "[16776 rows x 8 columns]\n",
      "Training Features Shape: (12582, 8)\n",
      "Training Labels Shape: (12582,)\n",
      "Testing Features Shape: (4194, 8)\n",
      "Testing Labels Shape: (4194,)\n",
      "Test Error:  198.25871339789862 W\n",
      "Zero-shot RMSE:  214.46154530431966 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                           temperature_1_5m  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00        284.554504               55.887508   \n",
      "2017-05-01 01:00:00+00:00        284.254486               57.414227   \n",
      "2017-05-01 02:00:00+00:00        283.904480               60.662121   \n",
      "2017-05-01 03:00:00+00:00        283.554504               63.641632   \n",
      "2017-05-01 04:00:00+00:00        283.204498               66.068321   \n",
      "...                                     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00        282.454498               83.513947   \n",
      "2019-04-30 20:00:00+00:00        282.354492               83.789474   \n",
      "2019-04-30 21:00:00+00:00        282.204498               84.060417   \n",
      "2019-04-30 22:00:00+00:00        282.004486               84.909599   \n",
      "2019-04-30 23:00:00+00:00        281.854492               85.479630   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                      0.0                0.000000   \n",
      "2017-05-01 01:00:00+00:00                      0.0                0.000000   \n",
      "2017-05-01 02:00:00+00:00                      0.0                0.000000   \n",
      "2017-05-01 03:00:00+00:00                      0.0                0.000000   \n",
      "2017-05-01 04:00:00+00:00                     17.0               62.864208   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00                      0.0                0.000000   \n",
      "2019-04-30 20:00:00+00:00                      0.0                0.000000   \n",
      "2019-04-30 21:00:00+00:00                      0.0                0.000000   \n",
      "2019-04-30 22:00:00+00:00                      0.0                0.000000   \n",
      "2019-04-30 23:00:00+00:00                      0.0                0.000000   \n",
      "\n",
      "                           downward_surface_SW_flux  P_24h_shift  \\\n",
      "2017-05-01 00:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 01:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 02:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 03:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 04:00:00+00:00                      23.0         0.13   \n",
      "...                                             ...          ...   \n",
      "2019-04-30 19:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 20:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 21:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 22:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 23:00:00+00:00                       0.0         0.00   \n",
      "\n",
      "                           wind_speed_10m  \n",
      "2017-05-01 00:00:00+00:00       10.568822  \n",
      "2017-05-01 01:00:00+00:00       10.096039  \n",
      "2017-05-01 02:00:00+00:00        9.752948  \n",
      "2017-05-01 03:00:00+00:00        9.771899  \n",
      "2017-05-01 04:00:00+00:00        9.646243  \n",
      "...                                   ...  \n",
      "2019-04-30 19:00:00+00:00        4.700000  \n",
      "2019-04-30 20:00:00+00:00        4.204759  \n",
      "2019-04-30 21:00:00+00:00        3.512834  \n",
      "2019-04-30 22:00:00+00:00        3.106445  \n",
      "2019-04-30 23:00:00+00:00        3.041381  \n",
      "\n",
      "[16656 rows x 7 columns]\n",
      "Training Features Shape: (12492, 7)\n",
      "Training Labels Shape: (12492,)\n",
      "Testing Features Shape: (4164, 7)\n",
      "Testing Labels Shape: (4164,)\n",
      "Test Error:  217.06989459232986 W\n",
      "Zero-shot RMSE:  265.2777432197617 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                                PoA  P_24h_shift  is_day  \\\n",
      "2017-05-01 00:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 01:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 02:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 03:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 04:00:00+00:00  0.463822         0.13     0.0   \n",
      "...                             ...          ...     ...   \n",
      "2019-04-30 19:00:00+00:00  0.000000         0.00     1.0   \n",
      "2019-04-30 20:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 21:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 22:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 23:00:00+00:00  0.000000         0.00     0.0   \n",
      "\n",
      "                           relative_humidity_1_5m  diffuse_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00               55.887508                      0.0   \n",
      "2017-05-01 01:00:00+00:00               57.414227                      0.0   \n",
      "2017-05-01 02:00:00+00:00               60.662121                      0.0   \n",
      "2017-05-01 03:00:00+00:00               63.641632                      0.0   \n",
      "2017-05-01 04:00:00+00:00               66.068321                     17.0   \n",
      "...                                           ...                      ...   \n",
      "2019-04-30 19:00:00+00:00               83.513947                      0.0   \n",
      "2019-04-30 20:00:00+00:00               83.789474                      0.0   \n",
      "2019-04-30 21:00:00+00:00               84.060417                      0.0   \n",
      "2019-04-30 22:00:00+00:00               84.909599                      0.0   \n",
      "2019-04-30 23:00:00+00:00               85.479630                      0.0   \n",
      "\n",
      "                           direct_surface_SW_flux  downward_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                0.000000                       0.0   \n",
      "2017-05-01 01:00:00+00:00                0.000000                       0.0   \n",
      "2017-05-01 02:00:00+00:00                0.000000                       0.0   \n",
      "2017-05-01 03:00:00+00:00                0.000000                       0.0   \n",
      "2017-05-01 04:00:00+00:00               62.864208                      23.0   \n",
      "...                                           ...                       ...   \n",
      "2019-04-30 19:00:00+00:00                0.000000                       0.0   \n",
      "2019-04-30 20:00:00+00:00                0.000000                       0.0   \n",
      "2019-04-30 21:00:00+00:00                0.000000                       0.0   \n",
      "2019-04-30 22:00:00+00:00                0.000000                       0.0   \n",
      "2019-04-30 23:00:00+00:00                0.000000                       0.0   \n",
      "\n",
      "                               T_PV  \n",
      "2017-05-01 00:00:00+00:00  8.391200  \n",
      "2017-05-01 01:00:00+00:00  8.055599  \n",
      "2017-05-01 02:00:00+00:00  7.677210  \n",
      "2017-05-01 03:00:00+00:00  7.326461  \n",
      "2017-05-01 04:00:00+00:00  6.964307  \n",
      "...                             ...  \n",
      "2019-04-30 19:00:00+00:00  6.046171  \n",
      "2019-04-30 20:00:00+00:00  5.294186  \n",
      "2019-04-30 21:00:00+00:00  4.958811  \n",
      "2019-04-30 22:00:00+00:00  4.655461  \n",
      "2019-04-30 23:00:00+00:00  4.485221  \n",
      "\n",
      "[16656 rows x 8 columns]\n",
      "Training Features Shape: (12492, 8)\n",
      "Training Labels Shape: (12492,)\n",
      "Testing Features Shape: (4164, 8)\n",
      "Testing Labels Shape: (4164,)\n",
      "Test Error:  187.20668070803197 W\n",
      "Zero-shot RMSE:  224.99152451023267 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                           temperature_1_5m  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00        292.576599               92.250000   \n",
      "2017-05-01 01:00:00+00:00        292.009674               95.400482   \n",
      "2017-05-01 02:00:00+00:00        291.741089               95.067291   \n",
      "2017-05-01 03:00:00+00:00        291.560181               96.167404   \n",
      "2017-05-01 04:00:00+00:00        291.550842               96.102631   \n",
      "...                                     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00        297.084442               71.213051   \n",
      "2019-04-30 20:00:00+00:00        296.348511               75.180099   \n",
      "2019-04-30 21:00:00+00:00        295.488403               77.755836   \n",
      "2019-04-30 22:00:00+00:00        294.466370               82.583282   \n",
      "2019-04-30 23:00:00+00:00        293.210876               87.480858   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                 0.000000                0.000000   \n",
      "2017-05-01 01:00:00+00:00                 0.000000                0.000000   \n",
      "2017-05-01 02:00:00+00:00                 0.000000                0.000000   \n",
      "2017-05-01 03:00:00+00:00                 0.000000                0.000000   \n",
      "2017-05-01 04:00:00+00:00                 0.000000                0.000000   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00               386.399192              473.397829   \n",
      "2019-04-30 20:00:00+00:00               374.469947              303.963191   \n",
      "2019-04-30 21:00:00+00:00               283.125507              246.979401   \n",
      "2019-04-30 22:00:00+00:00                90.000000                0.000000   \n",
      "2019-04-30 23:00:00+00:00                25.000000                0.000000   \n",
      "\n",
      "                           downward_surface_SW_flux  P_24h_shift  \\\n",
      "2017-05-01 00:00:00+00:00                  0.000000         0.13   \n",
      "2017-05-01 01:00:00+00:00                  0.000000         0.13   \n",
      "2017-05-01 02:00:00+00:00                  0.000000         0.13   \n",
      "2017-05-01 03:00:00+00:00                  0.000000         0.13   \n",
      "2017-05-01 04:00:00+00:00                  0.000000         0.13   \n",
      "...                                             ...          ...   \n",
      "2019-04-30 19:00:00+00:00                826.275513      2067.90   \n",
      "2019-04-30 20:00:00+00:00                620.125183      1884.63   \n",
      "2019-04-30 21:00:00+00:00                440.000000      1076.10   \n",
      "2019-04-30 22:00:00+00:00                 90.000000       363.49   \n",
      "2019-04-30 23:00:00+00:00                 25.000000        23.37   \n",
      "\n",
      "                           wind_speed_10m  \n",
      "2017-05-01 00:00:00+00:00        0.470510  \n",
      "2017-05-01 01:00:00+00:00        0.458585  \n",
      "2017-05-01 02:00:00+00:00        0.255121  \n",
      "2017-05-01 03:00:00+00:00        0.088529  \n",
      "2017-05-01 04:00:00+00:00        0.180552  \n",
      "...                                   ...  \n",
      "2019-04-30 19:00:00+00:00        2.424450  \n",
      "2019-04-30 20:00:00+00:00        2.297161  \n",
      "2019-04-30 21:00:00+00:00        2.040530  \n",
      "2019-04-30 22:00:00+00:00        1.580065  \n",
      "2019-04-30 23:00:00+00:00        1.359634  \n",
      "\n",
      "[17256 rows x 7 columns]\n",
      "Training Features Shape: (12942, 7)\n",
      "Training Labels Shape: (12942,)\n",
      "Testing Features Shape: (4314, 7)\n",
      "Testing Labels Shape: (4314,)\n",
      "Test Error:  287.6395795141767 W\n",
      "Zero-shot RMSE:  566.0126495831557 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                                  PoA  P_24h_shift  is_day  \\\n",
      "2017-05-01 00:00:00+00:00    0.000000         0.13     0.0   \n",
      "2017-05-01 01:00:00+00:00    0.000000         0.13     0.0   \n",
      "2017-05-01 02:00:00+00:00    0.000000         0.13     0.0   \n",
      "2017-05-01 03:00:00+00:00    0.000000         0.13     0.0   \n",
      "2017-05-01 04:00:00+00:00    0.000000         0.13     0.0   \n",
      "...                               ...          ...     ...   \n",
      "2019-04-30 19:00:00+00:00  785.511427      2067.90     1.0   \n",
      "2019-04-30 20:00:00+00:00  574.397605      1884.63     1.0   \n",
      "2019-04-30 21:00:00+00:00  392.582170      1076.10     1.0   \n",
      "2019-04-30 22:00:00+00:00   88.240313       363.49     1.0   \n",
      "2019-04-30 23:00:00+00:00   24.588811        23.37     1.0   \n",
      "\n",
      "                           relative_humidity_1_5m  diffuse_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00               92.250000                 0.000000   \n",
      "2017-05-01 01:00:00+00:00               95.400482                 0.000000   \n",
      "2017-05-01 02:00:00+00:00               95.067291                 0.000000   \n",
      "2017-05-01 03:00:00+00:00               96.167404                 0.000000   \n",
      "2017-05-01 04:00:00+00:00               96.102631                 0.000000   \n",
      "...                                           ...                      ...   \n",
      "2019-04-30 19:00:00+00:00               71.213051               386.399192   \n",
      "2019-04-30 20:00:00+00:00               75.180099               374.469947   \n",
      "2019-04-30 21:00:00+00:00               77.755836               283.125507   \n",
      "2019-04-30 22:00:00+00:00               82.583282                90.000000   \n",
      "2019-04-30 23:00:00+00:00               87.480858                25.000000   \n",
      "\n",
      "                           direct_surface_SW_flux  downward_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                0.000000                  0.000000   \n",
      "2017-05-01 01:00:00+00:00                0.000000                  0.000000   \n",
      "2017-05-01 02:00:00+00:00                0.000000                  0.000000   \n",
      "2017-05-01 03:00:00+00:00                0.000000                  0.000000   \n",
      "2017-05-01 04:00:00+00:00                0.000000                  0.000000   \n",
      "...                                           ...                       ...   \n",
      "2019-04-30 19:00:00+00:00              473.397829                826.275513   \n",
      "2019-04-30 20:00:00+00:00              303.963191                620.125183   \n",
      "2019-04-30 21:00:00+00:00              246.979401                440.000000   \n",
      "2019-04-30 22:00:00+00:00                0.000000                 90.000000   \n",
      "2019-04-30 23:00:00+00:00                0.000000                 25.000000   \n",
      "\n",
      "                                T_PV  \n",
      "2017-05-01 00:00:00+00:00  14.080282  \n",
      "2017-05-01 01:00:00+00:00  13.420383  \n",
      "2017-05-01 02:00:00+00:00  12.662015  \n",
      "2017-05-01 03:00:00+00:00  11.812211  \n",
      "2017-05-01 04:00:00+00:00  12.187113  \n",
      "...                              ...  \n",
      "2019-04-30 19:00:00+00:00  49.570481  \n",
      "2019-04-30 20:00:00+00:00  44.218244  \n",
      "2019-04-30 21:00:00+00:00  37.125933  \n",
      "2019-04-30 22:00:00+00:00  28.525224  \n",
      "2019-04-30 23:00:00+00:00  18.806948  \n",
      "\n",
      "[17256 rows x 8 columns]\n",
      "Training Features Shape: (12942, 8)\n",
      "Training Labels Shape: (12942,)\n",
      "Testing Features Shape: (4314, 8)\n",
      "Testing Labels Shape: (4314,)\n",
      "Test Error:  290.55821434539314 W\n",
      "Zero-shot RMSE:  563.6841351704481 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                           temperature_1_5m  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00        294.138000               86.712509   \n",
      "2017-05-01 01:00:00+00:00        293.687988               89.706894   \n",
      "2017-05-01 02:00:00+00:00        293.638000               90.830811   \n",
      "2017-05-01 03:00:00+00:00        293.337982               92.818314   \n",
      "2017-05-01 04:00:00+00:00        292.888000               95.739449   \n",
      "...                                     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00        298.037994               63.300858   \n",
      "2019-04-30 20:00:00+00:00        297.138000               68.727264   \n",
      "2019-04-30 21:00:00+00:00        297.238007               66.825874   \n",
      "2019-04-30 22:00:00+00:00        296.437988               70.789886   \n",
      "2019-04-30 23:00:00+00:00        295.587982               75.238235   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                 0.000000                0.000000   \n",
      "2017-05-01 01:00:00+00:00                 0.000000                0.000000   \n",
      "2017-05-01 02:00:00+00:00                 0.000000                0.000000   \n",
      "2017-05-01 03:00:00+00:00                 0.000000                0.000000   \n",
      "2017-05-01 04:00:00+00:00                 0.000000                0.000000   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00               471.750670              147.708644   \n",
      "2019-04-30 20:00:00+00:00               371.096560               70.409862   \n",
      "2019-04-30 21:00:00+00:00               252.472287               35.467085   \n",
      "2019-04-30 22:00:00+00:00               124.000000                0.000000   \n",
      "2019-04-30 23:00:00+00:00                20.000000                0.000000   \n",
      "\n",
      "                           downward_surface_SW_flux  P_24h_shift  \\\n",
      "2017-05-01 00:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 01:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 02:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 03:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 04:00:00+00:00                       0.0         0.13   \n",
      "...                                             ...          ...   \n",
      "2019-04-30 19:00:00+00:00                     609.0      2067.90   \n",
      "2019-04-30 20:00:00+00:00                     428.0      1884.63   \n",
      "2019-04-30 21:00:00+00:00                     275.0      1076.10   \n",
      "2019-04-30 22:00:00+00:00                     124.0       363.49   \n",
      "2019-04-30 23:00:00+00:00                      20.0        23.37   \n",
      "\n",
      "                           wind_speed_10m  \n",
      "2017-05-01 00:00:00+00:00        0.300000  \n",
      "2017-05-01 01:00:00+00:00        0.141421  \n",
      "2017-05-01 02:00:00+00:00        0.300000  \n",
      "2017-05-01 03:00:00+00:00        0.316228  \n",
      "2017-05-01 04:00:00+00:00        0.583095  \n",
      "...                                   ...  \n",
      "2019-04-30 19:00:00+00:00        3.182766  \n",
      "2019-04-30 20:00:00+00:00        2.408319  \n",
      "2019-04-30 21:00:00+00:00        2.408319  \n",
      "2019-04-30 22:00:00+00:00        2.163331  \n",
      "2019-04-30 23:00:00+00:00        1.878829  \n",
      "\n",
      "[17520 rows x 7 columns]\n",
      "Training Features Shape: (13140, 7)\n",
      "Training Labels Shape: (13140,)\n",
      "Testing Features Shape: (4380, 7)\n",
      "Testing Labels Shape: (4380,)\n",
      "Test Error:  217.66868155732175 W\n",
      "Zero-shot RMSE:  644.6340597439154 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                                  PoA  P_24h_shift  is_day  \\\n",
      "2017-05-01 00:00:00+00:00    0.000000         0.13     0.0   \n",
      "2017-05-01 01:00:00+00:00    0.000000         0.13     0.0   \n",
      "2017-05-01 02:00:00+00:00    0.000000         0.13     0.0   \n",
      "2017-05-01 03:00:00+00:00    0.000000         0.13     0.0   \n",
      "2017-05-01 04:00:00+00:00    0.000000         0.13     0.0   \n",
      "...                               ...          ...     ...   \n",
      "2019-04-30 19:00:00+00:00  586.802658      2067.90     1.0   \n",
      "2019-04-30 20:00:00+00:00  408.082813      1884.63     1.0   \n",
      "2019-04-30 21:00:00+00:00  259.735930      1076.10     1.0   \n",
      "2019-04-30 22:00:00+00:00  120.280231       363.49     1.0   \n",
      "2019-04-30 23:00:00+00:00   19.666861        23.37     1.0   \n",
      "\n",
      "                           relative_humidity_1_5m  diffuse_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00               86.712509                 0.000000   \n",
      "2017-05-01 01:00:00+00:00               89.706894                 0.000000   \n",
      "2017-05-01 02:00:00+00:00               90.830811                 0.000000   \n",
      "2017-05-01 03:00:00+00:00               92.818314                 0.000000   \n",
      "2017-05-01 04:00:00+00:00               95.739449                 0.000000   \n",
      "...                                           ...                      ...   \n",
      "2019-04-30 19:00:00+00:00               63.300858               471.750670   \n",
      "2019-04-30 20:00:00+00:00               68.727264               371.096560   \n",
      "2019-04-30 21:00:00+00:00               66.825874               252.472287   \n",
      "2019-04-30 22:00:00+00:00               70.789886               124.000000   \n",
      "2019-04-30 23:00:00+00:00               75.238235                20.000000   \n",
      "\n",
      "                           direct_surface_SW_flux  downward_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                0.000000                       0.0   \n",
      "2017-05-01 01:00:00+00:00                0.000000                       0.0   \n",
      "2017-05-01 02:00:00+00:00                0.000000                       0.0   \n",
      "2017-05-01 03:00:00+00:00                0.000000                       0.0   \n",
      "2017-05-01 04:00:00+00:00                0.000000                       0.0   \n",
      "...                                           ...                       ...   \n",
      "2019-04-30 19:00:00+00:00              147.708644                     609.0   \n",
      "2019-04-30 20:00:00+00:00               70.409862                     428.0   \n",
      "2019-04-30 21:00:00+00:00               35.467085                     275.0   \n",
      "2019-04-30 22:00:00+00:00                0.000000                     124.0   \n",
      "2019-04-30 23:00:00+00:00                0.000000                      20.0   \n",
      "\n",
      "                                T_PV  \n",
      "2017-05-01 00:00:00+00:00  15.386605  \n",
      "2017-05-01 01:00:00+00:00  14.353979  \n",
      "2017-05-01 02:00:00+00:00  14.796016  \n",
      "2017-05-01 03:00:00+00:00  14.524900  \n",
      "2017-05-01 04:00:00+00:00  14.544486  \n",
      "...                              ...  \n",
      "2019-04-30 19:00:00+00:00  48.214637  \n",
      "2019-04-30 20:00:00+00:00  44.636301  \n",
      "2019-04-30 21:00:00+00:00  37.948470  \n",
      "2019-04-30 22:00:00+00:00  29.527107  \n",
      "2019-04-30 23:00:00+00:00  21.053865  \n",
      "\n",
      "[17520 rows x 8 columns]\n",
      "Training Features Shape: (13140, 8)\n",
      "Training Labels Shape: (13140,)\n",
      "Testing Features Shape: (4380, 8)\n",
      "Testing Labels Shape: (4380,)\n",
      "Test Error:  218.3972930422371 W\n",
      "Zero-shot RMSE:  644.4035212854789 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                           temperature_1_5m  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00        284.541138               70.130333   \n",
      "2017-05-01 01:00:00+00:00        284.541138               70.130333   \n",
      "2017-05-01 02:00:00+00:00        284.124817               72.405571   \n",
      "2017-05-01 03:00:00+00:00        283.966705               72.041130   \n",
      "2017-05-01 04:00:00+00:00        283.958313               75.047226   \n",
      "...                                     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00        287.462646               59.713089   \n",
      "2019-04-30 20:00:00+00:00        284.839355               73.506241   \n",
      "2019-04-30 21:00:00+00:00        284.175049               79.345413   \n",
      "2019-04-30 22:00:00+00:00        283.750977               82.327530   \n",
      "2019-04-30 23:00:00+00:00        283.532715               85.310318   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 01:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 02:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 03:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 04:00:00+00:00                      0.0                     0.0   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00                      9.0                     0.0   \n",
      "2019-04-30 20:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 21:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 22:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 23:00:00+00:00                      0.0                     0.0   \n",
      "\n",
      "                           downward_surface_SW_flux  P_24h_shift  \\\n",
      "2017-05-01 00:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 01:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 02:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 03:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 04:00:00+00:00                       0.0         0.13   \n",
      "...                                             ...          ...   \n",
      "2019-04-30 19:00:00+00:00                       3.0         0.00   \n",
      "2019-04-30 20:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 21:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 22:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 23:00:00+00:00                       0.0         0.00   \n",
      "\n",
      "                           wind_speed_10m  \n",
      "2017-05-01 00:00:00+00:00        3.305590  \n",
      "2017-05-01 01:00:00+00:00        3.305590  \n",
      "2017-05-01 02:00:00+00:00        3.145515  \n",
      "2017-05-01 03:00:00+00:00        3.530340  \n",
      "2017-05-01 04:00:00+00:00        2.762845  \n",
      "...                                   ...  \n",
      "2019-04-30 19:00:00+00:00        3.117709  \n",
      "2019-04-30 20:00:00+00:00        3.474645  \n",
      "2019-04-30 21:00:00+00:00        2.963010  \n",
      "2019-04-30 22:00:00+00:00        2.393910  \n",
      "2019-04-30 23:00:00+00:00        1.983756  \n",
      "\n",
      "[16872 rows x 7 columns]\n",
      "Training Features Shape: (12654, 7)\n",
      "Training Labels Shape: (12654,)\n",
      "Testing Features Shape: (4218, 7)\n",
      "Testing Labels Shape: (4218,)\n",
      "Test Error:  190.90820164237522 W\n",
      "Zero-shot RMSE:  238.38287674488592 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                               PoA  P_24h_shift  is_day  \\\n",
      "2017-05-01 00:00:00+00:00  0.00000         0.13     0.0   \n",
      "2017-05-01 01:00:00+00:00  0.00000         0.13     0.0   \n",
      "2017-05-01 02:00:00+00:00  0.00000         0.13     0.0   \n",
      "2017-05-01 03:00:00+00:00  0.00000         0.13     0.0   \n",
      "2017-05-01 04:00:00+00:00  0.00000         0.13     0.0   \n",
      "...                            ...          ...     ...   \n",
      "2019-04-30 19:00:00+00:00  7.74923         0.00     1.0   \n",
      "2019-04-30 20:00:00+00:00  0.00000         0.00     0.0   \n",
      "2019-04-30 21:00:00+00:00  0.00000         0.00     0.0   \n",
      "2019-04-30 22:00:00+00:00  0.00000         0.00     0.0   \n",
      "2019-04-30 23:00:00+00:00  0.00000         0.00     0.0   \n",
      "\n",
      "                           relative_humidity_1_5m  diffuse_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00               70.130333                      0.0   \n",
      "2017-05-01 01:00:00+00:00               70.130333                      0.0   \n",
      "2017-05-01 02:00:00+00:00               72.405571                      0.0   \n",
      "2017-05-01 03:00:00+00:00               72.041130                      0.0   \n",
      "2017-05-01 04:00:00+00:00               75.047226                      0.0   \n",
      "...                                           ...                      ...   \n",
      "2019-04-30 19:00:00+00:00               59.713089                      9.0   \n",
      "2019-04-30 20:00:00+00:00               73.506241                      0.0   \n",
      "2019-04-30 21:00:00+00:00               79.345413                      0.0   \n",
      "2019-04-30 22:00:00+00:00               82.327530                      0.0   \n",
      "2019-04-30 23:00:00+00:00               85.310318                      0.0   \n",
      "\n",
      "                           direct_surface_SW_flux  downward_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 01:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 02:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 03:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 04:00:00+00:00                     0.0                       0.0   \n",
      "...                                           ...                       ...   \n",
      "2019-04-30 19:00:00+00:00                     0.0                       3.0   \n",
      "2019-04-30 20:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 21:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 22:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 23:00:00+00:00                     0.0                       0.0   \n",
      "\n",
      "                                T_PV  \n",
      "2017-05-01 00:00:00+00:00   7.286092  \n",
      "2017-05-01 01:00:00+00:00   7.282863  \n",
      "2017-05-01 02:00:00+00:00   6.818765  \n",
      "2017-05-01 03:00:00+00:00   6.749302  \n",
      "2017-05-01 04:00:00+00:00   6.542651  \n",
      "...                              ...  \n",
      "2019-04-30 19:00:00+00:00  12.966895  \n",
      "2019-04-30 20:00:00+00:00   7.826770  \n",
      "2019-04-30 21:00:00+00:00   6.821751  \n",
      "2019-04-30 22:00:00+00:00   6.210053  \n",
      "2019-04-30 23:00:00+00:00   5.822356  \n",
      "\n",
      "[16872 rows x 8 columns]\n",
      "Training Features Shape: (12654, 8)\n",
      "Training Labels Shape: (12654,)\n",
      "Testing Features Shape: (4218, 8)\n",
      "Testing Labels Shape: (4218,)\n",
      "Test Error:  183.6464893035492 W\n",
      "Zero-shot RMSE:  238.95604961997907 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                           temperature_1_5m  relative_humidity_1_5m  \\\n",
      "2017-05-01 00:00:00+00:00        283.315979               73.376953   \n",
      "2017-05-01 01:00:00+00:00        283.315979               72.617912   \n",
      "2017-05-01 02:00:00+00:00        283.216003               73.358826   \n",
      "2017-05-01 03:00:00+00:00        283.165985               74.890221   \n",
      "2017-05-01 04:00:00+00:00        283.015991               76.170937   \n",
      "...                                     ...                     ...   \n",
      "2019-04-30 19:00:00+00:00        286.365997               75.688919   \n",
      "2019-04-30 20:00:00+00:00        285.315979               79.452202   \n",
      "2019-04-30 21:00:00+00:00        284.315979               84.875366   \n",
      "2019-04-30 22:00:00+00:00        283.815979               85.108406   \n",
      "2019-04-30 23:00:00+00:00        283.515991               88.011612   \n",
      "\n",
      "                           diffuse_surface_SW_flux  direct_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 01:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 02:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 03:00:00+00:00                      0.0                     0.0   \n",
      "2017-05-01 04:00:00+00:00                      1.0                     0.0   \n",
      "...                                            ...                     ...   \n",
      "2019-04-30 19:00:00+00:00                      4.0                     0.0   \n",
      "2019-04-30 20:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 21:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 22:00:00+00:00                      0.0                     0.0   \n",
      "2019-04-30 23:00:00+00:00                      0.0                     0.0   \n",
      "\n",
      "                           downward_surface_SW_flux  P_24h_shift  \\\n",
      "2017-05-01 00:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 01:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 02:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 03:00:00+00:00                       0.0         0.13   \n",
      "2017-05-01 04:00:00+00:00                       1.0         0.13   \n",
      "...                                             ...          ...   \n",
      "2019-04-30 19:00:00+00:00                       4.0         0.00   \n",
      "2019-04-30 20:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 21:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 22:00:00+00:00                       0.0         0.00   \n",
      "2019-04-30 23:00:00+00:00                       0.0         0.00   \n",
      "\n",
      "                           wind_speed_10m  \n",
      "2017-05-01 00:00:00+00:00        5.000000  \n",
      "2017-05-01 01:00:00+00:00        4.884670  \n",
      "2017-05-01 02:00:00+00:00        5.053711  \n",
      "2017-05-01 03:00:00+00:00        5.011986  \n",
      "2017-05-01 04:00:00+00:00        5.028916  \n",
      "...                                   ...  \n",
      "2019-04-30 19:00:00+00:00        1.334166  \n",
      "2019-04-30 20:00:00+00:00        1.664332  \n",
      "2019-04-30 21:00:00+00:00        2.061553  \n",
      "2019-04-30 22:00:00+00:00        2.475884  \n",
      "2019-04-30 23:00:00+00:00        2.000000  \n",
      "\n",
      "[16944 rows x 7 columns]\n",
      "Training Features Shape: (12708, 7)\n",
      "Training Labels Shape: (12708,)\n",
      "Testing Features Shape: (4236, 7)\n",
      "Testing Labels Shape: (4236,)\n",
      "Test Error:  197.334665929294 W\n",
      "Zero-shot RMSE:  231.45180119303345 W\n",
      "Not in Colab environment: Using .pkl files\n",
      "                                PoA  P_24h_shift  is_day  \\\n",
      "2017-05-01 00:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 01:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 02:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 03:00:00+00:00  0.000000         0.13     0.0   \n",
      "2017-05-01 04:00:00+00:00  0.023873         0.13     0.0   \n",
      "...                             ...          ...     ...   \n",
      "2019-04-30 19:00:00+00:00  3.500905         0.00     1.0   \n",
      "2019-04-30 20:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 21:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 22:00:00+00:00  0.000000         0.00     0.0   \n",
      "2019-04-30 23:00:00+00:00  0.000000         0.00     0.0   \n",
      "\n",
      "                           relative_humidity_1_5m  diffuse_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00               73.376953                      0.0   \n",
      "2017-05-01 01:00:00+00:00               72.617912                      0.0   \n",
      "2017-05-01 02:00:00+00:00               73.358826                      0.0   \n",
      "2017-05-01 03:00:00+00:00               74.890221                      0.0   \n",
      "2017-05-01 04:00:00+00:00               76.170937                      1.0   \n",
      "...                                           ...                      ...   \n",
      "2019-04-30 19:00:00+00:00               75.688919                      4.0   \n",
      "2019-04-30 20:00:00+00:00               79.452202                      0.0   \n",
      "2019-04-30 21:00:00+00:00               84.875366                      0.0   \n",
      "2019-04-30 22:00:00+00:00               85.108406                      0.0   \n",
      "2019-04-30 23:00:00+00:00               88.011612                      0.0   \n",
      "\n",
      "                           direct_surface_SW_flux  downward_surface_SW_flux  \\\n",
      "2017-05-01 00:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 01:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 02:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 03:00:00+00:00                     0.0                       0.0   \n",
      "2017-05-01 04:00:00+00:00                     0.0                       1.0   \n",
      "...                                           ...                       ...   \n",
      "2019-04-30 19:00:00+00:00                     0.0                       4.0   \n",
      "2019-04-30 20:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 21:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 22:00:00+00:00                     0.0                       0.0   \n",
      "2019-04-30 23:00:00+00:00                     0.0                       0.0   \n",
      "\n",
      "                                T_PV  \n",
      "2017-05-01 00:00:00+00:00   6.458486  \n",
      "2017-05-01 01:00:00+00:00   6.432623  \n",
      "2017-05-01 02:00:00+00:00   6.369138  \n",
      "2017-05-01 03:00:00+00:00   6.309438  \n",
      "2017-05-01 04:00:00+00:00   6.161487  \n",
      "...                              ...  \n",
      "2019-04-30 19:00:00+00:00  12.479070  \n",
      "2019-04-30 20:00:00+00:00   7.828223  \n",
      "2019-04-30 21:00:00+00:00   6.659227  \n",
      "2019-04-30 22:00:00+00:00   6.305100  \n",
      "2019-04-30 23:00:00+00:00   5.812586  \n",
      "\n",
      "[16944 rows x 8 columns]\n",
      "Training Features Shape: (12708, 8)\n",
      "Training Labels Shape: (12708,)\n",
      "Testing Features Shape: (4236, 8)\n",
      "Testing Labels Shape: (4236,)\n",
      "Test Error:  183.28696934911702 W\n",
      "Zero-shot RMSE:  215.76083704881478 W\n"
     ]
    }
   ],
   "source": [
    "rmse_rf = pd.DataFrame(index=range(4), columns=(range(4)))\n",
    "\n",
    "for site in range(4):\n",
    "    for model in range(4): #Only treat nwp vs reanalysis and physics vs non-physics\n",
    "        if model in [0,2]:\n",
    "            phys=False\n",
    "            phys_str = \"no_phys.pkl\"\n",
    "        else:\n",
    "            phys=True\n",
    "            phys_str = \"phys.pkl\"\n",
    "        if model in [0,1]:\n",
    "            dataset_name = \"nwp\"\n",
    "        else:\n",
    "            dataset_name=\"era5\"\n",
    "        source_data,_,eval_data = data_handeler(site, dataset_name, \"nwp\", \"nwp\", phys)\n",
    "        # Labels are the values we want to predict\n",
    "        labels = np.array(source_data['P'])\n",
    "        # Remove the labels from the source_data\n",
    "        # axis 1 refers to the columns\n",
    "        source_data= source_data.drop('P', axis = 1)\n",
    "        # Saving feature names for later use\n",
    "        ftr_file = \"features/ft_\" + phys_str\n",
    "        if os.path.isfile(ftr_file):\n",
    "            with open(ftr_file, 'rb') as f:\n",
    "                feature_list = pickle.load(f)\n",
    "        # Convert to numpy array\n",
    "        source_data = source_data[feature_list]\n",
    "        print(source_data)\n",
    "        source_data = np.array(source_data)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(source_data, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "        print('Training Features Shape:', train_features.shape)\n",
    "        print('Training Labels Shape:', train_labels.shape)\n",
    "        print('Testing Features Shape:', test_features.shape)\n",
    "        print('Testing Labels Shape:', test_labels.shape)\n",
    "        #Instantiate model with 1000 decision trees\n",
    "        rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "        # Train the model on training data\n",
    "        rf.fit(train_features, train_labels)\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions = rf.predict(test_features)\n",
    "        # Calculate the absolute errors\n",
    "        errors = np.sqrt(np.mean(np.square(predictions - test_labels)))\n",
    "        # Print out rmse\n",
    "        print(\"Test Error: \", errors, 'W')\n",
    "\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        val_labels = eval_data['P'].iloc[24:31*24]\n",
    "        val_features = eval_data[feature_list].iloc[24:31*24]\n",
    "        forecasts = rf.predict(val_features)\n",
    "        # Calculate the absolute errors\n",
    "        errors = np.sqrt(np.mean(np.square(forecasts - val_labels)))\n",
    "        # Print out rmse\n",
    "        print(\"Zero-shot RMSE: \", errors, 'W')\n",
    "        rmse_rf.loc[model, site] = errors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250.973958</td>\n",
       "      <td>239.166421</td>\n",
       "      <td>566.01265</td>\n",
       "      <td>238.382877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>238.84915</td>\n",
       "      <td>214.461545</td>\n",
       "      <td>563.684135</td>\n",
       "      <td>238.95605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>304.382634</td>\n",
       "      <td>265.277743</td>\n",
       "      <td>644.63406</td>\n",
       "      <td>231.451801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>267.782638</td>\n",
       "      <td>224.991525</td>\n",
       "      <td>644.403521</td>\n",
       "      <td>215.760837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3\n",
       "0  250.973958  239.166421   566.01265  238.382877\n",
       "1   238.84915  214.461545  563.684135   238.95605\n",
       "2  304.382634  265.277743   644.63406  231.451801\n",
       "3  267.782638  224.991525  644.403521  215.760837"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for -: 'float' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mmin\u001b[39m \u001b[38;5;241m=\u001b[39m scale\u001b[38;5;241m.\u001b[39mmin\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m covar \u001b[38;5;129;01min\u001b[39;00m source_data\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m---> 25\u001b[0m     source_data[covar] \u001b[38;5;241m=\u001b[39m (\u001b[43msource_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcovar\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mmin\u001b[39;49m)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m)\n\u001b[0;32m     26\u001b[0m     eval_data[covar] \u001b[38;5;241m=\u001b[39m (eval_data[covar]\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m)\u001b[38;5;241m/\u001b[39m(\u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;28mmin\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Labels are the values we want to predict\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pandas\\core\\ops\\common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pandas\\core\\arraylike.py:194\u001b[0m, in \u001b[0;36mOpsMixin.__sub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__sub__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__sub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pandas\\core\\series.py:6126\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6125\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[1;32m-> 6126\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pandas\\core\\base.py:1382\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1379\u001b[0m     rvalues \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(rvalues\u001b[38;5;241m.\u001b[39mstart, rvalues\u001b[38;5;241m.\u001b[39mstop, rvalues\u001b[38;5;241m.\u001b[39mstep)\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1382\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:283\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    279\u001b[0m     _bool_arith_check(op, left, right)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 283\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[0;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[0;32m    222\u001b[0m     ):\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\anaconda3\\envs\\SolNet\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for -: 'float' and 'dict'"
     ]
    }
   ],
   "source": [
    "rmse_svm = pd.DataFrame(index=range(4), columns=(range(4)))\n",
    "\n",
    "for site in range(4):\n",
    "    for model in range(4): #Only treat nwp vs reanalysis and physics vs non-physics\n",
    "        if model in [0,2]:\n",
    "            phys=False\n",
    "            phys_str = \"no_phys.pkl\"\n",
    "        else:\n",
    "            phys=True\n",
    "            phys_str = \"phys.pkl\"\n",
    "        if model in [0,1]:\n",
    "            dataset_name = \"nwp\"\n",
    "        else:\n",
    "            dataset_name=\"era5\"\n",
    "        source_data,_,eval_data = data_handeler(site, dataset_name, \"nwp\", \"nwp\", phys)\n",
    "\n",
    "        #Scale data (necessary for SVR)\n",
    "        scale = Scale()\n",
    "        scale.load(site, dataset_name, phys)\n",
    "        max = scale.max\n",
    "        min = scale.min\n",
    "        for covar in source_data.columns:\n",
    "            source_data[covar] = (source_data[covar]-min[covar])/(max[covar]-min[covar])\n",
    "            eval_data[covar] = (eval_data[covar]-min[covar])/(max[covar]-min[covar])\n",
    "\n",
    "        # Labels are the values we want to predict\n",
    "        labels = np.array(source_data['P'])\n",
    "        # Remove the labels from the source_data\n",
    "        # axis 1 refers to the columns\n",
    "        source_data= source_data.drop('P', axis = 1)\n",
    "        # Saving feature names for later use\n",
    "        ftr_file = \"features/ft_\" + phys_str\n",
    "        if os.path.isfile(ftr_file):\n",
    "            with open(ftr_file, 'rb') as f:\n",
    "                feature_list = pickle.load(f)\n",
    "        # Convert to numpy array\n",
    "        source_data = source_data[feature_list]\n",
    "        source_data = np.array(source_data)\n",
    "\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        train_features, test_features, train_labels, test_labels = train_test_split(source_data, labels, test_size = 0.25, random_state = 42)\n",
    "\n",
    "        print('Training Features Shape:', train_features.shape)\n",
    "        print('Training Labels Shape:', train_labels.shape)\n",
    "        print('Testing Features Shape:', test_features.shape)\n",
    "        print('Testing Labels Shape:', test_labels.shape)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        #Instantiate model SVR\n",
    "        rf = SVR(kernel='linear')\n",
    "        # Train the model on training data\n",
    "        rf.fit(train_features, train_labels)\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        predictions = rf.predict(test_features)\n",
    "        # Calculate the absolute errors\n",
    "        errors = np.sqrt(np.mean(np.square(predictions - test_labels)))\n",
    "        # Print out rmse\n",
    "        print(\"Test Error: \", errors, 'W')\n",
    "\n",
    "\n",
    "        # Use the forest's predict method on the test data\n",
    "        val_labels = eval_data['P'].iloc[24:31*24]\n",
    "        val_features = eval_data[feature_list].iloc[24:31*24]\n",
    "        forecasts = rf.predict(val_features)\n",
    "        # Calculate the absolute errors\n",
    "        errors = np.sqrt(np.mean(np.square(forecasts - val_labels)))\n",
    "        # Print out rmse\n",
    "        print(\"Zero-shot RMSE: \", errors*(max['P']-min['P']), 'W')\n",
    "        rmse_svm.loc[model, site] = errors*(max['P']-min['P'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>284.358394</td>\n",
       "      <td>257.183519</td>\n",
       "      <td>580.511709</td>\n",
       "      <td>225.216348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259.125937</td>\n",
       "      <td>214.906515</td>\n",
       "      <td>575.809448</td>\n",
       "      <td>257.101905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>329.983429</td>\n",
       "      <td>269.719089</td>\n",
       "      <td>650.041726</td>\n",
       "      <td>234.422344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>293.571108</td>\n",
       "      <td>242.772438</td>\n",
       "      <td>626.608246</td>\n",
       "      <td>223.231431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3\n",
       "0  284.358394  257.183519  580.511709  225.216348\n",
       "1  259.125937  214.906515  575.809448  257.101905\n",
       "2  329.983429  269.719089  650.041726  234.422344\n",
       "3  293.571108  242.772438  626.608246  223.231431"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nb of source years open-meteo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Physics-informed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([1114, 24, 8]) torch.Size([278, 24, 8]) torch.Size([1114, 24, 1]) torch.Size([278, 24, 1])\n",
      "Step 0: Average train loss: 0.1044 | Average test loss: 0.0305\n",
      "Step 5: Average train loss: 0.0168 | Average test loss: 0.0121\n",
      "Step 10: Average train loss: 0.0115 | Average test loss: 0.0110\n",
      "Step 15: Average train loss: 0.0114 | Average test loss: 0.0108\n",
      "Step 20: Average train loss: 0.0121 | Average test loss: 0.0116\n",
      "Step 25: Average train loss: 0.0104 | Average test loss: 0.0099\n",
      "Step 30: Average train loss: 0.0108 | Average test loss: 0.0098\n",
      "Step 35: Average train loss: 0.0098 | Average test loss: 0.0105\n",
      "Step 40: Average train loss: 0.0103 | Average test loss: 0.0111\n",
      "Step 45: Average train loss: 0.0095 | Average test loss: 0.0102\n",
      "Step 50: Average train loss: 0.0095 | Average test loss: 0.0097\n",
      "Step 55: Average train loss: 0.0095 | Average test loss: 0.0097\n",
      "Step 60: Average train loss: 0.0094 | Average test loss: 0.0096\n",
      "Step 65: Average train loss: 0.0093 | Average test loss: 0.0098\n",
      "Step 70: Average train loss: 0.0092 | Average test loss: 0.0096\n",
      "Step 75: Average train loss: 0.0094 | Average test loss: 0.0091\n",
      "Step 80: Average train loss: 0.0093 | Average test loss: 0.0093\n",
      "Step 85: Average train loss: 0.0093 | Average test loss: 0.0097\n",
      "Step 90: Average train loss: 0.0092 | Average test loss: 0.0092\n",
      "Step 95: Average train loss: 0.0090 | Average test loss: 0.0093\n",
      "Best Epoch: 82\n",
      "0.008936552939793238\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 65704.4765625\n",
      "Step 0: Average train loss: 0.0105\n",
      "Step 5: Average train loss: 0.0103\n",
      "Step 10: Average train loss: 0.0101\n",
      "Step 15: Average train loss: 0.0100\n",
      "Step 20: Average train loss: 0.0098\n",
      "Step 25: Average train loss: 0.0097\n",
      "Step 30: Average train loss: 0.0095\n",
      "Step 35: Average train loss: 0.0094\n",
      "Step 40: Average train loss: 0.0093\n",
      "Step 45: Average train loss: 0.0091\n",
      "Step 50: Average train loss: 0.0090\n",
      "Step 55: Average train loss: 0.0089\n",
      "Step 60: Average train loss: 0.0088\n",
      "Step 65: Average train loss: 0.0088\n",
      "Step 70: Average train loss: 0.0087\n",
      "Step 75: Average train loss: 0.0086\n",
      "Step 80: Average train loss: 0.0085\n",
      "Step 85: Average train loss: 0.0084\n",
      "Step 90: Average train loss: 0.0084\n",
      "Step 95: Average train loss: 0.0083\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 62523.8203125\n",
      "Step 0: Average train loss: 0.0098\n",
      "Step 5: Average train loss: 0.0096\n",
      "Step 10: Average train loss: 0.0094\n",
      "Step 15: Average train loss: 0.0093\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0089\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0087\n",
      "Step 45: Average train loss: 0.0086\n",
      "Step 50: Average train loss: 0.0085\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0084\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0082\n",
      "Step 80: Average train loss: 0.0081\n",
      "Step 85: Average train loss: 0.0081\n",
      "Step 90: Average train loss: 0.0080\n",
      "Step 95: Average train loss: 0.0079\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 49904.93359375\n",
      "Step 0: Average train loss: 0.0081\n",
      "Step 5: Average train loss: 0.0080\n",
      "Step 10: Average train loss: 0.0079\n",
      "Step 15: Average train loss: 0.0078\n",
      "Step 20: Average train loss: 0.0078\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0077\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0075\n",
      "Step 50: Average train loss: 0.0075\n",
      "Step 55: Average train loss: 0.0075\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0073\n",
      "Step 85: Average train loss: 0.0073\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50297.109375\n",
      "Step 0: Average train loss: 0.0076\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0075\n",
      "Step 15: Average train loss: 0.0075\n",
      "Step 20: Average train loss: 0.0075\n",
      "Step 25: Average train loss: 0.0074\n",
      "Step 30: Average train loss: 0.0074\n",
      "Step 35: Average train loss: 0.0074\n",
      "Step 40: Average train loss: 0.0074\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0073\n",
      "Step 70: Average train loss: 0.0073\n",
      "Step 75: Average train loss: 0.0072\n",
      "Step 80: Average train loss: 0.0072\n",
      "Step 85: Average train loss: 0.0072\n",
      "Step 90: Average train loss: 0.0072\n",
      "Step 95: Average train loss: 0.0072\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 48838.97265625\n",
      "Step 0: Average train loss: 0.0073\n",
      "Step 5: Average train loss: 0.0073\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0072\n",
      "Step 20: Average train loss: 0.0072\n",
      "Step 25: Average train loss: 0.0072\n",
      "Step 30: Average train loss: 0.0072\n",
      "Step 35: Average train loss: 0.0072\n",
      "Step 40: Average train loss: 0.0072\n",
      "Step 45: Average train loss: 0.0072\n",
      "Step 50: Average train loss: 0.0071\n",
      "Step 55: Average train loss: 0.0071\n",
      "Step 60: Average train loss: 0.0071\n",
      "Step 65: Average train loss: 0.0071\n",
      "Step 70: Average train loss: 0.0071\n",
      "Step 75: Average train loss: 0.0071\n",
      "Step 80: Average train loss: 0.0071\n",
      "Step 85: Average train loss: 0.0071\n",
      "Step 90: Average train loss: 0.0071\n",
      "Step 95: Average train loss: 0.0071\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 38458.8984375\n",
      "Step 0: Average train loss: 0.0069\n",
      "Step 5: Average train loss: 0.0068\n",
      "Step 10: Average train loss: 0.0068\n",
      "Step 15: Average train loss: 0.0068\n",
      "Step 20: Average train loss: 0.0068\n",
      "Step 25: Average train loss: 0.0068\n",
      "Step 30: Average train loss: 0.0067\n",
      "Step 35: Average train loss: 0.0067\n",
      "Step 40: Average train loss: 0.0067\n",
      "Step 45: Average train loss: 0.0067\n",
      "Step 50: Average train loss: 0.0067\n",
      "Step 55: Average train loss: 0.0067\n",
      "Step 60: Average train loss: 0.0067\n",
      "Step 65: Average train loss: 0.0067\n",
      "Step 70: Average train loss: 0.0067\n",
      "Step 75: Average train loss: 0.0066\n",
      "Step 80: Average train loss: 0.0066\n",
      "Step 85: Average train loss: 0.0066\n",
      "Step 90: Average train loss: 0.0066\n",
      "Step 95: Average train loss: 0.0066\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 23563.607421875\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n",
      "Step 60: Average train loss: 0.0054\n",
      "Step 65: Average train loss: 0.0054\n",
      "Step 70: Average train loss: 0.0054\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9549.140625\n",
      "Step 0: Average train loss: 0.0054\n",
      "Step 5: Average train loss: 0.0054\n",
      "Step 10: Average train loss: 0.0054\n",
      "Step 15: Average train loss: 0.0054\n",
      "Step 20: Average train loss: 0.0054\n",
      "Step 25: Average train loss: 0.0054\n",
      "Step 30: Average train loss: 0.0054\n",
      "Step 35: Average train loss: 0.0054\n",
      "Step 40: Average train loss: 0.0054\n",
      "Step 45: Average train loss: 0.0054\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0053\n",
      "Step 60: Average train loss: 0.0053\n",
      "Step 65: Average train loss: 0.0053\n",
      "Step 70: Average train loss: 0.0053\n",
      "Step 75: Average train loss: 0.0053\n",
      "Step 80: Average train loss: 0.0053\n",
      "Step 85: Average train loss: 0.0053\n",
      "Step 90: Average train loss: 0.0053\n",
      "Step 95: Average train loss: 0.0053\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 10943.80859375\n",
      "Step 0: Average train loss: 0.0048\n",
      "Step 5: Average train loss: 0.0048\n",
      "Step 10: Average train loss: 0.0048\n",
      "Step 15: Average train loss: 0.0048\n",
      "Step 20: Average train loss: 0.0048\n",
      "Step 25: Average train loss: 0.0048\n",
      "Step 30: Average train loss: 0.0048\n",
      "Step 35: Average train loss: 0.0048\n",
      "Step 40: Average train loss: 0.0048\n",
      "Step 45: Average train loss: 0.0048\n",
      "Step 50: Average train loss: 0.0047\n",
      "Step 55: Average train loss: 0.0047\n",
      "Step 60: Average train loss: 0.0047\n",
      "Step 65: Average train loss: 0.0047\n",
      "Step 70: Average train loss: 0.0047\n",
      "Step 75: Average train loss: 0.0047\n",
      "Step 80: Average train loss: 0.0047\n",
      "Step 85: Average train loss: 0.0047\n",
      "Step 90: Average train loss: 0.0047\n",
      "Step 95: Average train loss: 0.0047\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 72584.6640625\n",
      "Step 0: Average train loss: 0.0058\n",
      "Step 5: Average train loss: 0.0057\n",
      "Step 10: Average train loss: 0.0057\n",
      "Step 15: Average train loss: 0.0056\n",
      "Step 20: Average train loss: 0.0056\n",
      "Step 25: Average train loss: 0.0056\n",
      "Step 30: Average train loss: 0.0056\n",
      "Step 35: Average train loss: 0.0056\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 62672.890625\n",
      "Step 0: Average train loss: 0.0061\n",
      "Step 5: Average train loss: 0.0061\n",
      "Step 10: Average train loss: 0.0060\n",
      "Step 15: Average train loss: 0.0060\n",
      "Step 20: Average train loss: 0.0060\n",
      "Step 25: Average train loss: 0.0060\n",
      "Step 30: Average train loss: 0.0060\n",
      "Step 35: Average train loss: 0.0060\n",
      "Step 40: Average train loss: 0.0060\n",
      "Step 45: Average train loss: 0.0060\n",
      "Step 50: Average train loss: 0.0059\n",
      "Step 55: Average train loss: 0.0059\n",
      "Step 60: Average train loss: 0.0059\n",
      "Step 65: Average train loss: 0.0059\n",
      "Step 70: Average train loss: 0.0059\n",
      "Step 75: Average train loss: 0.0059\n",
      "Step 80: Average train loss: 0.0059\n",
      "Step 85: Average train loss: 0.0059\n",
      "Step 90: Average train loss: 0.0059\n",
      "Step 95: Average train loss: 0.0059\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 57278.34375\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0058\n",
      "Step 10: Average train loss: 0.0058\n",
      "Step 15: Average train loss: 0.0058\n",
      "Step 20: Average train loss: 0.0058\n",
      "Step 25: Average train loss: 0.0057\n",
      "Step 30: Average train loss: 0.0057\n",
      "Step 35: Average train loss: 0.0057\n",
      "Step 40: Average train loss: 0.0057\n",
      "Step 45: Average train loss: 0.0057\n",
      "Step 50: Average train loss: 0.0057\n",
      "Step 55: Average train loss: 0.0057\n",
      "Step 60: Average train loss: 0.0057\n",
      "Step 65: Average train loss: 0.0057\n",
      "Step 70: Average train loss: 0.0057\n",
      "Step 75: Average train loss: 0.0057\n",
      "Step 80: Average train loss: 0.0057\n",
      "Step 85: Average train loss: 0.0057\n",
      "Step 90: Average train loss: 0.0057\n",
      "Step 95: Average train loss: 0.0057\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 69319.1328125\n",
      "256.32886\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([1394, 24, 8]) torch.Size([348, 24, 8]) torch.Size([1394, 24, 1]) torch.Size([348, 24, 1])\n",
      "Step 0: Average train loss: 0.0789 | Average test loss: 0.0410\n",
      "Step 5: Average train loss: 0.0114 | Average test loss: 0.0112\n",
      "Step 10: Average train loss: 0.0112 | Average test loss: 0.0112\n",
      "Step 15: Average train loss: 0.0111 | Average test loss: 0.0106\n",
      "Step 20: Average train loss: 0.0108 | Average test loss: 0.0098\n",
      "Step 25: Average train loss: 0.0101 | Average test loss: 0.0094\n",
      "Step 30: Average train loss: 0.0097 | Average test loss: 0.0094\n",
      "Step 35: Average train loss: 0.0096 | Average test loss: 0.0093\n",
      "Step 40: Average train loss: 0.0094 | Average test loss: 0.0092\n",
      "Step 45: Average train loss: 0.0096 | Average test loss: 0.0102\n",
      "Step 50: Average train loss: 0.0098 | Average test loss: 0.0095\n",
      "Step 55: Average train loss: 0.0097 | Average test loss: 0.0102\n",
      "Step 60: Average train loss: 0.0096 | Average test loss: 0.0090\n",
      "Step 65: Average train loss: 0.0093 | Average test loss: 0.0096\n",
      "Step 70: Average train loss: 0.0096 | Average test loss: 0.0101\n",
      "Step 75: Average train loss: 0.0094 | Average test loss: 0.0097\n",
      "Step 80: Average train loss: 0.0094 | Average test loss: 0.0100\n",
      "Step 85: Average train loss: 0.0092 | Average test loss: 0.0092\n",
      "Step 90: Average train loss: 0.0092 | Average test loss: 0.0097\n",
      "Step 95: Average train loss: 0.0091 | Average test loss: 0.0092\n",
      "Best Epoch: 60\n",
      "0.00897053474909626\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 75621.78125\n",
      "Step 0: Average train loss: 0.0121\n",
      "Step 5: Average train loss: 0.0119\n",
      "Step 10: Average train loss: 0.0116\n",
      "Step 15: Average train loss: 0.0114\n",
      "Step 20: Average train loss: 0.0112\n",
      "Step 25: Average train loss: 0.0110\n",
      "Step 30: Average train loss: 0.0108\n",
      "Step 35: Average train loss: 0.0106\n",
      "Step 40: Average train loss: 0.0105\n",
      "Step 45: Average train loss: 0.0103\n",
      "Step 50: Average train loss: 0.0101\n",
      "Step 55: Average train loss: 0.0099\n",
      "Step 60: Average train loss: 0.0098\n",
      "Step 65: Average train loss: 0.0096\n",
      "Step 70: Average train loss: 0.0094\n",
      "Step 75: Average train loss: 0.0093\n",
      "Step 80: Average train loss: 0.0091\n",
      "Step 85: Average train loss: 0.0090\n",
      "Step 90: Average train loss: 0.0088\n",
      "Step 95: Average train loss: 0.0087\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 60280.3984375\n",
      "Step 0: Average train loss: 0.0097\n",
      "Step 5: Average train loss: 0.0095\n",
      "Step 10: Average train loss: 0.0094\n",
      "Step 15: Average train loss: 0.0093\n",
      "Step 20: Average train loss: 0.0091\n",
      "Step 25: Average train loss: 0.0090\n",
      "Step 30: Average train loss: 0.0089\n",
      "Step 35: Average train loss: 0.0088\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0087\n",
      "Step 50: Average train loss: 0.0086\n",
      "Step 55: Average train loss: 0.0086\n",
      "Step 60: Average train loss: 0.0085\n",
      "Step 65: Average train loss: 0.0084\n",
      "Step 70: Average train loss: 0.0084\n",
      "Step 75: Average train loss: 0.0083\n",
      "Step 80: Average train loss: 0.0083\n",
      "Step 85: Average train loss: 0.0082\n",
      "Step 90: Average train loss: 0.0082\n",
      "Step 95: Average train loss: 0.0081\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 54629.2890625\n",
      "Step 0: Average train loss: 0.0086\n",
      "Step 5: Average train loss: 0.0084\n",
      "Step 10: Average train loss: 0.0083\n",
      "Step 15: Average train loss: 0.0082\n",
      "Step 20: Average train loss: 0.0082\n",
      "Step 25: Average train loss: 0.0081\n",
      "Step 30: Average train loss: 0.0081\n",
      "Step 35: Average train loss: 0.0080\n",
      "Step 40: Average train loss: 0.0080\n",
      "Step 45: Average train loss: 0.0079\n",
      "Step 50: Average train loss: 0.0079\n",
      "Step 55: Average train loss: 0.0079\n",
      "Step 60: Average train loss: 0.0078\n",
      "Step 65: Average train loss: 0.0078\n",
      "Step 70: Average train loss: 0.0078\n",
      "Step 75: Average train loss: 0.0078\n",
      "Step 80: Average train loss: 0.0077\n",
      "Step 85: Average train loss: 0.0077\n",
      "Step 90: Average train loss: 0.0077\n",
      "Step 95: Average train loss: 0.0077\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 50928.8671875\n",
      "Step 0: Average train loss: 0.0079\n",
      "Step 5: Average train loss: 0.0078\n",
      "Step 10: Average train loss: 0.0078\n",
      "Step 15: Average train loss: 0.0077\n",
      "Step 20: Average train loss: 0.0077\n",
      "Step 25: Average train loss: 0.0077\n",
      "Step 30: Average train loss: 0.0076\n",
      "Step 35: Average train loss: 0.0076\n",
      "Step 40: Average train loss: 0.0076\n",
      "Step 45: Average train loss: 0.0076\n",
      "Step 50: Average train loss: 0.0076\n",
      "Step 55: Average train loss: 0.0075\n",
      "Step 60: Average train loss: 0.0075\n",
      "Step 65: Average train loss: 0.0075\n",
      "Step 70: Average train loss: 0.0075\n",
      "Step 75: Average train loss: 0.0075\n",
      "Step 80: Average train loss: 0.0075\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0074\n",
      "Step 95: Average train loss: 0.0074\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 47148.9609375\n",
      "Step 0: Average train loss: 0.0075\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0074\n",
      "Step 15: Average train loss: 0.0074\n",
      "Step 20: Average train loss: 0.0074\n",
      "Step 25: Average train loss: 0.0073\n",
      "Step 30: Average train loss: 0.0073\n",
      "Step 35: Average train loss: 0.0073\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0073\n",
      "Step 50: Average train loss: 0.0073\n",
      "Step 55: Average train loss: 0.0073\n",
      "Step 60: Average train loss: 0.0073\n",
      "Step 65: Average train loss: 0.0072\n",
      "Step 70: Average train loss: 0.0072\n",
      "Step 75: Average train loss: 0.0072\n",
      "Step 80: Average train loss: 0.0072\n",
      "Step 85: Average train loss: 0.0072\n",
      "Step 90: Average train loss: 0.0072\n",
      "Step 95: Average train loss: 0.0072\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 42193.9765625\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0071\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0070\n",
      "Step 30: Average train loss: 0.0070\n",
      "Step 35: Average train loss: 0.0070\n",
      "Step 40: Average train loss: 0.0070\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0069\n",
      "Step 75: Average train loss: 0.0069\n",
      "Step 80: Average train loss: 0.0069\n",
      "Step 85: Average train loss: 0.0069\n",
      "Step 90: Average train loss: 0.0069\n",
      "Step 95: Average train loss: 0.0069\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 23829.998046875\n",
      "Step 0: Average train loss: 0.0056\n",
      "Step 5: Average train loss: 0.0056\n",
      "Step 10: Average train loss: 0.0056\n",
      "Step 15: Average train loss: 0.0056\n",
      "Step 20: Average train loss: 0.0056\n",
      "Step 25: Average train loss: 0.0056\n",
      "Step 30: Average train loss: 0.0056\n",
      "Step 35: Average train loss: 0.0056\n",
      "Step 40: Average train loss: 0.0056\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9438.373046875\n",
      "Step 0: Average train loss: 0.0056\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0055\n",
      "Step 80: Average train loss: 0.0055\n",
      "Step 85: Average train loss: 0.0055\n",
      "Step 90: Average train loss: 0.0055\n",
      "Step 95: Average train loss: 0.0055\n",
      "Best Epoch: 99\n",
      "Currently in month 8. MSE for this month is: 10873.9697265625\n",
      "Step 0: Average train loss: 0.0049\n",
      "Step 5: Average train loss: 0.0049\n",
      "Step 10: Average train loss: 0.0049\n",
      "Step 15: Average train loss: 0.0049\n",
      "Step 20: Average train loss: 0.0049\n",
      "Step 25: Average train loss: 0.0049\n",
      "Step 30: Average train loss: 0.0049\n",
      "Step 35: Average train loss: 0.0049\n",
      "Step 40: Average train loss: 0.0049\n",
      "Step 45: Average train loss: 0.0049\n",
      "Step 50: Average train loss: 0.0049\n",
      "Step 55: Average train loss: 0.0049\n",
      "Step 60: Average train loss: 0.0049\n",
      "Step 65: Average train loss: 0.0049\n",
      "Step 70: Average train loss: 0.0049\n",
      "Step 75: Average train loss: 0.0049\n",
      "Step 80: Average train loss: 0.0049\n",
      "Step 85: Average train loss: 0.0049\n",
      "Step 90: Average train loss: 0.0049\n",
      "Step 95: Average train loss: 0.0049\n",
      "Best Epoch: 99\n",
      "Currently in month 9. MSE for this month is: 71141.296875\n",
      "Step 0: Average train loss: 0.0059\n",
      "Step 5: Average train loss: 0.0058\n",
      "Step 10: Average train loss: 0.0058\n",
      "Step 15: Average train loss: 0.0058\n",
      "Step 20: Average train loss: 0.0058\n",
      "Step 25: Average train loss: 0.0058\n",
      "Step 30: Average train loss: 0.0057\n",
      "Step 35: Average train loss: 0.0057\n",
      "Step 40: Average train loss: 0.0057\n",
      "Step 45: Average train loss: 0.0057\n",
      "Step 50: Average train loss: 0.0057\n",
      "Step 55: Average train loss: 0.0057\n",
      "Step 60: Average train loss: 0.0057\n",
      "Step 65: Average train loss: 0.0057\n",
      "Step 70: Average train loss: 0.0057\n",
      "Step 75: Average train loss: 0.0057\n",
      "Step 80: Average train loss: 0.0057\n",
      "Step 85: Average train loss: 0.0056\n",
      "Step 90: Average train loss: 0.0056\n",
      "Step 95: Average train loss: 0.0056\n",
      "Best Epoch: 99\n",
      "Currently in month 10. MSE for this month is: 60140.921875\n",
      "Step 0: Average train loss: 0.0062\n",
      "Step 5: Average train loss: 0.0062\n",
      "Step 10: Average train loss: 0.0062\n",
      "Step 15: Average train loss: 0.0061\n",
      "Step 20: Average train loss: 0.0061\n",
      "Step 25: Average train loss: 0.0061\n",
      "Step 30: Average train loss: 0.0061\n",
      "Step 35: Average train loss: 0.0061\n",
      "Step 40: Average train loss: 0.0061\n",
      "Step 45: Average train loss: 0.0061\n",
      "Step 50: Average train loss: 0.0061\n",
      "Step 55: Average train loss: 0.0061\n",
      "Step 60: Average train loss: 0.0060\n",
      "Step 65: Average train loss: 0.0060\n",
      "Step 70: Average train loss: 0.0060\n",
      "Step 75: Average train loss: 0.0060\n",
      "Step 80: Average train loss: 0.0060\n",
      "Step 85: Average train loss: 0.0060\n",
      "Step 90: Average train loss: 0.0060\n",
      "Step 95: Average train loss: 0.0060\n",
      "Best Epoch: 99\n",
      "Currently in month 11. MSE for this month is: 57209.64453125\n",
      "Step 0: Average train loss: 0.0060\n",
      "Step 5: Average train loss: 0.0059\n",
      "Step 10: Average train loss: 0.0059\n",
      "Step 15: Average train loss: 0.0059\n",
      "Step 20: Average train loss: 0.0059\n",
      "Step 25: Average train loss: 0.0059\n",
      "Step 30: Average train loss: 0.0059\n",
      "Step 35: Average train loss: 0.0059\n",
      "Step 40: Average train loss: 0.0059\n",
      "Step 45: Average train loss: 0.0058\n",
      "Step 50: Average train loss: 0.0058\n",
      "Step 55: Average train loss: 0.0058\n",
      "Step 60: Average train loss: 0.0058\n",
      "Step 65: Average train loss: 0.0058\n",
      "Step 70: Average train loss: 0.0058\n",
      "Step 75: Average train loss: 0.0058\n",
      "Step 80: Average train loss: 0.0058\n",
      "Step 85: Average train loss: 0.0058\n",
      "Step 90: Average train loss: 0.0058\n",
      "Step 95: Average train loss: 0.0058\n",
      "Best Epoch: 99\n",
      "Currently in month 12. MSE for this month is: 78360.7578125\n",
      "274.99414\n",
      "Not in Colab environment: Using .pkl files\n",
      "Shape of data:  torch.Size([1674, 24, 8]) torch.Size([418, 24, 8]) torch.Size([1674, 24, 1]) torch.Size([418, 24, 1])\n",
      "Step 0: Average train loss: 0.0792 | Average test loss: 0.0332\n",
      "Step 5: Average train loss: 0.0128 | Average test loss: 0.0123\n",
      "Step 10: Average train loss: 0.0118 | Average test loss: 0.0126\n",
      "Step 15: Average train loss: 0.0114 | Average test loss: 0.0117\n",
      "Step 20: Average train loss: 0.0111 | Average test loss: 0.0124\n",
      "Step 25: Average train loss: 0.0105 | Average test loss: 0.0119\n",
      "Step 30: Average train loss: 0.0100 | Average test loss: 0.0111\n",
      "Step 35: Average train loss: 0.0099 | Average test loss: 0.0107\n",
      "Step 40: Average train loss: 0.0098 | Average test loss: 0.0104\n",
      "Step 45: Average train loss: 0.0096 | Average test loss: 0.0108\n",
      "Step 50: Average train loss: 0.0097 | Average test loss: 0.0105\n",
      "Step 55: Average train loss: 0.0098 | Average test loss: 0.0113\n",
      "Step 60: Average train loss: 0.0095 | Average test loss: 0.0105\n",
      "Step 65: Average train loss: 0.0095 | Average test loss: 0.0105\n",
      "Step 70: Average train loss: 0.0094 | Average test loss: 0.0107\n",
      "Step 75: Average train loss: 0.0094 | Average test loss: 0.0102\n",
      "Step 80: Average train loss: 0.0094 | Average test loss: 0.0107\n",
      "Step 85: Average train loss: 0.0095 | Average test loss: 0.0114\n",
      "Step 90: Average train loss: 0.0093 | Average test loss: 0.0102\n",
      "Step 95: Average train loss: 0.0092 | Average test loss: 0.0112\n",
      "Best Epoch: 90\n",
      "0.010166098976409748\n",
      "Shape of data:  torch.Size([30, 24, 8]) torch.Size([30, 24, 8]) torch.Size([30, 24, 1]) torch.Size([30, 24, 1])\n",
      "Currently in month 0. MSE for this month is: 100055.8125\n",
      "Step 0: Average train loss: 0.0180\n",
      "Step 5: Average train loss: 0.0175\n",
      "Step 10: Average train loss: 0.0170\n",
      "Step 15: Average train loss: 0.0166\n",
      "Step 20: Average train loss: 0.0161\n",
      "Step 25: Average train loss: 0.0157\n",
      "Step 30: Average train loss: 0.0153\n",
      "Step 35: Average train loss: 0.0150\n",
      "Step 40: Average train loss: 0.0146\n",
      "Step 45: Average train loss: 0.0142\n",
      "Step 50: Average train loss: 0.0139\n",
      "Step 55: Average train loss: 0.0136\n",
      "Step 60: Average train loss: 0.0133\n",
      "Step 65: Average train loss: 0.0130\n",
      "Step 70: Average train loss: 0.0127\n",
      "Step 75: Average train loss: 0.0124\n",
      "Step 80: Average train loss: 0.0122\n",
      "Step 85: Average train loss: 0.0119\n",
      "Step 90: Average train loss: 0.0116\n",
      "Step 95: Average train loss: 0.0114\n",
      "Best Epoch: 99\n",
      "Currently in month 1. MSE for this month is: 62304.83203125\n",
      "Step 0: Average train loss: 0.0107\n",
      "Step 5: Average train loss: 0.0103\n",
      "Step 10: Average train loss: 0.0100\n",
      "Step 15: Average train loss: 0.0098\n",
      "Step 20: Average train loss: 0.0095\n",
      "Step 25: Average train loss: 0.0093\n",
      "Step 30: Average train loss: 0.0092\n",
      "Step 35: Average train loss: 0.0090\n",
      "Step 40: Average train loss: 0.0088\n",
      "Step 45: Average train loss: 0.0087\n",
      "Step 50: Average train loss: 0.0086\n",
      "Step 55: Average train loss: 0.0085\n",
      "Step 60: Average train loss: 0.0084\n",
      "Step 65: Average train loss: 0.0083\n",
      "Step 70: Average train loss: 0.0083\n",
      "Step 75: Average train loss: 0.0082\n",
      "Step 80: Average train loss: 0.0081\n",
      "Step 85: Average train loss: 0.0081\n",
      "Step 90: Average train loss: 0.0080\n",
      "Step 95: Average train loss: 0.0080\n",
      "Best Epoch: 99\n",
      "Currently in month 2. MSE for this month is: 50595.35546875\n",
      "Step 0: Average train loss: 0.0083\n",
      "Step 5: Average train loss: 0.0082\n",
      "Step 10: Average train loss: 0.0081\n",
      "Step 15: Average train loss: 0.0080\n",
      "Step 20: Average train loss: 0.0079\n",
      "Step 25: Average train loss: 0.0079\n",
      "Step 30: Average train loss: 0.0079\n",
      "Step 35: Average train loss: 0.0078\n",
      "Step 40: Average train loss: 0.0078\n",
      "Step 45: Average train loss: 0.0077\n",
      "Step 50: Average train loss: 0.0077\n",
      "Step 55: Average train loss: 0.0077\n",
      "Step 60: Average train loss: 0.0077\n",
      "Step 65: Average train loss: 0.0076\n",
      "Step 70: Average train loss: 0.0076\n",
      "Step 75: Average train loss: 0.0076\n",
      "Step 80: Average train loss: 0.0076\n",
      "Step 85: Average train loss: 0.0075\n",
      "Step 90: Average train loss: 0.0075\n",
      "Step 95: Average train loss: 0.0075\n",
      "Best Epoch: 99\n",
      "Currently in month 3. MSE for this month is: 49236.09375\n",
      "Step 0: Average train loss: 0.0077\n",
      "Step 5: Average train loss: 0.0076\n",
      "Step 10: Average train loss: 0.0076\n",
      "Step 15: Average train loss: 0.0076\n",
      "Step 20: Average train loss: 0.0075\n",
      "Step 25: Average train loss: 0.0075\n",
      "Step 30: Average train loss: 0.0075\n",
      "Step 35: Average train loss: 0.0075\n",
      "Step 40: Average train loss: 0.0075\n",
      "Step 45: Average train loss: 0.0075\n",
      "Step 50: Average train loss: 0.0074\n",
      "Step 55: Average train loss: 0.0074\n",
      "Step 60: Average train loss: 0.0074\n",
      "Step 65: Average train loss: 0.0074\n",
      "Step 70: Average train loss: 0.0074\n",
      "Step 75: Average train loss: 0.0074\n",
      "Step 80: Average train loss: 0.0074\n",
      "Step 85: Average train loss: 0.0074\n",
      "Step 90: Average train loss: 0.0073\n",
      "Step 95: Average train loss: 0.0073\n",
      "Best Epoch: 99\n",
      "Currently in month 4. MSE for this month is: 47370.48828125\n",
      "Step 0: Average train loss: 0.0074\n",
      "Step 5: Average train loss: 0.0074\n",
      "Step 10: Average train loss: 0.0073\n",
      "Step 15: Average train loss: 0.0073\n",
      "Step 20: Average train loss: 0.0073\n",
      "Step 25: Average train loss: 0.0073\n",
      "Step 30: Average train loss: 0.0073\n",
      "Step 35: Average train loss: 0.0073\n",
      "Step 40: Average train loss: 0.0073\n",
      "Step 45: Average train loss: 0.0072\n",
      "Step 50: Average train loss: 0.0072\n",
      "Step 55: Average train loss: 0.0072\n",
      "Step 60: Average train loss: 0.0072\n",
      "Step 65: Average train loss: 0.0072\n",
      "Step 70: Average train loss: 0.0072\n",
      "Step 75: Average train loss: 0.0072\n",
      "Step 80: Average train loss: 0.0072\n",
      "Step 85: Average train loss: 0.0072\n",
      "Step 90: Average train loss: 0.0072\n",
      "Step 95: Average train loss: 0.0072\n",
      "Best Epoch: 99\n",
      "Currently in month 5. MSE for this month is: 40957.37109375\n",
      "Step 0: Average train loss: 0.0071\n",
      "Step 5: Average train loss: 0.0070\n",
      "Step 10: Average train loss: 0.0070\n",
      "Step 15: Average train loss: 0.0070\n",
      "Step 20: Average train loss: 0.0070\n",
      "Step 25: Average train loss: 0.0069\n",
      "Step 30: Average train loss: 0.0069\n",
      "Step 35: Average train loss: 0.0069\n",
      "Step 40: Average train loss: 0.0069\n",
      "Step 45: Average train loss: 0.0069\n",
      "Step 50: Average train loss: 0.0069\n",
      "Step 55: Average train loss: 0.0069\n",
      "Step 60: Average train loss: 0.0069\n",
      "Step 65: Average train loss: 0.0069\n",
      "Step 70: Average train loss: 0.0068\n",
      "Step 75: Average train loss: 0.0068\n",
      "Step 80: Average train loss: 0.0068\n",
      "Step 85: Average train loss: 0.0068\n",
      "Step 90: Average train loss: 0.0068\n",
      "Step 95: Average train loss: 0.0068\n",
      "Best Epoch: 99\n",
      "Currently in month 6. MSE for this month is: 23174.64453125\n",
      "Step 0: Average train loss: 0.0056\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0055\n",
      "Step 55: Average train loss: 0.0055\n",
      "Step 60: Average train loss: 0.0055\n",
      "Step 65: Average train loss: 0.0055\n",
      "Step 70: Average train loss: 0.0055\n",
      "Step 75: Average train loss: 0.0054\n",
      "Step 80: Average train loss: 0.0054\n",
      "Step 85: Average train loss: 0.0054\n",
      "Step 90: Average train loss: 0.0054\n",
      "Step 95: Average train loss: 0.0054\n",
      "Best Epoch: 99\n",
      "Currently in month 7. MSE for this month is: 9077.646484375\n",
      "Step 0: Average train loss: 0.0055\n",
      "Step 5: Average train loss: 0.0055\n",
      "Step 10: Average train loss: 0.0055\n",
      "Step 15: Average train loss: 0.0055\n",
      "Step 20: Average train loss: 0.0055\n",
      "Step 25: Average train loss: 0.0055\n",
      "Step 30: Average train loss: 0.0055\n",
      "Step 35: Average train loss: 0.0055\n",
      "Step 40: Average train loss: 0.0055\n",
      "Step 45: Average train loss: 0.0055\n",
      "Step 50: Average train loss: 0.0054\n",
      "Step 55: Average train loss: 0.0054\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m hp\u001b[39m.\u001b[39mload(\u001b[39m6\u001b[39m)\n\u001b[1;32m     21\u001b[0m hp\u001b[39m.\u001b[39msource_state_dict \u001b[39m=\u001b[39m state_dict\n\u001b[0;32m---> 22\u001b[0m accur, timer, forecasts \u001b[39m=\u001b[39m target(eval_data, features, hp, scale, WFE \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m);\n\u001b[1;32m     23\u001b[0m \u001b[39mprint\u001b[39m(accur[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m~/SolNet-2/Models/models.py:57\u001b[0m, in \u001b[0;36mtarget\u001b[0;34m(dataset, features, hp, scale, WFE)\u001b[0m\n\u001b[1;32m     54\u001b[0m     transfer_model\u001b[39m.\u001b[39mload_state_dict(hp\u001b[39m.\u001b[39msource_state_dict)\n\u001b[1;32m     56\u001b[0m \u001b[39mif\u001b[39;00m WFE:\n\u001b[0;32m---> 57\u001b[0m     avg_error, times, forecasts \u001b[39m=\u001b[39m WF_trainer(dataset, features, hp, transfer_model, scale\u001b[39m=\u001b[39mscale) \n\u001b[1;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     avg_error, times \u001b[39m=\u001b[39m trainer(dataset, features, hp, transfer_model, scale\u001b[39m=\u001b[39mscale)\n",
      "File \u001b[0;32m~/SolNet-2/Models/models.py:232\u001b[0m, in \u001b[0;36mWF_trainer\u001b[0;34m(dataset, features, hp, model, scale, criterion)\u001b[0m\n\u001b[1;32m    229\u001b[0m train_timer \u001b[39m=\u001b[39m Timer()\n\u001b[1;32m    230\u001b[0m training \u001b[39m=\u001b[39m Training(model, X_train[i], y_train[i], \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, epochs, learning_rate\u001b[39m=\u001b[39mhp\u001b[39m.\u001b[39mlr, criterion\u001b[39m=\u001b[39mcriterion, \n\u001b[1;32m    231\u001b[0m                 trial\u001b[39m=\u001b[39mhp\u001b[39m.\u001b[39mtrial, optimizer_name\u001b[39m=\u001b[39mhp\u001b[39m.\u001b[39moptimizer_name, weight_decay \u001b[39m=\u001b[39m hp\u001b[39m.\u001b[39mwd, batch_size\u001b[39m=\u001b[39mhp\u001b[39m.\u001b[39mbatch_size)\n\u001b[0;32m--> 232\u001b[0m avg_error, state_dict \u001b[39m=\u001b[39m training\u001b[39m.\u001b[39mfit()\n\u001b[1;32m    233\u001b[0m train_timer\u001b[39m.\u001b[39mstop()\n\u001b[1;32m    234\u001b[0m model\u001b[39m.\u001b[39mload_state_dict(state_dict)\n",
      "File \u001b[0;32m~/SolNet-2/Models/training.py:119\u001b[0m, in \u001b[0;36mTraining.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m output \u001b[39m=\u001b[39m output\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m    118\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcriterion(prediction, output)\n\u001b[0;32m--> 119\u001b[0m total_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(loss)\n\u001b[1;32m    120\u001b[0m num_train_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    122\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pd.read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "33"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.2 ('solnet')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02543bb0ef14551c549047461536d109a34ccf1dceeb84fa14a9d60c3d57cc93"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
