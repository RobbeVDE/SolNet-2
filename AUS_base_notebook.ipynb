{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_id = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALL CODE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Importing and key parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters needed for a run:\n",
    "\n",
    "# Data fetching\n",
    "locations_used = 1\n",
    "start_date = 2012\n",
    "end_date = 2013\n",
    "\n",
    "# Forecasting parameters\n",
    "day_only = False\n",
    "features = ['P']\n",
    "final_month = 12\n",
    "split = 0.8\n",
    "\n",
    "# Lstm parameters\n",
    "hidden_size = 400\n",
    "num_layers = 3\n",
    "dropout = 0.5\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Training parameters\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Target location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Robbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1206\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1178\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1142\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyarrow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_aus \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../data/australia/aus_production.parquet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m data_aus \u001b[38;5;241m=\u001b[39m data_aus[data_aus[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCustomer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m customer_id]\n\u001b[0;32m      3\u001b[0m data_aus\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:654\u001b[0m, in \u001b[0;36mread_parquet\u001b[1;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    502\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_parquet\u001b[39m(\n\u001b[0;32m    503\u001b[0m     path: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    512\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m    513\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    Load a parquet object from the file path, returning a DataFrame.\u001b[39;00m\n\u001b[0;32m    515\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    651\u001b[0m \u001b[38;5;124;03m    1    4    9\u001b[39;00m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 654\u001b[0m     impl \u001b[38;5;241m=\u001b[39m \u001b[43mget_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_nullable_dtypes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n\u001b[0;32m    657\u001b[0m         msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    658\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe argument \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muse_nullable_dtypes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will be removed \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    659\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124min a future version.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    660\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:77\u001b[0m, in \u001b[0;36mget_engine\u001b[1;34m(engine)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to find a usable engine; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtried using: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_msgs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     74\u001b[0m     )\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPyArrowImpl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfastparquet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FastParquetImpl()\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parquet.py:162\u001b[0m, in \u001b[0;36mPyArrowImpl.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 162\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpyarrow is required for parquet support.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m    164\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyarrow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparquet\u001b[39;00m\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;66;03m# import utils to register the pyarrow extension types\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Robbe\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\compat\\_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pyarrow'. pyarrow is required for parquet support. Use pip or conda to install pyarrow."
     ]
    }
   ],
   "source": [
    "data_aus = pd.read_parquet('../data/australia/aus_production.parquet', engine='pyarrow')\n",
    "data_aus = data_aus[data_aus['Customer'] == customer_id]\n",
    "data_aus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-33.69699153381296, 151.13077966206853, 3.78, 0, 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparams from the data\n",
    "peak_power = data_aus['Generator Capacity'].iloc[0]\n",
    "latitude = data_aus['latitude'].iloc[0]\n",
    "longitude = data_aus['longitude'].iloc[0]\n",
    "\n",
    "# Hyperparams not included in the data\n",
    "tilt = 0\n",
    "azimuth = 0\n",
    "optimalangles = True\n",
    "\n",
    "latitude, longitude, peak_power, tilt, azimuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'australia_1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique name for the data, model and metrics\n",
    "data_name = 'australia' '_' + str(customer_id)\n",
    "data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the folders to save the data and models\n",
    "data_folder = '../data/AUS/'\n",
    "model_folder = '../models/AUS/' + data_name\n",
    "if not os.path.exists(data_folder):\n",
    "    os.makedirs(data_folder)\n",
    "if not os.path.exists(model_folder):\n",
    "    os.makedirs(model_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-07-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-07-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 19:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 20:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 21:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 22:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17544 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       P\n",
       "date                    \n",
       "2011-07-01 00:00:00  0.0\n",
       "2011-07-01 01:00:00  0.0\n",
       "2011-07-01 02:00:00  0.0\n",
       "2011-07-01 03:00:00  0.0\n",
       "2011-07-01 04:00:00  0.0\n",
       "...                  ...\n",
       "2013-06-30 19:00:00  0.0\n",
       "2013-06-30 20:00:00  0.0\n",
       "2013-06-30 21:00:00  0.0\n",
       "2013-06-30 22:00:00  0.0\n",
       "2013-06-30 23:00:00  0.0\n",
       "\n",
       "[17544 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aus = pd.DataFrame(data_aus['Values'])\n",
    "data_aus = data_aus.resample('H').sum()\n",
    "data_aus = data_aus.rename(columns={\"Values\":\"P\"})\n",
    "\n",
    "target_data = data_aus\n",
    "target_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Source location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Robbe\\\\OneDrive - KU Leuven\\\\Master\\\\Thesis\\\\SolNet-CD07\\\\notebooks'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the datafetcher class\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatafetcher\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataFetcher\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Fetch data from PVGIS\u001b[39;00m\n\u001b[0;32m      5\u001b[0m data_PVGIS \u001b[38;5;241m=\u001b[39m DataFetcher(latitude,longitude,peak_power, tilt, azimuth, locations\u001b[38;5;241m=\u001b[39mlocations_used, start_date\u001b[38;5;241m=\u001b[39mstart_date, end_date\u001b[38;5;241m=\u001b[39mend_date,optimal_angles\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# Import the datafetcher class\n",
    "from src.data.datafetcher import DataFetcher\n",
    "\n",
    "# Fetch data from PVGIS\n",
    "data_PVGIS = DataFetcher(latitude,longitude,peak_power, tilt, azimuth, locations=locations_used, start_date=start_date, end_date=end_date,optimal_angles=1)\n",
    "\n",
    "# Save the data in the data folder\n",
    "#path = data.save_data(file_name = data_name + '/' + data_name)\n",
    "#path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =[]\n",
    "data.append(data_PVGIS.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users/Robbe/OneDrive - KU Leuven/Master/Thesis/SolNet-CD07/src/data\\featurisation.py:56: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[i]['hour_sin'] = np.sin(2 * np.pi * self.data[i].index.hour / 24)\n",
      "C:\\Users/Robbe/OneDrive - KU Leuven/Master/Thesis/SolNet-CD07/src/data\\featurisation.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[i]['hour_cos'] = np.cos(2 * np.pi * self.data[i].index.hour / 24)\n",
      "C:\\Users/Robbe/OneDrive - KU Leuven/Master/Thesis/SolNet-CD07/src/data\\featurisation.py:59: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[i]['month_sin'] = np.sin(2 * np.pi * self.data[i].index.month / 12)\n",
      "C:\\Users/Robbe/OneDrive - KU Leuven/Master/Thesis/SolNet-CD07/src/data\\featurisation.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.data[i]['month_cos'] = np.cos(2 * np.pi * self.data[i].index.month / 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-01 00:00:00</th>\n",
       "      <td>2946.32</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 01:00:00</th>\n",
       "      <td>3091.74</td>\n",
       "      <td>0.258819</td>\n",
       "      <td>0.965926</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 02:00:00</th>\n",
       "      <td>3103.42</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 03:00:00</th>\n",
       "      <td>2909.88</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-01 04:00:00</th>\n",
       "      <td>2618.67</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           P  hour_sin  hour_cos  month_sin  month_cos\n",
       "time                                                                  \n",
       "2012-01-01 00:00:00  2946.32  0.000000  1.000000        0.5   0.866025\n",
       "2012-01-01 01:00:00  3091.74  0.258819  0.965926        0.5   0.866025\n",
       "2012-01-01 02:00:00  3103.42  0.500000  0.866025        0.5   0.866025\n",
       "2012-01-01 03:00:00  2909.88  0.707107  0.707107        0.5   0.866025\n",
       "2012-01-01 04:00:00  2618.67  0.866025  0.500000        0.5   0.866025"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the featurisation class\n",
    "from featurisation import Featurisation\n",
    "\n",
    "# Decide on the features to use in making the model (Note that 'P' should always be included since it's the target variable)\n",
    "#dataset = Featurisation(data.dataset).base_features(features)\n",
    "dataset = Featurisation(data).base_features(features)\n",
    "\n",
    "# Use cyclic features as well\n",
    "dataset = Featurisation(dataset).cyclic_features(yearly=True)\n",
    "features = dataset[0].columns # update the features\n",
    "dataset[0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import daytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if day_only is True:\n",
    "    dataset, removed_hours, kept_hours = daytime.remove_nighttime(dataset)\n",
    "    lags = len(kept_hours)\n",
    "    forecast_period = len(kept_hours)\n",
    "    removed_hours, kept_hours\n",
    "else:\n",
    "    lags = 24\n",
    "    forecast_period = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain_min = [0.0]\n",
    "domain_max = [peak_power*0.86]\n",
    "for i in range(len(features[1:])):\n",
    "    domain_min.append(min(dataset[0][features[i+1]]))\n",
    "    domain_max.append(max(dataset[0][features[i+1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0] = dataset[0].tz_localize('UTC').tz_convert('Australia/Sydney').tz_localize(None)\n",
    "dataset[0] = dataset[0][13:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Target featurisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove nighttime\n",
    "if day_only is True:\n",
    "    data_aus = data_aus[~data_aus.index.hour.isin(removed_hours)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = data_aus.index[0]\n",
    "end = dataset[0].index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-02 00:00:00</th>\n",
       "      <td>-0.258819</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02 01:00:00</th>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02 02:00:00</th>\n",
       "      <td>-0.707107</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02 03:00:00</th>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02 04:00:00</th>\n",
       "      <td>-0.965926</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     hour_sin  hour_cos  month_sin  month_cos\n",
       "time                                                         \n",
       "2012-01-02 00:00:00 -0.258819 -0.965926        0.5   0.866025\n",
       "2012-01-02 01:00:00 -0.500000 -0.866025        0.5   0.866025\n",
       "2012-01-02 02:00:00 -0.707107 -0.707107        0.5   0.866025\n",
       "2012-01-02 03:00:00 -0.866025 -0.500000        0.5   0.866025\n",
       "2012-01-02 04:00:00 -0.965926 -0.258819        0.5   0.866025"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We use the features of dataset[0] because this is the base location, and is identical to the target location\n",
    "features_nl = dataset[0][features[1:]].loc[start:end]\n",
    "features_nl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2012-01-02 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012-01-02 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.659258e-01</td>\n",
       "      <td>-0.258819</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 19:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.071068e-01</td>\n",
       "      <td>-0.707107</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 20:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 21:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 22:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-06-30 23:00:00</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.588190e-01</td>\n",
       "      <td>-0.965926</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13104 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       P      hour_sin  hour_cos     month_sin  month_cos\n",
       "2012-01-02 00:00:00  0.0 -2.588190e-01 -0.965926  5.000000e-01   0.866025\n",
       "2012-01-02 01:00:00  0.0 -5.000000e-01 -0.866025  5.000000e-01   0.866025\n",
       "2012-01-02 02:00:00  0.0 -7.071068e-01 -0.707107  5.000000e-01   0.866025\n",
       "2012-01-02 03:00:00  0.0 -8.660254e-01 -0.500000  5.000000e-01   0.866025\n",
       "2012-01-02 04:00:00  0.0 -9.659258e-01 -0.258819  5.000000e-01   0.866025\n",
       "...                  ...           ...       ...           ...        ...\n",
       "2013-06-30 19:00:00  0.0  7.071068e-01 -0.707107  1.224647e-16  -1.000000\n",
       "2013-06-30 20:00:00  0.0  5.000000e-01 -0.866025  1.224647e-16  -1.000000\n",
       "2013-06-30 21:00:00  0.0  2.588190e-01 -0.965926  1.224647e-16  -1.000000\n",
       "2013-06-30 22:00:00  0.0  1.224647e-16 -1.000000  1.224647e-16  -1.000000\n",
       "2013-06-30 23:00:00  0.0 -2.588190e-01 -0.965926  1.224647e-16  -1.000000\n",
       "\n",
       "[13104 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_data = pd.merge(data_aus.loc[start:end], features_nl, left_index=True, right_index=True)\n",
    "target_data = target_data.loc[~target_data.index.duplicated(keep='first')]\n",
    "target_data = target_data.resample('H').asfreq() # Add the missing values from summer time\n",
    "target_data = target_data.interpolate(method='linear')\n",
    "\n",
    "target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>month_cos</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [P, hour_sin, hour_cos, month_sin, month_cos]\n",
       "Index: []"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0] = dataset[0][dataset[0].index.year < target_data.index.year[0]]\n",
    "dataset[0] = dataset[0].loc[~dataset[0].index.duplicated(keep='first')]\n",
    "dataset[0] = dataset[0].resample('H').asfreq() # Add the missing values from summer time\n",
    "dataset[0] = dataset[0].interpolate(method='linear')\n",
    "dataset[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create tensors of the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Import the tensorisation class to transform the data into tensors for use in pytorch models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensors\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensorisation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensorisation\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m# Get the list of features\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# Import the tensorisation class to transform the data into tensors for use in pytorch models\n",
    "from src.tensors.tensorisation import Tensorisation\n",
    "import torch\n",
    "\n",
    "# Get the list of features\n",
    "features = list(dataset[0].columns)\n",
    "\n",
    "# Get the tensors\n",
    "X_train_source = torch.empty(0, dtype=torch.float32)\n",
    "X_test_source = torch.empty(0, dtype=torch.float32)\n",
    "y_train_source = torch.empty(0, dtype=torch.float32)\n",
    "y_test_source = torch.empty(0, dtype=torch.float32)\n",
    "\n",
    "for i in range(len(dataset)):\n",
    "    tensors = Tensorisation(dataset[i], 'P', features, lags, forecast_period)\n",
    "    X_train, X_test, y_train, y_test = tensors.tensor_creation()\n",
    "    X_train_source = torch.concat([X_train_source, X_train])\n",
    "    X_test_source = torch.concat([X_test_source, X_test])\n",
    "    y_train_source = torch.concat([y_train_source, y_train])\n",
    "    y_test_source = torch.concat([y_test_source, y_test])\n",
    "    \n",
    "X_train_source.shape, X_test_source.shape, y_train_source.shape, y_test_source.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_months = list(target_data[target_data.index.year == (target_data.index.year[-1]-1)].index.month.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the end of the month\n",
    "\n",
    "training_months_copy = training_months.copy()\n",
    "\n",
    "for month in training_months_copy:\n",
    "    if month > final_month:\n",
    "        training_months.remove(month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_starts = []\n",
    "for i in range(len(training_months)):\n",
    "    train_start = target_data[(target_data.index.year == (target_data.index.year[-1]-1)) & (target_data.index.month ==training_months[i])].index[0]\n",
    "    train_starts.append(train_start)\n",
    "    \n",
    "train_starts = list(reversed(train_starts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data_end = target_data[(target_data.index.year == (target_data.index.year[-1]-1)) & (target_data.index.month ==final_month)].index[-1]\n",
    "model_data_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_target_list = []\n",
    "X_test_target_list = []\n",
    "X_eval_target_list = []\n",
    "y_train_target_list = []\n",
    "y_test_target_list = []\n",
    "y_eval_target_list = []\n",
    "\n",
    "for i in range(len(training_months)):     \n",
    "    tensors = Tensorisation(target_data[train_starts[i]:model_data_end], 'P', features, lags, forecast_period,train_test_split = split, domain_min=domain_min, domain_max=domain_max)\n",
    "    eval_tensors = Tensorisation(target_data, 'P', features, lags, forecast_period,domain_min=domain_min, domain_max=domain_max)\n",
    "    X_train_target, X_test_target, y_train_target, y_test_target = tensors.tensor_creation()\n",
    "    _, _, _, _, X_eval_target, y_eval_target = eval_tensors.tensor_creation_with_evaluation(len(target_data[(target_data.index >= '2012-07-01')]))\n",
    "    X_train_target_list.append(X_train_target)\n",
    "    X_test_target_list.append(X_test_target)\n",
    "    X_eval_target_list.append(X_eval_target)\n",
    "    y_train_target_list.append(y_train_target)\n",
    "    y_test_target_list.append(y_test_target)\n",
    "    y_eval_target_list.append(y_eval_target) \n",
    "    \n",
    "    print(X_train_target.shape, X_test_target.shape, X_eval_target.shape, y_train_target.shape, y_test_target.shape, y_eval_target.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Source model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the lstm class to create an untrained LSTM\n",
    "from src.models.lstm import LSTM\n",
    "\n",
    "# Set the parameters for the lstm\n",
    "input_size = len(features)\n",
    "\n",
    "my_lstm = LSTM(input_size,hidden_size,num_layers, forecast_period, dropout).to(device)\n",
    "my_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the training class to train the model\n",
    "import src.models.training as train\n",
    " \n",
    "# Initialize the trainer\n",
    "training = train.Training(my_lstm, X_train_source, y_train_source, X_test_source, y_test_source, epochs,batch_size=batch_size, learning_rate=learning_rate)\n",
    "\n",
    "# Train the model and return the trained parameters and the best iteration\n",
    "state_dict_list, best_epoch = training.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state dictionary of the best performing model\n",
    "my_lstm.load_state_dict(state_dict_list[best_epoch])\n",
    "\n",
    "# Save the model state dictionary for later use \n",
    "train.save_model(my_lstm, 'AUS/' + data_name + '/model_' + data_name + '_transfer_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecast with the model\n",
    "forecasts = my_lstm(X_test_source.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the evaluation script\n",
    "from src.evaluation.evaluation import Evaluation\n",
    "\n",
    "# Evaluate the model performance\n",
    "source_eval = Evaluation(y_test_source.detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "# Show the evaluation metrics\n",
    "source_eval.metrics()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Target model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters for the lstm\n",
    "input_size = len(features)\n",
    "\n",
    "# Create empty models for each of the periods\n",
    "lstms = []\n",
    "\n",
    "for i in range(len(training_months)+1):\n",
    "    lstms.append(LSTM(input_size,hidden_size,num_layers, forecast_period, dropout).to(device))\n",
    "    \n",
    "torch.save(lstms[0].state_dict(), '../models/AUS/' + data_name + '/model_' + data_name + '_target_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_best_epochs = [0]\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    # Initialize the trainer\n",
    "    training = train.Training(lstms[i+1], X_train_target_list[i], y_train_target_list[i], X_test_target_list[i], y_test_target_list[i], epochs, learning_rate=learning_rate)\n",
    "\n",
    "    # Train the model and return the trained parameters and the best iteration\n",
    "    state_dict_list, best_epoch = training.fit()\n",
    "    \n",
    "    # Load the state dictionary of the best performing model\n",
    "    lstms[i+1].load_state_dict(state_dict_list[best_epoch])\n",
    "    target_best_epochs.append(best_epoch)\n",
    "    \n",
    "    # Save the model state dictionary for later use\n",
    "    #Training.save_model(lstms[i+1], 'AUS/' + data_name + '/model_' + data_name + '_target_' + str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_RMSEs = []\n",
    "\n",
    "# Evaluate a clean model\n",
    "forecasts = lstms[0](X_eval_target_list[0].to(device))\n",
    "source_eval = Evaluation(y_eval_target_list[0].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "target_RMSEs.append(source_eval.metrics()['RMSE'].values[0])\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    # Forecast with the model\n",
    "    forecasts = lstms[i+1](X_eval_target_list[i].to(device))\n",
    "    # Evaluate the model performance\n",
    "    source_eval = Evaluation(y_eval_target_list[i].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "    # Show the evaluation metrics\n",
    "    target_RMSEs.append(source_eval.metrics()['RMSE'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_RMSEs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Transfer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers to freeze\n",
    "\n",
    "freezing = []\n",
    "\n",
    "for name, _ in my_lstm.lstm.named_parameters():\n",
    "    freezing.append(name)\n",
    "    \n",
    "freezing = freezing[:4]\n",
    "freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_models = []\n",
    "transfer_best_epochs = [0]\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    transfer_model  = LSTM(input_size,hidden_size,num_layers, forecast_period, dropout).to(device)\n",
    "    transfer_model.load_state_dict(torch.load('../models/AUS/' + data_name + '/model_' + data_name + '_transfer_0'))\n",
    "       \n",
    "    for name, param in transfer_model.lstm.named_parameters():\n",
    "        if any(freezing_name in name for freezing_name in freezing):\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # Initialize the trainer\n",
    "    training = train.Training(transfer_model, X_train_target_list[i], y_train_target_list[i], X_test_target_list[i], y_test_target_list[i], epochs, batch_size = batch_size, \n",
    "                              learning_rate =learning_rate/100)\n",
    "\n",
    "    # Train the model and return the trained parameters and the best iteration\n",
    "    state_dict_list, best_epoch = training.fit()\n",
    "    \n",
    "    # Load the state dictionary of the best performing model\n",
    "    transfer_model.load_state_dict(state_dict_list[best_epoch])\n",
    "    transfer_best_epochs.append(best_epoch)\n",
    "    \n",
    "    # Save the model state dictionary for later use\n",
    "    #Training.save_model(transfer_model, 'AUS/' + data_name + '/model_' + data_name + '_transfer_' + str(i+1))\n",
    "    transfer_models.append(transfer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_RMSEs = []\n",
    "\n",
    "# Evaluate a clean model\n",
    "\n",
    "transfer_model = LSTM(input_size,hidden_size,num_layers, forecast_period, dropout).to(device)\n",
    "transfer_model.load_state_dict(torch.load('../models/AUS/' + data_name + '/model_' + data_name + '_transfer_0'))\n",
    "\n",
    "forecasts = transfer_model(X_eval_target_list[0].to(device))\n",
    "source_eval = Evaluation(y_eval_target_list[0].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "transfer_RMSEs.append(source_eval.metrics()['RMSE'].values[0])\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    # Forecast with the model\n",
    "    forecasts = transfer_models[i](X_eval_target_list[i].to(device))\n",
    "    # Evaluate the model performance\n",
    "    source_eval = Evaluation(y_eval_target_list[i].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "    # Show the evaluation metrics\n",
    "    transfer_RMSEs.append(source_eval.metrics()['RMSE'].values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_RMSEs,label='target')\n",
    "plt.plot(transfer_RMSEs,label='transfer')\n",
    "plt.legend()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_RMSEs = []\n",
    "\n",
    "# Evaluate a clean model\n",
    "forecasts = X_eval_target_list[0][:,:,0]\n",
    "source_eval = Evaluation(y_eval_target_list[0].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "baseline_RMSEs.append(source_eval.metrics()['RMSE'].values[0])\n",
    "\n",
    "for i in range(len(training_months)):\n",
    "    # Forecast with the model\n",
    "    forecasts = X_eval_target_list[i][:,:,0]\n",
    "    # Evaluate the model performance\n",
    "    source_eval = Evaluation(y_eval_target_list[i].detach().flatten().numpy(), forecasts.cpu().detach().flatten().numpy())\n",
    "\n",
    "    # Show the evaluation metrics\n",
    "    baseline_RMSEs.append(source_eval.metrics()['RMSE'].values[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final visualisation and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(target_RMSEs,label='target')\n",
    "plt.plot(transfer_RMSEs,label='transfer')\n",
    "plt.plot(baseline_RMSEs, label='baseline')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(transfer_RMSEs,label='transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = []\n",
    "\n",
    "for i in range(len(training_months)+1):\n",
    "    column_names.append(str(i) + 'm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = pd.DataFrame([baseline_RMSEs, target_RMSEs, transfer_RMSEs, target_best_epochs, transfer_best_epochs],columns=column_names, index=['Baseline RMSE', 'Target RMSE', 'Transfer RMSE', 'Target epoch', 'Transfer epoch']).transpose()\n",
    "all_metrics['Target epoch'] = all_metrics['Target epoch'].astype(int)\n",
    "all_metrics['Transfer epoch'] = all_metrics['Transfer epoch'].astype(int)\n",
    "all_metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics.to_csv('../data/AUS/' + 'summary_table_' + data_name + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "solarGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
